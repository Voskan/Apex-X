{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex AI / Apex-X: Model Visualization\n",
    "\n",
    "This notebook provides tools to visualize the predictions of `TeacherModelV3` on satellite imagery. \n",
    "\n",
    "It demonstrates the \"World-Class\" capabilities:\n",
    "- **Instance Segmentation**: Precise roof masks.\n",
    "- **Mask Quality Scores**: Predicted IoU for each object.\n",
    "- **Cascade Refinement**: High-precision bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from apex_x.model import TeacherModelV3\n",
    "from apex_x.utils import seed_all\n",
    "\n",
    "seed_all(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TeacherModelV3(\n",
    "    num_classes=80,\n",
    "    backbone_model=\"facebook/dinov2-large\",\n",
    "    lora_rank=8,\n",
    "    fpn_channels=256,\n",
    "    num_cascade_stages=3\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"TeacherModelV3 loaded successfully. Note: Weights are random unless you load a checklist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualization Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(image_path, model, threshold=0.5):\n",
    "    # Load image\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return\n",
    "        \n",
    "    img_raw = cv2.imread(str(image_path))\n",
    "    img_raw = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Preprocess: DINOv2 needs multiples of 14\n",
    "    h, w = img_raw.shape[:2]\n",
    "    new_h = (h // 14) * 14\n",
    "    new_w = (w // 14) * 14\n",
    "    img = cv2.resize(img_raw, (new_w, new_h))\n",
    "    \n",
    "    img_tensor = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "    \n",
    "    # Parse outputs\n",
    "    boxes = outputs['boxes'].cpu().numpy()\n",
    "    scores = outputs['scores'].cpu().numpy()\n",
    "    quality = outputs['predicted_quality'].cpu().numpy()\n",
    "    masks = outputs['masks'].cpu().numpy() if outputs['masks'] is not None else None\n",
    "    \n",
    "    # Filter\n",
    "    keep = scores > threshold\n",
    "    boxes = boxes[keep]\n",
    "    scores = scores[keep]\n",
    "    quality = quality[keep]\n",
    "    if masks is not None:\n",
    "        masks = masks[keep]\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    # Create display image\n",
    "    disp_img = img.copy()\n",
    "    \n",
    "    # Overlay masks\n",
    "    if masks is not None and len(masks) > 0:\n",
    "        mask_overlay = np.zeros_like(disp_img)\n",
    "        for i in range(len(masks)):\n",
    "            x1, y1, x2, y2 = boxes[i].astype(int)\n",
    "            mask_logit = masks[i, 0]\n",
    "            \n",
    "            # Resize mask to box size\n",
    "            bw = max(1, x2 - x1)\n",
    "            bh = max(1, y2 - y1)\n",
    "            mask_crop = cv2.resize(mask_logit, (bw, bh))\n",
    "            mask_bool = mask_crop > 0.0\n",
    "            \n",
    "            # Color (Red)\n",
    "            roi = mask_overlay[y1:y2, x1:x2]\n",
    "            roi[mask_bool] = [255, 0, 0]  # RGB for Red\n",
    "            \n",
    "        disp_img = cv2.addWeighted(disp_img, 1.0, mask_overlay, 0.4, 0)\n",
    "    \n",
    "    plt.imshow(disp_img)\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    num_dets = len(boxes)\n",
    "    print(f\"Found {num_dets} objects\")\n",
    "    \n",
    "    for i in range(num_dets):\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        sc = scores[i]\n",
    "        q = quality[i]\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, color='cyan', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1-5, f\"{sc:.2f} Q:{q:.2f}\", color='white', fontsize=10, backgroundcolor='black')\n",
    "            \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "# visualize_prediction(\"../data/sample.jpg\", model, threshold=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
