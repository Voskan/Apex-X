
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Universal Vision Dynamic Compute Graph">
      
      
      
        <link rel="canonical" href="https://example.com/apex-x/CONTEXT/">
      
      
        <link rel="prev" href="../algorithms/">
      
      
        <link rel="next" href="../DECISIONS/">
      
      
        
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Context - Apex-X</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#apex-x-project-context-persistent-memory" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Apex-X" class="md-header__button md-logo" aria-label="Apex-X" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Apex-X
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Context
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://example.com/apex-x" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    apex-x
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../benchmarks/" class="md-tabs__link">
          
  
  
  Overview

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../PRD/" class="md-tabs__link">
          
  
  
  Specs

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../PERF/" class="md-tabs__link">
          
  
  
  Performance

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../runtime/PLUGIN_SPEC/" class="md-tabs__link">
          
  
  
  Runtime

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../release/CHECKLIST/" class="md-tabs__link">
          
  
  
  Release

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../TODO/" class="md-tabs__link">
          
  
  
  Activity

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Apex-X" class="md-nav__button md-logo" aria-label="Apex-X" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Apex-X
  </label>
  
    <div class="md-nav__source">
      <a href="https://example.com/apex-x" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    apex-x
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Overview
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../benchmarks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Benchmarks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../algorithms/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Algorithms
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Context
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Context
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#authoritative-links-mandatory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Authoritative Links (Mandatory)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#project-identity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Project Identity
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recent-updates-2026-02-11" class="md-nav__link">
    <span class="md-ellipsis">
      
        Recent Updates (2026-02-11)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#current-architecture-snapshot" class="md-nav__link">
    <span class="md-ellipsis">
      
        Current Architecture Snapshot
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-exists-right-now-2026-02-07" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Exists Right Now (2026-02-07)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#invariants-to-preserve" class="md-nav__link">
    <span class="md-ellipsis">
      
        Invariants to Preserve
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#open-risks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Open Risks
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#immediate-next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Immediate Next Steps
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-triton-fused-stage-1-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): Triton Fused Stage-1 Pipeline
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): Triton Fused Stage-1 Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-triton-tilessm-scan-baseline" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): Triton TileSSM Scan Baseline
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): Triton TileSSM Scan Baseline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-triton-tilessm-multi-direction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): Triton TileSSM Multi-Direction
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): Triton TileSSM Multi-Direction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-build-hardening-harness" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT Build Hardening + Harness
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT Build Hardening + Harness">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exact-build-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        Exact Build Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#environment-variables" class="md-nav__link">
    <span class="md-ellipsis">
      
        Environment Variables
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-tilepack-plugin-real-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT TilePack Plugin (Real Implementation)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT TilePack Plugin (Real Implementation)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-tileunpackfusion-plugin-priority-alpha" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT TileUnpackFusion Plugin (Priority + Alpha)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT TileUnpackFusion Plugin (Priority + Alpha)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-tilessmscan-plugin-forward-backward-flag" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT TileSSMScan Plugin (Forward + Backward Flag)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT TileSSMScan Plugin (Forward + Backward Flag)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-decodenms-plugin-det-postprocessing-in-engine" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT Decode+NMS Plugin (DET Postprocessing In-Engine)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT Decode+NMS Plugin (DET Postprocessing In-Engine)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-python-engine-builder-int8-calibrator" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT Python Engine Builder + INT8 Calibrator
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT Python Engine Builder + INT8 Calibrator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#engine-build-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        Engine Build Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#artifact-locations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Artifact Locations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-unified-gpu-benchmark-suite-torchtritontrt" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): Unified GPU Benchmark Suite (Torch/Triton/TRT)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): Unified GPU Benchmark Suite (Torch/Triton/TRT)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#artifact-locations_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Artifact Locations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-gpu-perf-regression-ci-workflow-baseline-compare" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): GPU Perf Regression CI Workflow + Baseline Compare
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): GPU Perf Regression CI Workflow + Baseline Compare">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#artifact-locations_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Artifact Locations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-go-runtime-hardening-loaders-batching-metrics-logging-integration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): Go Runtime Hardening (Loaders, Batching Metrics, Logging, Integration)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): Go Runtime Hardening (Loaders, Batching Metrics, Logging, Integration)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#update-protocol-every-significant-change" class="md-nav__link">
    <span class="md-ellipsis">
      
        Update Protocol (Every Significant Change)
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../DECISIONS/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Decisions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Specs
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Specs
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PRD/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PRD
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ENGINEERING_SPEC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Engineering Spec
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../QAT/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    QAT Policy
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../FP8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    FP8 Policy
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Performance
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Performance
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PERF/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PERF_GPU/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    GPU Bench
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../CI_GPU/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    GPU CI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Runtime
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Runtime
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/PLUGIN_SPEC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Plugin Spec
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/CAPS/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Capabilities
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    TensorRT
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    TensorRT
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/TENSORRT/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/TENSORRT_BUILD/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Building
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/TENSORRT_INT8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    INT8
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/TENSORRT_POST/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Postprocessing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/GO_SERVICE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Go Service
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
        
          
          <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Triton
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Triton
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/TRITON/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/TRITON_TILEPACK/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    TilePack
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/TRITON_TILEUNPACK/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    TileUnpack
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/TRITON_FUSION/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Fusion
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/TRITON_SSM/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    SSM
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../runtime/TRITON_FUSED_STAGE1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Stage 1
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Release
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Release
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../release/CHECKLIST/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Checklist
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../release/MIGRATION/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Migration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Activity
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Activity
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../TODO/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    TODO
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#authoritative-links-mandatory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Authoritative Links (Mandatory)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#project-identity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Project Identity
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recent-updates-2026-02-11" class="md-nav__link">
    <span class="md-ellipsis">
      
        Recent Updates (2026-02-11)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#current-architecture-snapshot" class="md-nav__link">
    <span class="md-ellipsis">
      
        Current Architecture Snapshot
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-exists-right-now-2026-02-07" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Exists Right Now (2026-02-07)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#invariants-to-preserve" class="md-nav__link">
    <span class="md-ellipsis">
      
        Invariants to Preserve
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#open-risks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Open Risks
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#immediate-next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Immediate Next Steps
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-triton-fused-stage-1-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): Triton Fused Stage-1 Pipeline
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): Triton Fused Stage-1 Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-triton-tilessm-scan-baseline" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): Triton TileSSM Scan Baseline
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): Triton TileSSM Scan Baseline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-triton-tilessm-multi-direction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): Triton TileSSM Multi-Direction
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): Triton TileSSM Multi-Direction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-build-hardening-harness" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT Build Hardening + Harness
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT Build Hardening + Harness">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exact-build-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        Exact Build Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#environment-variables" class="md-nav__link">
    <span class="md-ellipsis">
      
        Environment Variables
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-tilepack-plugin-real-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT TilePack Plugin (Real Implementation)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT TilePack Plugin (Real Implementation)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-tileunpackfusion-plugin-priority-alpha" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT TileUnpackFusion Plugin (Priority + Alpha)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT TileUnpackFusion Plugin (Priority + Alpha)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-tilessmscan-plugin-forward-backward-flag" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT TileSSMScan Plugin (Forward + Backward Flag)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT TileSSMScan Plugin (Forward + Backward Flag)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-decodenms-plugin-det-postprocessing-in-engine" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT Decode+NMS Plugin (DET Postprocessing In-Engine)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT Decode+NMS Plugin (DET Postprocessing In-Engine)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-tensorrt-python-engine-builder-int8-calibrator" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): TensorRT Python Engine Builder + INT8 Calibrator
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): TensorRT Python Engine Builder + INT8 Calibrator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#engine-build-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        Engine Build Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#artifact-locations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Artifact Locations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-unified-gpu-benchmark-suite-torchtritontrt" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): Unified GPU Benchmark Suite (Torch/Triton/TRT)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): Unified GPU Benchmark Suite (Torch/Triton/TRT)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#artifact-locations_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Artifact Locations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-gpu-perf-regression-ci-workflow-baseline-compare" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): GPU Perf Regression CI Workflow + Baseline Compare
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): GPU Perf Regression CI Workflow + Baseline Compare">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#artifact-locations_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Artifact Locations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-update-2026-02-08-go-runtime-hardening-loaders-batching-metrics-logging-integration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latest Update (2026-02-08): Go Runtime Hardening (Loaders, Batching Metrics, Logging, Integration)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Latest Update (2026-02-08): Go Runtime Hardening (Loaders, Batching Metrics, Logging, Integration)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run-commands_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Run Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-status_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remaining-work_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Remaining Work
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#update-protocol-every-significant-change" class="md-nav__link">
    <span class="md-ellipsis">
      
        Update Protocol (Every Significant Change)
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="apex-x-project-context-persistent-memory">Apex-X Project Context (Persistent Memory)</h1>
<h2 id="authoritative-links-mandatory">Authoritative Links (Mandatory)</h2>
<ul>
<li>PRD: <code>docs/PRD.md</code></li>
<li>Engineering spec: <code>docs/ENGINEERING_SPEC.md</code></li>
<li>Runtime plugin spec: <code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li>Decisions log: <code>docs/DECISIONS.md</code></li>
<li>Active worklist: <code>docs/TODO.md</code></li>
</ul>
<h2 id="project-identity">Project Identity</h2>
<ul>
<li>Name: <code>apex-x</code></li>
<li>Version: <code>0.1.0</code></li>
<li>License: <code>Apache-2.0</code></li>
<li>Current baseline: CPU-only reference implementation</li>
</ul>
<h2 id="recent-updates-2026-02-11">Recent Updates (2026-02-11)</h2>
<ul>
<li>Runtime capability contract was hardened:</li>
<li>canonical reason-code catalog added in <code>apex_x/runtime/caps.py</code></li>
<li>dynamic reason strings were removed in favor of stable reason codes</li>
<li>runtime reason catalog exposed via <code>runtime_reason_catalog()</code></li>
<li>Capability docs/spec alignment updates:</li>
<li><code>docs/runtime/CAPS.md</code> now defines frozen backend capability matrix and reason-code contract</li>
<li><code>docs/ENGINEERING_SPEC.md</code> includes explicit runtime capability and parity contract section</li>
<li><code>docs/PRD.md</code> adds FR-14 for runtime capability transparency</li>
<li>Parity tolerance framework was extended:</li>
<li>FP8 tolerance added to <code>ToleranceConfig</code></li>
<li>profile API added (<code>quality</code>, <code>balanced</code>, <code>edge</code>) with op/e2e tolerance bundles</li>
<li>new tests added in <code>tests/test_runtime_parity.py</code></li>
<li>Deterministic replay package was added:</li>
<li>golden fixtures: <code>tests/fixtures/replay_golden_small.json</code>, <code>tests/fixtures/replay_golden_medium.json</code></li>
<li>replay hash utilities in <code>apex_x/utils/repro.py</code> (<code>build_replay_manifest</code>, JSON/file SHA256 helpers)</li>
<li>replay validation test in <code>tests/test_replay_golden.py</code></li>
<li>CLI backend selection contract was added:</li>
<li><code>--backend cpu|torch|triton|tensorrt</code></li>
<li><code>--fallback-policy strict|permissive</code></li>
<li>strict mode returns actionable errors; permissive mode falls back deterministically</li>
<li>backend selection metadata is emitted by <code>predict</code> and <code>eval</code></li>
<li>TODO progression:</li>
<li>completed tasks <code>P0-01</code>, <code>P0-02</code>, <code>P0-03</code>, and <code>P1-01</code> were removed from <code>docs/TODO.md</code></li>
<li>completed task <code>P2-04</code> was removed from active backlog and moved to completed history</li>
<li>CI/perf gate hardening updates:</li>
<li>GPU perf workflow now has PR path trigger for GPU-critical code paths:<ul>
<li><code>apex_x/kernels/**</code></li>
<li><code>apex_x/runtime/**</code></li>
<li><code>runtime/tensorrt/**</code></li>
</ul>
</li>
<li>fork PRs are fail-closed for GPU workflow execution (<code>blocked-untrusted-pr</code>)</li>
<li>CPU and GPU perf regression scripts now emit normalized trend artifacts:<ul>
<li>CPU: <code>--trend-output artifacts/perf_trend_cpu_ci.json</code></li>
<li>GPU: <code>--trend-output artifacts/perf_gpu_trend_ci.json</code></li>
</ul>
</li>
<li>weekly trend workflow added:<ul>
<li><code>.github/workflows/perf_trend_weekly.yml</code></li>
<li>CPU weekly trend always runs</li>
<li>GPU weekly trend runs on self-hosted CUDA when <code>APEXX_ENABLE_GPU_WEEKLY=true</code></li>
</ul>
</li>
<li>workflow policy contract test added:<ul>
<li><code>tests/test_gpu_ci_workflow_contract.py</code></li>
<li>guards GPU-critical PR triggers + trusted self-hosted execution rules</li>
</ul>
</li>
<li>Release checklist evidence automation was added:</li>
<li>new generator script: <code>scripts/release_attestation.py</code></li>
<li>outputs JSON + Markdown attestation bundles with artifact SHA256/status fields</li>
<li>CI workflows now auto-publish release evidence drafts:<ul>
<li>CPU CI: <code>artifacts/release/release_attestation_ci.{json,md}</code></li>
<li>GPU CI: <code>artifacts/release/release_attestation_gpu_ci.{json,md}</code></li>
<li>weekly trend CPU/GPU jobs publish corresponding weekly attestation bundles</li>
</ul>
</li>
<li>Backward-compatibility migration documentation was finalized:</li>
<li>migration guide: <code>docs/release/MIGRATION.md</code></li>
<li>project changelog baseline: <code>CHANGELOG.md</code></li>
<li>X-03 was removed from active queue after adding explicit deprecation timeline and migration actions.</li>
<li>Temporal hysteresis quality gates were expanded:</li>
<li>new budget-aware update API: <code>hysteresis_update_with_budget(...)</code></li>
<li><code>hysteresis_rollout(...)</code> now supports optional <code>max_active</code> frame cap</li>
<li>new stability metrics:<ul>
<li><code>tile_flip_rate(...)</code></li>
<li><code>temporal_consistency(...)</code></li>
<li><code>mean_active_ratio(...)</code></li>
<li><code>summarize_temporal_stability(...)</code></li>
</ul>
</li>
<li>model CPU baseline now applies budget-aware hysteresis using <code>kmax_l0</code></li>
<li>new sequence-level tests in <code>tests/test_temporal_hysteresis_metrics.py</code></li>
<li>Quadtree recursion budgeting was extended to depth-2 deterministic selection:</li>
<li>new API: <code>deterministic_three_stage_selection(...)</code> in <code>apex_x/routing/inference_budget.py</code></li>
<li>stage contracts:<ul>
<li><code>L0</code> under <code>B1</code></li>
<li><code>L0 -&gt; L1</code> split under <code>B2</code></li>
<li><code>L1 -&gt; L2</code> split under <code>B3</code></li>
</ul>
</li>
<li>deterministic parent tie-break at split stages: score desc, tile-id asc</li>
<li><code>Kmax_L1</code>/<code>Kmax_L2</code> capacity limits enforced during child expansion</li>
<li>new tests: <code>tests/test_three_stage_selection.py</code></li>
<li>Deterministic inference-budget stress coverage was expanded:</li>
<li>new stress suite: <code>tests/test_inference_budget_stress.py</code></li>
<li>covers:<ul>
<li>equal-utility tie scaling</li>
<li>zero/near-zero delta-cost stability</li>
<li>saturated <code>Kmax</code> clipping</li>
<li>adversarial close-score repeatability</li>
</ul>
</li>
<li>Continuous dual-budget convergence controls were hardened:</li>
<li><code>BudgetDualController</code> now supports adaptive update schedule with:<ul>
<li>step decay</li>
<li>EMA-scaled learning-rate modulation</li>
<li>deadband near target budget</li>
<li>optional delta clipping</li>
</ul>
</li>
<li>trainer/model wiring now passes dual schedule config fields from <code>TrainConfig</code></li>
<li>stage-3 trainer metrics now report dual dynamics:<ul>
<li><code>dual_effective_lr_last</code></li>
<li><code>dual_error_ema_last</code></li>
<li><code>dual_update_count</code></li>
</ul>
</li>
<li>new convergence test suite: <code>tests/test_dual_budget_convergence.py</code></li>
<li>PCGrad++ monitoring was completed for shared-trunk training:</li>
<li><code>apply_pcgradpp(...)</code> diagnostics now include conflict metrics before/after projection</li>
<li>trainer emits <code>train_summary["pcgrad"]</code> payload with:<ul>
<li>pair counts/rates (<code>before</code> vs <code>after</code>)</li>
<li>shared/head parameter counts</li>
<li>gradient norm snapshots</li>
</ul>
</li>
<li>head-gradient non-projection and conflict-rate behavior are covered in:<ul>
<li><code>tests/test_pcgradpp.py</code></li>
<li><code>tests/test_trainer_stages.py</code></li>
</ul>
</li>
<li>FP8 operational telemetry was extended:</li>
<li><code>precision.py</code> fallback reasons now align to canonical runtime reason-codes</li>
<li>GPU benchmark now supports explicit FP8 request mode (<code>--dtype fp8</code>)</li>
<li>benchmark report now includes requested-vs-effective precision fields:<ul>
<li><code>requested_dtype</code></li>
<li><code>effective_dtype</code></li>
<li><code>fp8_requested</code></li>
<li><code>fp8_enabled</code></li>
<li><code>fp8_fallback_reason</code></li>
</ul>
</li>
<li>FP8 telemetry coverage added in:<ul>
<li><code>tests/test_precision_policy.py</code></li>
<li><code>tests/test_gpu_bench_fp8.py</code></li>
</ul>
</li>
<li>Unified perf regression policy was extended to TensorRT shape-sweep:</li>
<li>new script: <code>scripts/perf_regression_trt.py</code></li>
<li>new baseline: <code>scripts/perf_baseline_trt.json</code></li>
<li>trend artifacts:<ul>
<li><code>artifacts/perf_trt_trend_ci.json</code></li>
<li><code>artifacts/perf_trt_trend_weekly.json</code></li>
</ul>
</li>
<li>GPU workflows now run optional TRT compare/trend when <code>TRT_ENGINE_PATH</code> is provided.</li>
<li>Oracle supervision pipeline was hardened:</li>
<li>oracle sampler now supports a third component for long-tail tile selection</li>
<li>stage-2 trainer now logs/reports oracle label diagnostics:<ul>
<li>sample composition (<code>random</code>, <code>uncertainty</code>, <code>long_tail</code>)</li>
<li>delta distribution summary (<code>mean/std/min/max/abs_p95</code>)</li>
<li>clipping diagnostics (<code>clipped_ratio</code>)</li>
</ul>
</li>
<li>new stats helper added: <code>summarize_oracle_delta_targets(...)</code></li>
<li>coverage expanded in:<ul>
<li><code>tests/test_oracle_sampling.py</code></li>
<li><code>tests/test_oracle_distill.py</code></li>
<li><code>tests/test_trainer_stages.py</code></li>
</ul>
</li>
<li>Export and predict runtime paths reached active-queue completion status:</li>
<li><code>P1-02</code> closure validated by export contract tests:<ul>
<li><code>tests/test_export.py</code></li>
<li><code>tests/test_tensorrt_export_manifest.py</code></li>
</ul>
</li>
<li><code>P1-03</code> closure validated by runner/CLI backend execution tests:<ul>
<li><code>tests/test_infer_runner.py</code></li>
<li><code>tests/test_cli.py</code></li>
</ul>
</li>
<li>deployment-host evidence for real TensorRT engines remains tracked in device-blocked queue.</li>
<li>Eval runtime path reached active-queue completion status:</li>
<li><code>P1-04</code> closure validated by eval + dataset execution contract tests:<ul>
<li><code>tests/test_eval_metrics.py</code></li>
<li><code>tests/test_infer_runner.py</code></li>
<li><code>tests/test_cli.py</code></li>
</ul>
</li>
<li>TensorRT INT8 sensitive-layer precision enforcement was hardened:</li>
<li>builder now emits per-layer precision evidence in <code>EngineBuildResult.layer_precision_status</code></li>
<li>strict precision-constraint mode now fails build when matched layers cannot be constrained</li>
<li>new coverage added in <code>tests/test_tensorrt_precision_policy.py</code></li>
<li>TensorRT plugin build-time contract validation was hardened:</li>
<li>builder now validates plugin creator contracts for:<ul>
<li>presence</li>
<li>version</li>
<li>namespace</li>
<li>plugin field-signature metadata</li>
</ul>
</li>
<li>strict mode emits actionable mismatch errors for required plugins</li>
<li><code>PluginContract</code> overrides are now supported in build config</li>
<li>new non-CUDA unit coverage:<ul>
<li><code>tests/test_tensorrt_plugin_contracts.py</code></li>
</ul>
</li>
<li>TensorRT INT8 calibration cache governance was completed:</li>
<li>cache-key contract now binds calibration cache reuse to:<ul>
<li>model/export identity hash</li>
<li>plugin version/namespace metadata</li>
<li>precision profile</li>
<li>calibration dataset version (explicit or auto-digest)</li>
</ul>
</li>
<li>calibrator cache blob now enforces key-aware stale-cache invalidation.</li>
<li>legacy raw cache blobs are accepted only when key governance is disabled.</li>
<li>new non-CUDA unit coverage:<ul>
<li><code>tests/test_tensorrt_int8_cache.py</code></li>
</ul>
</li>
<li>TensorRT parity harness was expanded with backend matrix + sweep APIs:</li>
<li><code>ParityMatrixCase</code> and <code>run_parity_matrix_case(...)</code> compare:<ul>
<li>reference vs triton</li>
<li>reference vs tensorrt</li>
<li>triton vs tensorrt</li>
</ul>
</li>
<li><code>run_parity_sweep(...)</code> provides shape/precision sweep aggregation with profile-aware tolerances.</li>
<li>CPU-safe harness contract coverage added in:<ul>
<li><code>tests/test_trt_parity_harness.py</code></li>
</ul>
</li>
<li>Triton TileSSM long-sequence behavior was hardened:</li>
<li>Triton forward scan now streams long sequences in chunks when <code>K &gt; 4096</code>.</li>
<li>chunk execution carries recurrent state between launches to preserve recurrence semantics.</li>
<li>CPU-safe chunking contract tests added in:<ul>
<li><code>tests/test_triton_tilessm_parity_dispatch.py</code></li>
</ul>
</li>
<li>Triton TileUnpack overlap blend dispatch gap was reduced:</li>
<li><code>overlap_mode=\"blend\"</code> no longer has a forced reference-only dispatch branch.</li>
<li>blend overlap path now executes through <code>tileunpack_triton(...)</code> entrypoint with
    ordered composition parity semantics.</li>
<li>overlap tests expanded:<ul>
<li><code>tests/test_triton_tileunpack_overlap_dispatch.py</code></li>
<li><code>tests/test_triton_tileunpack_overlap_gpu.py</code></li>
</ul>
</li>
<li>Triton Stage-1 fused selector was integrated into FF heavy-path inference:</li>
<li><code>FFHeavyPath</code> now routes to <code>fused_pack_op_unpack_dispatch(...)</code> only when strict
    compatibility predicates hold (eval, identity refine, constant FiLM params, unique indices).</li>
<li>non-compatible cases remain on deterministic decomposed <code>pack -&gt; FiLM -&gt; unpack</code> path.</li>
<li>new coverage:<ul>
<li><code>tests/test_ff_heavy_path_fused_stage1.py</code></li>
</ul>
</li>
<li>Triton autotune registry + benchmark telemetry were added:</li>
<li>new module: <code>apex_x/kernels/triton/autotune_registry.py</code></li>
<li>registry records per-op/per-shape-bucket selected launch config and cache counters</li>
<li>instrumented kernels:<ul>
<li>TilePack</li>
<li>TileUnpack priority/scatter</li>
<li>FusionGate alpha/fuse</li>
<li>fused stage-1 pack/op/unpack</li>
</ul>
</li>
<li>GPU benchmark report now exports:<ul>
<li><code>triton_autotune.summary</code></li>
<li><code>triton_autotune.entries</code></li>
</ul>
</li>
<li>CPU-safe contract coverage added in:<ul>
<li><code>tests/test_triton_autotune_registry.py</code></li>
</ul>
</li>
<li>Runtime docs consistency sweep completed:</li>
<li>synchronized current implementation status in:<ul>
<li><code>docs/runtime/TRITON.md</code></li>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
</ul>
</li>
<li>Release readiness docs were strengthened:</li>
<li>added <code>docs/release/CHECKLIST.md</code> with mandatory artifact attestation + rollback section</li>
<li>linked checklist in <code>README.md</code>, docs index, and MkDocs navigation</li>
<li>Go runtime telemetry schema was aligned with Python CLI/runtime reports:</li>
<li><code>/predict</code> response now includes <code>runtime</code> payload with backend selection, fallback, precision, and latency breakdown</li>
<li>latency keys aligned to <code>latency_ms.total</code>, <code>latency_ms.backend_execute</code>, <code>latency_ms.backend_preflight</code></li>
<li>service test coverage updated for runtime telemetry schema</li>
<li>explicit SLA-oriented error policies added:<ul>
<li>queue saturation returns <code>429 Too Many Requests</code></li>
<li>predict timeout returns <code>504 Gateway Timeout</code></li>
</ul>
</li>
<li>Go runtime backend bridge execution path was added:</li>
<li>ORT and TRT adapters now support optional Python bridge execution via:<ul>
<li><code>APEXX_ORT_BRIDGE_CMD</code></li>
<li><code>APEXX_TRT_BRIDGE_CMD</code></li>
</ul>
</li>
<li>bridge protocol entrypoint implemented at <code>apex_x/runtime/service_bridge.py</code></li>
<li>Go service backend error classification now maps:<ul>
<li>backend unavailable -&gt; <code>503 Service Unavailable</code></li>
<li>backend inference/protocol failure -&gt; <code>502 Bad Gateway</code></li>
</ul>
</li>
<li>synthetic score fallback was removed from ORT/TRT adapters (fail-closed behavior)</li>
<li>native host limitation snapshot:<ul>
<li>Go <code>onnxruntime</code> native pkg-config package is unavailable on this host</li>
<li>TensorRT Python module is unavailable on this host</li>
</ul>
</li>
<li>Go runtime canary parity mode was added:</li>
<li>optional shadow adapter execution with configurable sample rate</li>
<li>mismatch telemetry counters (<code>samples</code>, <code>compares</code>, <code>mismatches</code>, <code>errors</code>, <code>mismatch_ratio</code>)</li>
<li>canary behavior is asynchronous to avoid impacting primary response path</li>
<li>configurable canary payload capture policy and storage controls were added:<ul>
<li>policy: <code>off|mismatch|error|all</code></li>
<li>JSONL sink: <code>APEXX_CANARY_CAPTURE_PATH</code></li>
<li>file size guard: <code>APEXX_CANARY_CAPTURE_MAX_BYTES</code></li>
</ul>
</li>
<li>SLA gate test was added for timeout/overflow rates and canary overhead:<ul>
<li><code>TestCanaryLoadGateThresholds</code> in <code>runtime/go/internal/service/sla_gate_test.go</code></li>
<li>CI wiring added in <code>.github/workflows/ci.yml</code> (<code>go-runtime</code> job)</li>
</ul>
</li>
<li>Inference runner abstraction was added for CLI predict/eval:</li>
<li>new module <code>apex_x/infer/runner.py</code> introduces:<ul>
<li><code>run_model_inference(...)</code> with a common inference result schema</li>
<li><code>RuntimeMetadata</code> and <code>InferenceRunResult</code> dataclasses</li>
<li><code>extract_routing_diagnostics(...)</code> (replacing ad-hoc placeholder extraction)</li>
<li>FFModule-based <code>torch</code> executor path for backend-specific execution</li>
<li>triton execution branch with capability checks and deterministic fallback behavior</li>
</ul>
</li>
<li><code>apex_x/cli.py</code> now uses the runner for both <code>predict</code> and <code>eval</code></li>
<li><code>predict</code> now supports <code>--report-json</code> with runtime metadata + routing diagnostics payload</li>
<li>TensorRT branch now performs preflight validation:<ul>
<li>capability gate (<code>cuda</code> + TensorRT Python)</li>
<li>env-driven artifact checks (<code>APEXX_EXPORT_MANIFEST_PATH</code>, <code>APEXX_TRT_ENGINE_PATH</code>)</li>
<li>deterministic fallback/error reasons when runtime execution is unavailable</li>
</ul>
</li>
<li>TensorRT runtime execution path is now implemented:<ul>
<li>new <code>TensorRTEngineExecutor</code> in <code>apex_x/runtime/tensorrt/executor.py</code></li>
<li>runner executes real TensorRT serialized engine inference when <code>APEXX_TRT_ENGINE_PATH</code> is set</li>
<li>optional runtime env controls:</li>
<li><code>APEXX_TRT_PLUGIN_LIB</code> for plugin shared libraries</li>
<li><code>APEXX_TRT_INPUT_NAME</code> for explicit input tensor selection</li>
<li><code>APEXX_TRT_PRIMARY_OUTPUT_NAME</code> for primary output mapping in CLI result schema</li>
<li><code>APEXX_TRT_EXTRA_INPUTS_NPZ</code> for named auxiliary tensors in multi-input TRT engines</li>
<li><code>APEXX_TRT_DET_BOXES_NAME</code>, <code>APEXX_TRT_DET_SCORES_NAME</code>,
    <code>APEXX_TRT_DET_CLASS_IDS_NAME</code>, <code>APEXX_TRT_DET_VALID_NAME</code>
    for explicit DET output binding into CLI det schema</li>
</ul>
</li>
<li>TensorRT deployment shape-sweep harness was added:<ul>
<li><code>apex_x/bench/trt_engine_sweep.py</code></li>
<li>supports repeated shape cases for single/multi-input engines</li>
<li>emits JSON + Markdown sweep summary for per-shape TRT runtime evidence</li>
</ul>
</li>
<li>runtime metadata now explicitly includes:<ul>
<li>requested backend</li>
<li>selected backend</li>
<li>actual execution backend</li>
<li>precision profile</li>
<li>selection/execution fallback reasons</li>
<li>latency breakdown (<code>total</code>, <code>backend_execute</code>, <code>backend_preflight</code>)</li>
<li>runtime capability snapshot</li>
</ul>
</li>
<li>Eval dataset adapter path was added:</li>
<li><code>apex_x/infer/runner.py</code> now includes:<ul>
<li><code>load_eval_images_npz(...)</code></li>
<li><code>load_eval_dataset_npz(...)</code></li>
<li><code>evaluate_model_dataset(...)</code></li>
<li><code>ModelDatasetEvalSummary</code></li>
</ul>
</li>
<li><code>apex_x/cli.py eval</code> now accepts:<ul>
<li><code>--dataset-npz</code> for <code>.npz/.npy</code> image arrays</li>
<li><code>--max-samples</code> for deterministic subset evaluation</li>
</ul>
</li>
<li>when dataset eval is enabled, reports include <code>model_eval</code> aggregates in JSON/Markdown</li>
<li>optional dataset target contract:<ul>
<li><code>.npz</code> key <code>det_score_target</code> (or compat alias <code>det_scores_target</code>)</li>
<li><code>.npz</code> key <code>selected_tiles_target</code> (or compat alias <code>selected_tiles_targets</code>)</li>
<li>model-eval report now includes target regression metrics:</li>
<li><code>det_score_target</code>: <code>mae</code>, <code>rmse</code>, <code>bias</code>, <code>r2</code>, <code>pearson_corr</code></li>
<li><code>selected_tiles_target</code>: <code>mae</code>, <code>rmse</code>, <code>bias</code>, <code>exact_match_rate</code></li>
</ul>
</li>
<li>eval JSON reports now always include <code>runtime</code> metadata for backend/precision/fallback traceability</li>
<li>Export/TRT handoff integration was added:</li>
<li><code>apex_x/runtime/tensorrt/builder.py</code> now provides:<ul>
<li><code>load_export_manifest(...)</code></li>
<li><code>TensorRTEngineBuilder.build_from_export_manifest(...)</code></li>
</ul>
</li>
<li>manifest loader validates ONNX path and optional SHA256 integrity before build handoff</li>
</ul>
<h2 id="current-architecture-snapshot">Current Architecture Snapshot</h2>
<ul>
<li>Dual-stream concept established in docs (PV dense + FF sparse)</li>
<li>Utility-based router contracts defined</li>
<li>Continuous and deterministic budgeting contracts defined</li>
<li>Quadtree nesting policy defined (<code>L0/L1/L2</code>)</li>
<li>TilePack/TileUnpack and ordering contracts defined</li>
<li>Tile-SSM placeholder behavior defined</li>
</ul>
<h2 id="what-exists-right-now-2026-02-07">What Exists Right Now (2026-02-07)</h2>
<ul>
<li>Repository scaffold created:</li>
<li><code>apex_x/</code>, <code>tests/</code>, <code>docs/</code>, <code>docs/runtime/</code>, <code>examples/</code>, <code>scripts/</code>, <code>runtime/</code>, <code>.github/workflows/</code></li>
<li>Governance/Open-source files added:</li>
<li><code>LICENSE</code>, <code>CODE_OF_CONDUCT.md</code>, <code>CONTRIBUTING.md</code>, <code>SECURITY.md</code></li>
<li>Authoritative docs added/updated:</li>
<li><code>docs/PRD.md</code> (full)</li>
<li><code>docs/ENGINEERING_SPEC.md</code> (full)</li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li>CPU baseline code added:</li>
<li><code>apex_x/config/schema.py</code></li>
<li><code>apex_x/routing/core.py</code></li>
<li><code>apex_x/tiles/ops.py</code></li>
<li><code>apex_x/utils/ssm.py</code></li>
<li><code>apex_x/model/core.py</code></li>
<li>Validation assets added:</li>
<li><code>tests/test_router.py</code></li>
<li><code>tests/test_tile_ops.py</code></li>
<li><code>tests/test_model.py</code></li>
<li><code>scripts/perf_regression.py</code></li>
<li><code>.github/workflows/ci.yml</code></li>
<li>Tooling and developer workflow baseline:</li>
<li><code>pyproject.toml</code> now targets <code>python&gt;=3.11</code></li>
<li>runtime deps: <code>torch</code>, <code>numpy</code>, <code>typer</code>, <code>rich</code>, <code>pydantic</code></li>
<li>dev deps/tools: <code>pytest</code>, <code>ruff</code>, <code>black</code>, <code>mypy</code>, <code>pre-commit</code></li>
<li>pre-commit hooks: <code>.pre-commit-config.yaml</code></li>
<li>CI now runs lint + typecheck + tests on <code>ubuntu-latest</code> with CPU torch index</li>
<li>Package skeleton and public API surfaces:</li>
<li>Created package layout: <code>apex_x/config/</code>, <code>apex_x/model/</code>, <code>apex_x/tiles/</code>, <code>apex_x/routing/</code>, <code>apex_x/losses/</code>, <code>apex_x/train/</code>, <code>apex_x/infer/</code>, <code>apex_x/data/</code>, <code>apex_x/export/</code>, <code>apex_x/bench/</code>, <code>apex_x/runtime/</code>, <code>apex_x/utils/</code></li>
<li>Root API now exports required surfaces in <code>apex_x/__init__.py</code>:<ul>
<li><code>ApexXConfig</code>, <code>ApexXModel</code></li>
<li><code>Router</code>, <code>BudgetController</code></li>
<li><code>TilePack</code>, <code>TileUnpack</code></li>
<li><code>Exporter</code></li>
</ul>
</li>
<li>Added import smoke coverage in <code>tests/test_import_smoke.py</code></li>
<li>Migrated baseline code into package modules and removed legacy flat modules to avoid namespace ambiguity</li>
<li>Nested configuration system implemented:</li>
<li>New nested config domains in <code>apex_x/config/schema.py</code>:<ul>
<li><code>ModelConfig</code> (profiles, channels, strides, tile sizes, Kmax, nesting depth)</li>
<li><code>RoutingConfig</code> (budgets B/B1/B2/B3, costs, hysteresis/split thresholds)</li>
<li><code>TrainConfig</code> (curriculum, dual-<code>mu</code> parameters, distill weights, PCGrad++, QAT toggles)</li>
<li><code>DataConfig</code> (COCO paths and augmentation knobs)</li>
<li><code>RuntimeConfig</code> (precision profile, export/runtime toggles)</li>
</ul>
</li>
<li>Top-level <code>ApexXConfig</code> now nests all sections and performs cross-section validation</li>
<li>Added YAML + CLI-style override support in <code>apex_x/config/io.py</code>:<ul>
<li><code>load_yaml_config(path, overrides=...)</code></li>
<li><code>apply_overrides(cfg, [\"section.key=value\", ...])</code></li>
</ul>
</li>
<li>Added config validation test coverage in <code>tests/test_config.py</code> + fixture <code>tests/fixtures/apex_x_config.yaml</code></li>
<li>Updated model to consume nested config fields in <code>apex_x/model/core.py</code></li>
<li>Added <code>PyYAML</code> + <code>types-PyYAML</code> to project dependencies for runtime + typing support</li>
<li>Reproducibility and logging utilities implemented:</li>
<li>Added <code>apex_x/utils/repro.py</code>:<ul>
<li><code>seed_all()</code></li>
<li><code>set_deterministic_mode()</code></li>
<li><code>deterministic_mode()</code> context manager</li>
<li><code>get_determinism_state()</code></li>
<li><code>reproducibility_notes()</code> (CPU vs CUDA behavior notes)</li>
</ul>
</li>
<li>Added <code>apex_x/utils/logging.py</code>:<ul>
<li><code>configure_logging()</code></li>
<li><code>get_logger()</code> shared <code>apex_x.*</code> logger namespace</li>
<li><code>log_event()</code> structured key/value logging with <code>rich</code></li>
</ul>
</li>
<li>Wired shared logger usage in:<ul>
<li><code>apex_x/config/io.py</code></li>
<li><code>apex_x/model/core.py</code></li>
</ul>
</li>
<li>Added determinism tests in <code>tests/test_repro.py</code></li>
<li>CLI surface implemented:</li>
<li>Added Typer CLI entrypoint in <code>apex_x/cli.py</code> with commands:<ul>
<li><code>apex-x train</code></li>
<li><code>apex-x eval</code></li>
<li><code>apex-x predict</code></li>
<li><code>apex-x bench</code></li>
<li><code>apex-x ablate</code></li>
<li><code>apex-x export</code></li>
</ul>
</li>
<li>All commands load config via YAML and support repeated <code>--set section.key=value</code> overrides</li>
<li>Added console script entrypoint in <code>pyproject.toml</code>:<ul>
<li><code>[project.scripts] apex-x = \"apex_x.cli:main\"</code></li>
</ul>
</li>
<li>Added CLI parsing/behavior tests in <code>tests/test_cli.py</code></li>
<li>Documentation scaffold implemented:</li>
<li>Added MkDocs config in <code>mkdocs.yml</code></li>
<li>Added docs home page in <code>docs/index.md</code> linking PRD/spec/runtime/context/decisions/TODO</li>
<li>Added docs build instructions in <code>docs/index.md</code> and <code>README.md</code></li>
<li>Added docs dependency group in <code>pyproject.toml</code>:<ul>
<li><code>.[docs]</code> with <code>mkdocs</code></li>
</ul>
</li>
<li>Added CI docs build job in <code>.github/workflows/ci.yml</code> running:<ul>
<li><code>mkdocs build --strict</code></li>
</ul>
</li>
<li>Protocol typing standardization implemented:</li>
<li>Added explicit protocol names and aliases for consistency:<ul>
<li><code>RouterProtocol</code></li>
<li><code>BudgetControllerProtocol</code></li>
<li><code>TilePackerProtocol</code></li>
<li><code>RuntimeAdapterProtocol</code></li>
</ul>
</li>
<li>Kept backward-compatible aliases in existing modules (<code>Router</code>, <code>BudgetController</code>, <code>TilePack</code>, etc.)</li>
<li>Added runtime adapter interface + reference adapter:<ul>
<li><code>apex_x/runtime/interfaces.py</code></li>
<li><code>apex_x/runtime/adapters.py</code> (<code>NullRuntimeAdapter</code>)</li>
</ul>
</li>
<li>Updated model typing to consume protocol-based interfaces in <code>apex_x/model/core.py</code></li>
<li>Added minimal protocol-conformance tests:<ul>
<li><code>tests/test_protocols.py</code></li>
</ul>
</li>
<li>Updated import-smoke expectations in <code>tests/test_import_smoke.py</code></li>
<li>CPU smoke example added:</li>
<li>Added <code>examples/smoke_cpu.py</code> that:<ul>
<li>loads YAML config</li>
<li>instantiates <code>ApexXModel</code> stub</li>
<li>runs one forward pass on random input</li>
</ul>
</li>
<li>Added <code>examples/smoke_cpu.yaml</code> default config for fast CPU smoke runs</li>
<li>Added <code>tests/test_smoke_cpu_example.py</code> as a quick smoke pytest</li>
<li>Documentation governance updates:</li>
<li>Added initial convention ADRs in <code>docs/DECISIONS.md</code> for:<ul>
<li>naming conventions</li>
<li>tensor shape contracts</li>
<li>determinism rules</li>
</ul>
</li>
<li>Expanded <code>docs/TODO.md</code> with known future implementation tracks:<ul>
<li>full Triton fused kernels</li>
<li>full TensorRT plugin stack</li>
<li>ONNX Runtime custom-op sparse path and parity gates</li>
</ul>
</li>
<li>Strengthened <code>CONTRIBUTING.md</code> policy to require:<ul>
<li><code>docs/CONTEXT.md</code> update in every significant PR</li>
<li><code>docs/DECISIONS.md</code> update when architectural/convention decisions change</li>
</ul>
</li>
<li>L0 tiling mapping implemented and validated:</li>
<li>Added <code>apex_x/tiles/mapping.py</code> with explicit L0 mapping API:<ul>
<li><code>l0_grid_shape(feature_h, feature_w, tile_size)</code> with strict divisibility checks</li>
<li><code>l0_tile_to_index(ty, tx, grid_h, grid_w)</code> and <code>l0_index_to_tile(index, grid_h, grid_w)</code> with bounds checks</li>
<li>batched helpers:</li>
<li><code>l0_indices_to_coords(indices[B,K], grid_h, grid_w) -&gt; coords[B,K,2]</code></li>
<li><code>l0_coords_to_indices(coords[B,K,2], grid_h, grid_w) -&gt; indices[B,K]</code></li>
</ul>
</li>
<li>Wired tile ops grid sizing to strict mapping validation:<ul>
<li><code>apex_x/tiles/ops.py::tile_grid_shape</code> now uses <code>l0_grid_shape(...)</code></li>
</ul>
</li>
<li>Exported mapping API through <code>apex_x/tiles/__init__.py</code></li>
<li>Added focused tests in <code>tests/test_tile_mapping.py</code>:<ul>
<li>index/coord bijection</li>
<li>batched <code>[B,K]</code> roundtrip</li>
<li>invalid size/divisibility</li>
<li>out-of-bounds and shape/dtype validation</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Hilbert ordering implemented for coordinates and indices:</li>
<li>Added <code>apex_x/tiles/ordering.py</code> with explicit Hilbert APIs:<ul>
<li><code>hilbert_distance(tx, ty, order_n)</code></li>
<li><code>hilbert_order_coords(grid_h, grid_w)</code> for full-grid coordinate traversal</li>
<li><code>hilbert_order_indices(indices, grid_h, grid_w)</code> for subset index ordering</li>
<li><code>hilbert_full_indices(grid_h, grid_w)</code> for complete index traversal</li>
</ul>
</li>
<li>Updated <code>apex_x/tiles/ops.py</code>:<ul>
<li><code>order_idx(..., mode=\"hilbert\")</code> now uses <code>hilbert_order_indices(...)</code></li>
</ul>
</li>
<li>Exported ordering APIs from <code>apex_x/tiles/__init__.py</code></li>
<li>Added fixtures:<ul>
<li><code>tests/fixtures/hilbert_2x2.json</code></li>
<li><code>tests/fixtures/hilbert_4x4.json</code></li>
<li><code>tests/fixtures/hilbert_8x8.json</code></li>
</ul>
</li>
<li>Added fixture-driven tests in <code>tests/test_tile_hilbert.py</code>:<ul>
<li>exact traversal match vs fixtures</li>
<li>determinism across repeated calls</li>
<li>full coverage of all coordinates/indices</li>
<li>subset index ordering stability + parity with <code>order_idx(..., mode=\"hilbert\")</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Scan ordering variants and stable dispatcher implemented:</li>
<li>Extended <code>apex_x/tiles/ordering.py</code> with scan modes and dispatcher utilities:<ul>
<li>Scan variants: <code>l2r</code>, <code>r2l</code>, <code>u2d</code>, <code>d2u</code></li>
<li>Stable dispatcher: <code>order_tile_indices(indices, grid_h, grid_w, mode=...)</code></li>
<li>Mode normalization and aliases: <code>normalize_order_mode(...)</code></li>
<li>supports <code>scan_lr/scan_rl/scan_ud/scan_du</code> + short aliases + canonical names</li>
<li>Scan inverse mapping helper: <code>inverse_scan_mode(...)</code></li>
<li>Explicit scan ordering APIs:</li>
<li><code>scan_order_coords(grid_h, grid_w, mode)</code></li>
<li><code>scan_order_indices(indices, grid_h, grid_w, mode)</code></li>
</ul>
</li>
<li>Updated <code>apex_x/tiles/ops.py</code>:<ul>
<li><code>order_idx(...)</code> now delegates to <code>order_tile_indices(...)</code> (single path for ordering semantics)</li>
</ul>
</li>
<li>Exported new ordering APIs from <code>apex_x/tiles/__init__.py</code></li>
<li>Added tests in <code>tests/test_tile_scan_ordering.py</code>:<ul>
<li>deterministic ordering for all scan variants</li>
<li>alias/normalization correctness</li>
<li>stable ordering behavior on duplicate indices</li>
<li>reversible mapping checks:</li>
<li><code>L2R &lt;-&gt; R2L</code> by horizontal mirror</li>
<li><code>U2D &lt;-&gt; D2U</code> by vertical mirror</li>
<li>dispatcher parity with <code>order_idx(...)</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>L0-&gt;L1 quadtree mapping and metadata implemented:</li>
<li>Added <code>apex_x/tiles/quadtree.py</code> with deterministic L0/L1 mapping APIs:<ul>
<li><code>l1_grid_shape_from_l0(l0_grid_h, l0_grid_w)</code></li>
<li><code>l0_l1_grid_shapes_from_feature(feature_h, feature_w, tile_size_l0, tile_size_l1)</code></li>
<li><code>l0_to_l1_children_coords(l0_ty, l0_tx, l0_grid_h, l0_grid_w)</code> (TL, TR, BL, BR order)</li>
<li><code>l0_to_l1_children_indices(l0_index, l0_grid_h, l0_grid_w)</code></li>
<li>reverse mapping:</li>
<li><code>l1_to_l0_parent_coord(l1_ty, l1_tx, l0_grid_h, l0_grid_w)</code></li>
<li><code>l1_to_l0_parent_index(l1_index, l0_grid_h, l0_grid_w)</code></li>
<li>metadata builder:</li>
<li><code>build_l0_l1_quadtree_meta(parent_indices, l0_grid_h, l0_grid_w) -&gt; L0L1QuadtreeMeta</code></li>
</ul>
</li>
<li>Exported new quadtree APIs in <code>apex_x/tiles/__init__.py</code></li>
<li>Added tests in <code>tests/test_tile_quadtree.py</code>:<ul>
<li>boundary tile mapping correctness (bottom-right L0 tile to L1 children)</li>
<li>reverse parent mapping across full L1 grids</li>
<li>multiple config coverage via <code>(feature_h, feature_w, tile_size_l0, tile_size_l1)</code> parametrization</li>
<li>metadata shape/content checks</li>
<li>invalid ratio/divisibility/out-of-bounds validation checks</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>L2 nesting and overlap priority contract implemented:</li>
<li>Extended <code>apex_x/tiles/quadtree.py</code> with L1-&gt;L2 and combined depth-2 utilities:<ul>
<li>grid shapes:</li>
<li><code>l2_grid_shape_from_l1(...)</code></li>
<li><code>l1_l2_grid_shapes_from_feature(...)</code></li>
<li><code>l0_l1_l2_grid_shapes_from_feature(...)</code></li>
<li>mappings:</li>
<li><code>l1_to_l2_children_coords(...)</code>, <code>l1_to_l2_children_indices(...)</code></li>
<li><code>l2_to_l1_parent_coord(...)</code>, <code>l2_to_l1_parent_index(...)</code></li>
<li><code>l0_to_l2_descendant_indices(...)</code></li>
<li>metadata:</li>
<li><code>L1L2QuadtreeMeta</code></li>
<li><code>L0L1L2QuadtreeMeta</code></li>
<li><code>build_l1_l2_quadtree_meta(...)</code></li>
<li><code>build_l0_l1_l2_quadtree_meta(...)</code></li>
</ul>
</li>
<li>Defined explicit overlap priority tags and helper:<ul>
<li><code>OVERLAP_PRIORITY_L0 = 1</code></li>
<li><code>OVERLAP_PRIORITY_L1 = 2</code></li>
<li><code>OVERLAP_PRIORITY_L2 = 3</code></li>
<li><code>overlap_priority_for_level(...)</code></li>
<li>contract enforces <code>L2 &gt; L1 &gt; L0</code></li>
</ul>
</li>
<li>Exported new L2 and priority APIs through <code>apex_x/tiles/__init__.py</code></li>
<li>Added/expanded tests:<ul>
<li><code>tests/test_tile_quadtree.py</code>:</li>
<li>L1-&gt;L2 mapping correctness (including boundary tiles)</li>
<li>L2-&gt;L1 reverse mapping correctness</li>
<li>L0-&gt;L2 descendant index correctness</li>
<li>combined <code>L0/L1/L2</code> metadata consistency</li>
<li>priority tag contract checks</li>
<li>multi-config and validation coverage for depth-2 shapes</li>
<li><code>tests/test_tile_ops.py</code>:</li>
<li>overlap behavior check using unpack priorities confirming <code>L2</code> overrides <code>L1</code> and <code>L0</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Tile selection debug dataclasses implemented:</li>
<li>Added <code>apex_x/tiles/selection.py</code> with:<ul>
<li><code>TileSelection</code></li>
<li>fields: <code>level</code>, <code>indices</code>, <code>ordered_indices</code>, <code>meta</code>, <code>budgets_used</code></li>
<li>validation:<ul>
<li><code>level</code> constrained to <code>l0/l1/l2</code></li>
<li><code>ordered_indices</code> must be a permutation of <code>indices</code></li>
<li>budgets must be finite and non-negative</li>
</ul>
</li>
<li>JSON persistence:<ul>
<li><code>to_dict()/from_dict()</code></li>
<li><code>save_json()/load_json()</code></li>
</ul>
</li>
<li><code>TileSelectionTrace</code> for multi-level selection records</li>
<li>fields: <code>selections</code>, <code>run_meta</code></li>
<li>helpers:<ul>
<li><code>to_dict()/from_dict()</code></li>
<li><code>save_json()/load_json()</code></li>
<li><code>for_level(level)</code></li>
</ul>
</li>
</ul>
</li>
<li>JSON serialization includes recursive normalization of NumPy arrays/scalars for debug/ablation dumps.</li>
<li>Exported APIs via <code>apex_x/tiles/__init__.py</code>:<ul>
<li><code>TileSelection</code></li>
<li><code>TileSelectionTrace</code></li>
</ul>
</li>
<li>Added unit tests in <code>tests/test_tile_selection.py</code>:<ul>
<li>roundtrip dict serialization</li>
<li>file save/load JSON</li>
<li>validation error cases</li>
<li>trace roundtrip and level lookup</li>
<li>non-empty trace guard</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Tile overlay visualization utility implemented:</li>
<li>Added <code>apex_x/utils/visualization.py</code> with dependency-free overlay rendering:<ul>
<li><code>draw_selected_tiles_overlay(...)</code></li>
<li>supports <code>HWC</code>, <code>CHW</code>, and batch-size-1 image inputs</li>
<li>deterministic tile overlay rendering from selected tile indices + grid/tile size</li>
<li>fill + border blending with deterministic integer alpha math</li>
<li><code>save_overlay_ppm(...)</code></li>
<li>saves overlay to <code>.ppm</code> for debug/ablation without extra image libraries</li>
<li><code>draw_and_save_selected_tiles_overlay(...)</code></li>
<li>convenience wrapper combining render + save</li>
</ul>
</li>
<li>Exported visualization utilities through <code>apex_x/utils/__init__.py</code></li>
<li>Added deterministic tests in <code>tests/test_visualization.py</code>:<ul>
<li>overlay output shape/dtype checks</li>
<li>stable SHA256 hash checks for rendered overlay bytes</li>
<li>stable SHA256 hash checks for saved PPM file bytes</li>
<li>save-path extension validation for <code>.ppm</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Cost model interface and reference implementation added:</li>
<li>Extended routing interfaces in <code>apex_x/routing/interfaces.py</code>:<ul>
<li><code>CostModelProtocol</code></li>
<li>backward-compatible alias <code>CostModel</code></li>
</ul>
</li>
<li>Added <code>apex_x/routing/cost_model.py</code>:<ul>
<li><code>LevelCost</code>:</li>
<li>per-level cost terms:<ul>
<li><code>c_cheap (C_c)</code></li>
<li><code>c_heavy (C_h)</code></li>
<li><code>pack_overhead</code></li>
<li><code>unpack_overhead</code></li>
<li><code>split_overhead (O_split)</code></li>
</ul>
</li>
<li><code>CalibrationRecord</code>:</li>
<li>stores empirical calibration measurements, blend factor, and apply flag</li>
<li><code>StaticCostModel</code>:</li>
<li>level-aware cost computations:<ul>
<li><code>cheap_cost(...)</code></li>
<li><code>heavy_cost(...)</code></li>
<li><code>delta_cost(...)</code></li>
<li><code>split_overhead(...)</code></li>
<li><code>expected_level_cost(...)</code></li>
<li><code>total_cost(...)</code></li>
</ul>
</li>
<li>optional empirical calibration hook:<ul>
<li><code>apply_empirical_calibration(level, measured_timings, blend, apply)</code></li>
<li>stores records in <code>calibration_history</code></li>
</ul>
</li>
<li>serialization:<ul>
<li><code>to_dict()/from_dict()</code></li>
<li><code>save_json()/load_json()</code></li>
</ul>
</li>
</ul>
</li>
<li>Exported cost model symbols through:<ul>
<li><code>apex_x/routing/__init__.py</code></li>
<li><code>apex_x/__init__.py</code> (public API now includes <code>CostModel</code>, <code>CostModelProtocol</code>, <code>StaticCostModel</code>)</li>
</ul>
</li>
<li>Added tests in <code>tests/test_cost_model.py</code>:<ul>
<li>deterministic cost computations and totals</li>
<li>calibration update behavior and history storage</li>
<li>JSON serialization roundtrip</li>
<li>validation/error paths</li>
<li>protocol conformance check (<code>isinstance(..., CostModelProtocol)</code>)</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Oracle set sampler implemented (<code>S</code> sampling for utility oracle training):</li>
<li>Added <code>apex_x/routing/oracle_sampling.py</code>:<ul>
<li><code>OracleSetSample</code> dataclass:</li>
<li><code>indices</code></li>
<li><code>random_indices</code></li>
<li><code>uncertainty_indices</code></li>
<li><code>sample_oracle_set(u_hat, random_fraction, uncertainty_fraction, seed)</code>:</li>
<li>random fraction sampling over all tiles</li>
<li>uncertainty-biased sampling over remaining tiles using PV uncertainty <code>u_hat</code></li>
<li>deterministic behavior under fixed seed</li>
</ul>
</li>
<li>Exported sampler APIs through <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>OracleSetSample</code></li>
<li><code>sample_oracle_set</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_oracle_sampling.py</code>:<ul>
<li>seed determinism checks</li>
<li>count/uniqueness checks for random + uncertainty components</li>
<li>uncertainty-biased distribution check across many seeds</li>
<li>validation/error checks for fraction bounds and invalid uncertainty values</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passedprodoljai</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Stable tie-breaking helper for selections implemented:</li>
<li>Updated <code>apex_x/routing/core.py</code>:<ul>
<li>added <code>stable_rank_tile_ids(scores)</code> with deterministic ordering policy:</li>
<li>primary key: score descending</li>
<li>secondary key: tile id ascending</li>
<li>wired <code>greedy_utility_per_cost(...)</code> to use <code>stable_rank_tile_ids(...)</code> for score-ratio ranking</li>
</ul>
</li>
<li>Exported helper via <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>stable_rank_tile_ids</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_router.py</code>:<ul>
<li>explicit tie-break behavior validation</li>
<li>repeat-run determinism checks</li>
<li>integration check that greedy selection follows stable tie-breaking under equal utility/cost ratios</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>PV-&gt;FF tile vector aggregation implemented:</li>
<li>Added <code>apex_x/routing/aggregation.py</code>:<ul>
<li><code>compute_ff_tile_bounds_on_pv_grid(...)</code></li>
<li>computes PV-aligned bounds for each FF tile on coarse PV maps</li>
<li><code>aggregate_pv_maps_to_ff_tile_vectors(...)</code></li>
<li>pools per-tile stats from PV maps aligned to FF grid</li>
<li>supported stats: <code>mean</code>, <code>max</code>, <code>var</code></li>
<li>deterministic feature ordering using sorted PV map names</li>
<li><code>PVTileAggregation</code> dataclass:</li>
<li><code>vectors</code> (<code>[B, K, D]</code>)</li>
<li><code>tile_bounds_pv</code> (<code>[K,4]</code>)</li>
<li><code>feature_layout</code> (feature names per channel/stat/map)</li>
</ul>
</li>
<li>Exported aggregation APIs via <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>PVTileAggregation</code></li>
<li><code>compute_ff_tile_bounds_on_pv_grid</code></li>
<li><code>aggregate_pv_maps_to_ff_tile_vectors</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_pv_aggregation.py</code>:<ul>
<li>alignment on simple integer scale mapping</li>
<li>pooled stat correctness (<code>mean/max/var</code>)</li>
<li>output shape and feature layout checks</li>
<li>deterministic outputs across map ordering</li>
<li>non-integer scale edge/boundary alignment</li>
<li>validation error paths</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>RouterTinyMLP implemented with utility/split/temporal outputs:</li>
<li>Added <code>apex_x/routing/tiny_mlp.py</code>:<ul>
<li><code>RouterTinyOutput</code> dataclass carrying per-tile tensors:</li>
<li><code>U</code> (<code>[B,K]</code>) utility logits</li>
<li><code>S</code> (<code>[B,K]</code>) split utility logits</li>
<li>optional <code>T</code> (<code>[B,K]</code>) temporal keep logits</li>
<li><code>RouterTinyMLP(nn.Module)</code>:</li>
<li>configurable <code>input_dim</code>, <code>hidden_dim</code>, <code>num_layers</code>, <code>temporal_head</code></li>
<li>forward contract on <code>x[B,K,D]</code> with strict input validation</li>
<li>compatibility method <code>predict_utilities(...)</code> for <code>RouterProtocol</code> usage (<code>input_dim=1</code>)</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>RouterTinyOutput</code></li>
<li><code>RouterTinyMLP</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_router_tiny_mlp.py</code>:<ul>
<li>shape checks for <code>U/S</code> and optional <code>T</code></li>
<li>deterministic outputs for fixed seed/model initialization</li>
<li>backward/gradient-flow checks through router outputs</li>
<li><code>predict_utilities(...)</code> behavior and validation paths</li>
<li>runtime protocol conformance (<code>isinstance(..., RouterProtocol)</code>)</li>
</ul>
</li>
<li>Minor typing fix to keep strict typecheck green:<ul>
<li><code>apex_x/utils/visualization.py</code> now uses an explicit typed cast in <code>_as_hwc_uint8(...)</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Lightweight spline activation + RouterKANLike implemented:</li>
<li>Added <code>apex_x/routing/kan_like.py</code>:<ul>
<li><code>LightweightSplineActivation</code>:</li>
<li>compact per-feature piecewise-linear spline on fixed knot grid</li>
<li>identity initialization for stable startup</li>
<li>explicit <code>nan/inf</code> sanitization + bounded input clamp</li>
<li><code>RouterKANLike</code>:</li>
<li>small-parameter KAN-like router (<code>LayerNorm -&gt; Linear -&gt; Spline -&gt; Linear</code>)</li>
<li>outputs <code>U</code>, <code>S</code>, and optional <code>T</code> via <code>RouterKANOutput</code></li>
<li>bounded head logits via configurable <code>logit_clip</code></li>
<li>protocol-compatible <code>predict_utilities(...)</code> and <code>parameter_count()</code></li>
</ul>
</li>
<li>Exported via <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>LightweightSplineActivation</code></li>
<li><code>RouterKANOutput</code></li>
<li><code>RouterKANLike</code></li>
</ul>
</li>
<li>Added numerical stability tests in <code>tests/test_router_kan_like.py</code>:<ul>
<li>finite outputs under extreme/nonnumeric input values</li>
<li>finite gradients for spline params and inputs</li>
<li>router output shape + finite output checks at large input magnitudes</li>
<li>deterministic initialization/output checks under fixed seeds</li>
<li>small-parameter-count guard</li>
<li><code>RouterProtocol</code> conformance check</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Tensor STE gating implemented for continuous-budget training path:</li>
<li>Added <code>apex_x/routing/gating.py</code>:<ul>
<li><code>sigmoid_probabilities(U, temperature)</code>:</li>
<li>computes <code>p = sigmoid(U)</code> with temperature support</li>
<li>clamps/sanitizes extreme and non-finite logits for numerical stability</li>
<li><code>ste_hard_gate(p, mode, threshold)</code>:</li>
<li>forward hard gate modes:<ul>
<li><code>threshold</code>: <code>g = 1[p &gt;= threshold]</code></li>
<li><code>bernoulli</code>: <code>g ~ Bernoulli(p)</code></li>
</ul>
</li>
<li>backward straight-through estimator via detach trick (<code>dg/dp = 1</code>)</li>
<li><code>ste_gate_from_utilities(U, ...) -&gt; (p, g)</code> convenience function</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>GateMode</code></li>
<li><code>sigmoid_probabilities</code></li>
<li><code>ste_hard_gate</code></li>
<li><code>ste_gate_from_utilities</code></li>
</ul>
</li>
<li>Added autograd and numerical tests in <code>tests/test_ste_gating.py</code>:<ul>
<li>non-zero and finite gradient checks w.r.t. <code>U</code> in threshold mode</li>
<li>non-zero and finite gradient checks w.r.t. <code>U</code> in Bernoulli mode</li>
<li>explicit gradient-form check against sigmoid derivative under linear loss</li>
<li>finite probability checks under extreme/non-finite utility inputs</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>BudgetDualController implemented for continuous-budget dual optimization:</li>
<li>Added <code>apex_x/routing/dual_budget.py</code>:<ul>
<li><code>BudgetDualController</code> (stateful dual variable controller) with:</li>
<li>expected cost:<ul>
<li><code>E[C] = sum_i(p_i * C_h + (1 - p_i) * C_c)</code> via <code>expected_cost(...)</code></li>
</ul>
</li>
<li>budget term:<ul>
<li><code>L_budget = mu * (E[C] - B)</code> via <code>budget_loss(...)</code></li>
</ul>
</li>
<li>projected/clamped dual update:<ul>
<li><code>mu &lt;- clamp(mu + mu_lr * (E[C] - B), [mu_min, mu_max])</code> via <code>update_mu(...)</code></li>
</ul>
</li>
<li>structured debug logging on each update (<code>event='dual_mu_update'</code>) including:<ul>
<li><code>expected_cost</code>, <code>budget</code>, <code>delta</code>, <code>mu_prev</code>, <code>mu_next</code>, <code>clamped</code></li>
</ul>
</li>
<li>support for both sequence and tensor probabilities in expected-cost path</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>BudgetDualController</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_budget_dual_controller.py</code>:<ul>
<li>expected-cost and budget-loss formula checks</li>
<li><code>mu</code> moves in correct direction (<code>E[C] &gt; B</code> increases, <code>E[C] &lt; B</code> decreases)</li>
<li><code>mu</code> clamp bounds respected (<code>mu_min</code> / <code>mu_max</code>)</li>
<li>tensor-path budget loss backpropagates with finite non-zero gradients</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Deterministic greedy inference budgeting implemented with explicit Kmax buffer contract:</li>
<li>Added <code>apex_x/routing/inference_budget.py</code>:<ul>
<li><code>deterministic_greedy_selection(...)</code>:</li>
<li>computes scores exactly as <code>score_i = U_i / DeltaC_i</code></li>
<li>deterministic ordering by:<ul>
<li>primary: score descending</li>
<li>secondary: tile id ascending</li>
</ul>
</li>
<li>selects until budget exhausted and <code>kmax</code> reached</li>
<li>returns <code>GreedySelectionResult</code> with:<ul>
<li><code>selected_indices</code></li>
<li><code>spent_budget</code></li>
<li><code>ordered_candidates</code></li>
<li><code>scores</code></li>
<li><code>kmax_buffer</code> (fixed-length padded buffer)</li>
<li><code>valid_count</code></li>
</ul>
</li>
<li><code>build_kmax_buffer(...)</code> helper for fixed-size runtime buffers</li>
</ul>
</li>
<li>Wired existing public helper to the new deterministic path:<ul>
<li><code>apex_x/routing/core.py::greedy_utility_per_cost(...)</code> now delegates to
  <code>deterministic_greedy_selection(...)</code> and preserves existing return signature</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>GreedySelectionResult</code></li>
<li><code>build_kmax_buffer</code></li>
<li><code>deterministic_greedy_selection</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_inference_budget.py</code>:<ul>
<li>repeat-run determinism for ordering and selections</li>
<li>budget enforcement and <code>kmax</code> cap behavior</li>
<li>stable tie handling (<code>tile_id</code> ascending under equal scores)</li>
<li>Kmax buffer padding/truncation semantics</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Two-stage nesting selection implemented (<code>L0</code> under <code>B1</code>, split under <code>B2</code>):</li>
<li>Extended <code>apex_x/routing/inference_budget.py</code>:<ul>
<li><code>TwoStageSelectionResult</code> dataclass carrying:</li>
<li><code>l0</code> selection result</li>
<li>split parent ordering/selection</li>
<li>spent split budget</li>
<li>generated <code>L1</code> indices</li>
<li>ordered <code>L1</code> indices + fixed-size <code>L1</code> Kmax buffer</li>
<li><code>deterministic_two_stage_selection(...)</code>:</li>
<li>stage 1: deterministic <code>L0</code> selection using <code>U / DeltaC</code> under <code>budget_b1</code> + <code>kmax_l0</code></li>
<li>stage 2: split parent ranking by <code>S / O_split</code> under <code>budget_b2</code></li>
<li>expands selected <code>L0</code> parents to <code>L1</code> children via quadtree mapping</li>
<li>enforces <code>kmax_l1</code> capacity during split expansion</li>
<li>applies deterministic <code>L1</code> ordering via configured order mode (Hilbert/scan)</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>TwoStageSelectionResult</code></li>
<li><code>deterministic_two_stage_selection</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_two_stage_selection.py</code>:<ul>
<li><code>L0</code> selection under <code>B1</code></li>
<li>split candidate selection under <code>B2</code> with <code>S/O_split</code></li>
<li>deterministic tie handling on split parents (<code>tile_id</code> ascending)</li>
<li><code>L1</code> children generation and ordering behavior</li>
<li>determinism across repeated runs</li>
<li><code>kmax_l1</code> capacity/buffer enforcement</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Temporal hysteresis rollout and toggle analysis implemented:</li>
<li>Extended <code>apex_x/routing/core.py</code> hysteresis APIs:<ul>
<li><code>hysteresis_update(...)</code> now validates:</li>
<li><code>theta_on &gt; theta_off</code></li>
<li>equal lengths for <code>utilities_t</code> and <code>prev_mask</code></li>
<li>added <code>hysteresis_rollout(...)</code>:</li>
<li>applies rule over full time sequence with carried <code>z(t-1)</code> state</li>
<li>added <code>count_mask_toggles(...)</code>:</li>
<li>counts total 0/1 transitions across time (for anti-flicker evaluation)</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>hysteresis_rollout</code></li>
<li><code>count_mask_toggles</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_hysteresis_temporal.py</code>:<ul>
<li>deadband behavior preserves previous mask state (<code>z(t-1)</code>) when utility remains between thresholds</li>
<li>synthetic noisy sequence shows reduced toggling vs single-threshold baseline</li>
<li>validation/error-path checks for threshold ordering and shape consistency</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Routing diagnostics implemented and surfaced in model/train/infer paths:</li>
<li>Added <code>apex_x/routing/diagnostics.py</code>:<ul>
<li><code>utility_histogram(...)</code> for per-level utility histogram summaries</li>
<li><code>build_routing_diagnostics(...)</code> producing:</li>
<li>selected ratios/counts per level</li>
<li>utility histograms per level</li>
<li>budget usage (<code>used</code>, <code>budget</code>, <code>ratio</code>)</li>
<li>dual variable history (<code>mu_history</code>)</li>
</ul>
</li>
<li>Exported diagnostics APIs through <code>apex_x/routing/__init__.py</code></li>
<li>Integrated diagnostics into <code>apex_x/model/core.py</code>:<ul>
<li>model outputs now include <code>routing_diagnostics</code></li>
<li>dual controller (<code>BudgetDualController</code>) state tracked in <code>mu_history</code></li>
<li>optional dual update path enabled via <code>forward(..., update_dual=True)</code></li>
<li>structured logs now include selected ratio, budget usage ratio, and latest <code>mu</code></li>
</ul>
</li>
<li>Updated <code>apex_x/train/__init__.py</code> and <code>apex_x/infer/__init__.py</code>:<ul>
<li>train placeholder logs/returns routing diagnostics summary fields</li>
<li>infer placeholder returns diagnostics from model outputs</li>
</ul>
</li>
<li>Updated CLI integration in <code>apex_x/cli.py</code>:<ul>
<li><code>train</code> now performs short warmup forwards with dual updates and reports diagnostics</li>
<li><code>predict</code> now reads infer diagnostics and logs budget usage ratio</li>
</ul>
</li>
<li>Added tests in <code>tests/test_routing_diagnostics.py</code>:<ul>
<li>diagnostics presence in inference outputs</li>
<li>diagnostics propagation through train/infer placeholders</li>
<li><code>mu_history</code> progression when dual updates are enabled</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Config-driven feature toggles added for forced-off routing/training paths:</li>
<li>Extended <code>apex_x/config/schema.py</code>:<ul>
<li><code>ModelConfig</code> toggles:</li>
<li><code>force_dense_routing</code> (router off =&gt; dense tile activation)</li>
<li><code>disable_nesting</code> (effective nesting depth forced to 0)</li>
<li><code>disable_ssm</code> (bypass Tile-SSM mixing)</li>
<li><code>TrainConfig</code> toggles:</li>
<li><code>disable_distill</code></li>
<li><code>disable_pcgradpp</code></li>
<li>Added helper methods:</li>
<li><code>ModelConfig.effective_nesting_depth()</code></li>
<li><code>ModelConfig.router_enabled()</code></li>
<li><code>ModelConfig.ssm_enabled()</code></li>
<li><code>TrainConfig.distill_enabled()</code></li>
<li><code>TrainConfig.pcgradpp_enabled()</code></li>
<li>Validation updated so <code>disable_nesting=true</code> can force nesting off without requiring manual <code>kmax_l1/l2</code> and <code>budget_b3</code> cleanup.</li>
</ul>
</li>
<li>Updated <code>apex_x/model/core.py</code> runtime behavior:<ul>
<li>router-off mode forces dense <code>L0</code> selection and skips budget controller routing selection</li>
<li>no-SSM mode bypasses <code>tile_ssm_scan(...)</code> and uses zero modulation/state</li>
<li>no-nesting mode uses effective depth for diagnostics totals (<code>L1/L2</code> counts become zero)</li>
<li>output now includes <code>feature_toggles</code> summary for debug/smoke assertions</li>
</ul>
</li>
<li>Updated <code>apex_x/train/__init__.py</code> + <code>apex_x/cli.py</code>:<ul>
<li>train placeholder now accepts config and reports effective distill/PCGrad++ enabled flags</li>
<li>CLI <code>train</code> passes config through to preserve toggle behavior in logs/output paths</li>
</ul>
</li>
<li>Added smoke coverage:<ul>
<li><code>tests/test_feature_toggle_smoke.py</code></li>
<li>validates override behavior for <code>disable_nesting</code></li>
<li>executes all <code>2^5=32</code> toggle combinations:<ul>
<li>router off / on</li>
<li>no nesting / nesting</li>
<li>no SSM / SSM</li>
<li>no distill / distill</li>
<li>no PCGrad++ / PCGrad++</li>
</ul>
</li>
<li>asserts forward + train placeholder run without crashes and toggle semantics hold</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Torch tile packer implemented with contiguous output contract:</li>
<li>Added <code>apex_x/tiles/torch_ops.py</code>:<ul>
<li><code>TilePackTorch.pack(...)</code>:</li>
<li>input: <code>F[B,C,H,W]</code>, <code>idx[B,K]</code>, <code>tile_size</code></li>
<li>output: <code>P[B,K,C,t,t]</code>, <code>meta</code></li>
<li>deterministic ordering via shared ordering dispatcher (<code>order_idx(...)</code>)</li>
<li>strict shape/dtype/bounds validation</li>
<li>guarantees contiguous packed tensor via <code>.contiguous()</code></li>
<li><code>pack_tiles_torch(...)</code> convenience wrapper</li>
<li><code>TorchTileMeta</code> type alias (<code>dict[str, torch.Tensor]</code>)</li>
</ul>
</li>
<li>Exported through <code>apex_x/tiles/__init__.py</code>:<ul>
<li><code>TorchTileMeta</code></li>
<li><code>TilePackTorch</code></li>
<li><code>pack_tiles_torch</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_tile_pack_torch.py</code>:<ul>
<li>correctness vs NumPy reference <code>pack_tiles(...)</code></li>
<li>contiguous output assertion</li>
<li>autograd gradient-flow check from packed output back to source feature map</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check ...</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_tile_pack_torch.py tests/test_tile_ops.py</code> passed</li>
</ul>
</li>
<li>Torch tile unpacker implemented with overlap priority modes:</li>
<li>Extended <code>apex_x/tiles/torch_ops.py</code>:<ul>
<li><code>TileUnpackTorch.unpack(...)</code>:</li>
<li>input: <code>base_map[B,C,H,W]</code>, <code>packed_out[B,K,C,t,t]</code>, <code>meta</code>, <code>level_priority</code>, optional <code>priority_map</code></li>
<li>overlap modes:<ul>
<li><code>override</code>: incoming tile values replace existing values where priority allows</li>
<li><code>blend</code>: weighted fusion <code>out = (1-alpha)*current + alpha*incoming</code> where priority allows</li>
</ul>
</li>
<li>priority contract preserved via per-pixel <code>priority_map</code> updates</li>
<li>strict validation for tensor ranks/shapes, bounds, and mode/alpha values</li>
<li><code>unpack_tiles_torch(...)</code> convenience wrapper</li>
<li><code>OverlapMode</code> type alias</li>
</ul>
</li>
<li>Exported through <code>apex_x/tiles/__init__.py</code>:<ul>
<li><code>OverlapMode</code></li>
<li><code>TileUnpackTorch</code></li>
<li><code>unpack_tiles_torch</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_tile_unpack_torch.py</code>:<ul>
<li>override-mode parity vs NumPy <code>unpack_tiles(...)</code></li>
<li>overlap priority enforcement and blend-mode numeric behavior</li>
<li>autograd gradient-flow checks for blend mode (<code>base</code> and <code>packed_out</code>)</li>
<li>helper/function parity (<code>TileUnpackTorch().unpack</code> vs <code>unpack_tiles_torch</code>)</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/tiles/torch_ops.py apex_x/tiles/__init__.py tests/test_tile_unpack_torch.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_tile_pack_torch.py tests/test_tile_unpack_torch.py tests/test_tile_ops.py</code> passed</li>
</ul>
</li>
<li>Fusion gate implemented with boundary/uncertainty-conditioned alpha:</li>
<li>Added <code>apex_x/model/fusion_gate.py</code>:<ul>
<li><code>FusionGate(nn.Module)</code> computes spatial gate:</li>
<li><code>alpha [B,1,H,W] = sigmoid(w_b * boundary_proxy + w_u * uncertainty_proxy + bias)</code></li>
<li>positive monotonic proxy weights enforced via <code>softplus(...)</code></li>
<li>outputs fused features:</li>
<li><code>fused = base + alpha * (heavy - base)</code></li>
<li>validates proxy shape contracts and aligns proxies to feature dtype/device</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>FusionGate</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_fusion_gate.py</code>:<ul>
<li>alpha shape/range and fusion formula correctness</li>
<li>sensitivity checks: increasing boundary/uncertainty proxies increases mean alpha</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/fusion_gate.py tests/test_fusion_gate.py apex_x/model/__init__.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_fusion_gate.py</code> passed</li>
</ul>
</li>
<li>Cheap block implemented (<code>1x1 + norm + ReGLU + optional residual</code>):</li>
<li>Added <code>apex_x/model/cheap_block.py</code>:<ul>
<li><code>CheapBlock(nn.Module)</code>:</li>
<li>path: <code>Conv2d(1x1) -&gt; GroupNorm -&gt; ReGLU</code></li>
<li>optional residual add</li>
<li>automatic residual projection (<code>1x1</code>) when <code>in_channels != out_channels</code></li>
<li>validation for input channels and normalization group divisibility</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>CheapBlock</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_cheap_block.py</code>:<ul>
<li>shape checks with residual projection path</li>
<li>residual identity behavior when main path is zeroed</li>
<li>no-residual zero-output behavior when main path is zeroed</li>
<li>gradient-flow checks for input and block parameters</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/cheap_block.py apex_x/model/__init__.py tests/test_cheap_block.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_cheap_block.py tests/test_model.py</code> passed</li>
</ul>
</li>
<li>Tile refine block implemented for packed tiles:</li>
<li>Added <code>apex_x/model/tile_refine_block.py</code>:<ul>
<li><code>TileRefineBlock(nn.Module)</code> operating on packed tensors <code>[B,K,C,t,t]</code></li>
<li>local refine path per tile:</li>
<li>depthwise conv (<code>k x k</code>)</li>
<li>pointwise conv</li>
<li><code>GroupNorm</code></li>
<li>ReGLU activation</li>
<li>optional residual (with automatic projection when channels differ)</li>
<li>implementation flattens <code>B*K</code> for conv processing and restores <code>[B,K,...]</code>, preserving per-tile independence</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>TileRefineBlock</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_tile_refine_block.py</code>:<ul>
<li>shape/projection path checks</li>
<li>residual identity when main path is zeroed</li>
<li>per-tile independence (no cross-tile mixing)</li>
<li>gradient-flow checks for inputs and parameters</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/tile_refine_block.py apex_x/model/__init__.py tests/test_tile_refine_block.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_tile_refine_block.py tests/test_cheap_block.py</code> passed</li>
</ul>
</li>
<li>PV backbone implemented with P3/P4/P5 feature outputs:</li>
<li>Added <code>apex_x/model/pv_backbone.py</code>:<ul>
<li><code>PVBackbone(nn.Module)</code> returning feature dict:</li>
<li><code>P3</code> (stride 8)</li>
<li><code>P4</code> (stride 16)</li>
<li><code>P5</code> (stride 32)</li>
<li>uses lightweight staged downsampling + <code>CheapBlock</code> refinement per level</li>
<li>validates input shape/channel contract and minimum spatial size</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>PVBackbone</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_pv_backbone.py</code>:<ul>
<li>parameterized shape checks across multiple input sizes</li>
<li>gradient-flow check</li>
<li>input validation checks</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/pv_backbone.py apex_x/model/__init__.py tests/test_pv_backbone.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_pv_backbone.py</code> passed</li>
</ul>
</li>
<li>PV coarse heads implemented with explicit uncertainty proxy definition:</li>
<li>Added <code>apex_x/model/pv_coarse_heads.py</code>:<ul>
<li><code>PVCoarseHeads(nn.Module)</code> producing coarse PV maps from a selected backbone level (default <code>P4</code>):</li>
<li><code>objectness_logits</code></li>
<li><code>objectness = sigmoid(objectness_logits)</code></li>
<li><code>boundary_proxy = sigmoid(boundary_logits)</code></li>
<li><code>variance_proxy = softplus(variance_logits)</code></li>
<li><code>uncertainty_proxy</code></li>
<li>clear uncertainty definition:</li>
<li><code>u_hat = 4 * p * (1 - p)</code> where <code>p = objectness</code></li>
<li>normalized Bernoulli variance (<code>u_hat=1</code> at <code>p=0.5</code>, <code>u_hat=0</code> at <code>p in {0,1}</code>)</li>
<li>output typed via <code>PVCoarseOutput</code> dataclass</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>PVCoarseHeads</code></li>
<li><code>PVCoarseOutput</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_pv_coarse_heads.py</code>:<ul>
<li>parameterized shape/range checks across multiple image sizes (via <code>PVBackbone</code> + <code>P4</code>)</li>
<li>uncertainty sensitivity checks with controlled objectness logits</li>
<li>direct uncertainty formula parity check</li>
<li>gradient-flow check through backbone + heads</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/pv_coarse_heads.py apex_x/model/__init__.py tests/test_pv_coarse_heads.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_pv_coarse_heads.py</code> passed</li>
</ul>
</li>
<li>PV module wired with backbone + coarse heads:</li>
<li>Added <code>apex_x/model/pv_module.py</code>:<ul>
<li><code>PVModule</code> composes:</li>
<li><code>PVBackbone</code> for <code>P3/P4/P5</code> feature extraction</li>
<li><code>PVCoarseHeads</code> for coarse proxies</li>
<li><code>PVModule.forward()</code> now returns <code>PVModuleOutput</code> containing:</li>
<li><code>features</code> dict (<code>P3/P4/P5</code>)</li>
<li><code>coarse</code> maps from selected level (<code>coarse_level</code>: <code>P3</code>/<code>P4</code>/<code>P5</code>)</li>
<li><code>proxy_maps</code> dict for routing-facing signals:<ul>
<li><code>objectness</code></li>
<li><code>uncertainty</code></li>
<li><code>boundary</code></li>
<li><code>variance</code></li>
</ul>
</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>PVModule</code></li>
<li><code>PVModuleOutput</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_pv_module.py</code>:<ul>
<li>shape checks across multiple input sizes</li>
<li>coarse-level selection checks (<code>P3</code> vs <code>P5</code>)</li>
<li><code>proxy_maps</code> key/shape checks</li>
<li>finite-output assertions</li>
</ul>
</li>
<li>Added dedicated CPU smoke test in <code>tests/test_pv_module_smoke_cpu.py</code>:<ul>
<li>validates CPU forward path and proxy-map outputs are finite with expected shapes</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/pv_module.py apex_x/model/__init__.py tests/test_pv_module.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_pv_module.py tests/test_pv_module_smoke_cpu.py tests/test_pv_backbone.py tests/test_pv_coarse_heads.py</code> passed</li>
</ul>
</li>
<li>Stable state-space-like scan implemented with constrained parameters:</li>
<li>Extended <code>apex_x/utils/ssm.py</code>:<ul>
<li><code>StableStateSpaceScan(nn.Module)</code> with constrained recurrent parameters:</li>
<li>decay constrained to <code>(min_decay, max_decay)</code> via sigmoid mapping</li>
<li>positive input/output gains via softplus</li>
<li>numerically safe token sanitization/clamp path</li>
<li><code>SSMScanStats</code> for explicit scan complexity accounting:</li>
<li><code>steps</code></li>
<li><code>recurrent_updates</code></li>
<li><code>pairwise_updates</code></li>
<li><code>tile_ssm_scan(...)</code> now clamps alpha to stable bounds</li>
</ul>
</li>
<li>Exported in <code>apex_x/utils/__init__.py</code>:<ul>
<li><code>StableStateSpaceScan</code></li>
<li><code>SSMScanStats</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_stable_ssm_scan.py</code>:<ul>
<li>no-NaN/finite checks on extreme inputs</li>
<li>gradient-flow checks for inputs and scan parameters</li>
<li>O(K) behavior checks via linear recurrent-update accounting and zero pairwise updates</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/utils/ssm.py apex_x/utils/__init__.py tests/test_stable_ssm_scan.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_stable_ssm_scan.py</code> passed</li>
</ul>
</li>
<li>Bidirectional scan and merge gate added on top of stable scan:</li>
<li>Extended <code>apex_x/utils/ssm.py</code>:<ul>
<li><code>StableBidirectionalStateSpaceScan(nn.Module)</code>:</li>
<li>forward-direction stable scan</li>
<li>backward-direction stable scan (reverse sequence + reverse outputs back)</li>
<li>channel-wise constrained merge gate:<ul>
<li><code>gate = sigmoid(merge_gate_logit)</code> in <code>[0,1]</code></li>
<li>merged output: <code>gate * y_fwd + (1 - gate) * y_bwd</code></li>
</ul>
</li>
<li>complexity stats preserved as linear-time recurrent updates (no pairwise updates)</li>
</ul>
</li>
<li>Exported in <code>apex_x/utils/__init__.py</code>:<ul>
<li><code>StableBidirectionalStateSpaceScan</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_bidirectional_ssm_scan.py</code>:<ul>
<li>finite/no-NaN checks with extreme inputs</li>
<li>merge formula correctness vs explicit gate-weighted combination</li>
<li>gradient-flow checks for inputs and parameters (including merge gate path)</li>
<li>O(K) scaling checks from recurrent update counts</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/utils/ssm.py apex_x/utils/__init__.py tests/test_bidirectional_ssm_scan.py tests/test_stable_ssm_scan.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_stable_ssm_scan.py tests/test_bidirectional_ssm_scan.py</code> passed</li>
</ul>
</li>
<li>FiLM modulation implemented from tokens to packed tiles:</li>
<li>Added <code>apex_x/model/film.py</code>:<ul>
<li><code>TileFiLM(nn.Module)</code>:</li>
<li>computes FiLM parameters from tokens <code>tokens[B,K,Ct]</code></li>
<li>bounded gain path: <code>gamma = tanh(gamma_raw) * gamma_limit</code></li>
<li>shift path: <code>beta</code></li>
<li>applies modulation to packed tiles: <code>out = (1 + gamma) * tiles + beta</code></li>
<li><code>apply_film(...)</code> functional helper with strict shape validation</li>
</ul>
</li>
<li>Updated <code>apex_x/model/core.py</code>:<ul>
<li>replaced additive-only packed modulation with FiLM-style modulation using SSM mixed tokens:</li>
<li><code>gamma = tanh(mixed)</code></li>
<li><code>beta = mixed</code></li>
<li><code>packed_out = (1 + gamma) * packed + beta</code></li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>TileFiLM</code></li>
<li><code>apply_film</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_film_modulation.py</code>:<ul>
<li>formula and shape checks</li>
<li>gamma range bound checks</li>
<li>deterministic forward under fixed inputs</li>
<li>gradient-flow checks through tokens, tiles, and module parameters</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/film.py apex_x/model/core.py apex_x/model/__init__.py tests/test_film_modulation.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_film_modulation.py tests/test_model.py</code> passed</li>
</ul>
</li>
<li>FF heavy path implemented end-to-end with aligned detail map output:</li>
<li>Added <code>apex_x/model/ff_heavy_path.py</code>:<ul>
<li><code>FFHeavyPath(nn.Module)</code> pipeline:</li>
<li><code>TilePackTorch</code> gather on selected FF tile indices</li>
<li>tile tokenization via spatial pooling: <code>tokens[B,K,C]</code></li>
<li>stable scan (<code>forward</code> or <code>bidirectional</code>) over tokens</li>
<li>FiLM modulation (<code>gamma</code>, <code>beta</code>) from mixed tokens to packed tiles</li>
<li>local packed-tile refine via <code>TileRefineBlock</code></li>
<li><code>TileUnpackTorch</code> scatter back to dense map shape</li>
<li>optional proxy-conditioned fusion gate (<code>FusionGate</code>)</li>
<li>output contract via <code>FFHeavyPathOutput</code>:</li>
<li><code>heavy_features[B,C,H,W]</code></li>
<li><code>detail_map[B,C,H,W]</code> aligned to dense features</li>
<li><code>alpha[B,1,H,W]</code></li>
<li>diagnostics tensors (<code>tokens</code>, <code>mixed_tokens</code>, <code>gamma</code>, <code>beta</code>, <code>state</code>)</li>
<li>includes robust CPU behavior for empty tile selections (<code>K=0</code>) with zero detail contribution.</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>FFHeavyPath</code></li>
<li><code>FFHeavyPathOutput</code></li>
</ul>
</li>
<li>Added CPU tests in <code>tests/test_ff_heavy_path.py</code>:<ul>
<li>shape/alignment checks and finite outputs</li>
<li>empty-selection behavior (<code>K=0</code>) -&gt; zero <code>detail_map</code></li>
<li>deterministic repeated forward and gradient-flow checks</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/ff_heavy_path.py apex_x/model/__init__.py tests/test_ff_heavy_path.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_ff_heavy_path.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>FF module implemented for train/infer routing execution:</li>
<li>Added <code>apex_x/model/ff_module.py</code>:<ul>
<li><code>FFModule(nn.Module)</code> with two explicit entrypoints:</li>
<li><code>forward_train(...)</code>:<ul>
<li>STE routing gates via <code>ste_gate_from_utilities(...)</code></li>
<li>expected-cost computation via <code>BudgetDualController.expected_cost(...)</code></li>
<li>budget loss term via <code>BudgetDualController.budget_loss(...)</code></li>
<li>optional dual-<code>mu</code> update with persistent <code>mu_history</code></li>
<li>routed L0 heavy execution through <code>FFHeavyPath</code></li>
</ul>
</li>
<li><code>forward_infer(...)</code>:<ul>
<li>deterministic L0 greedy selection under <code>B1</code>/<code>Kmax_l0</code></li>
<li>optional L0-&gt;L1 two-stage selection under <code>B2</code>/<code>Kmax_l1</code></li>
<li>optional nesting execution (L1 heavy pass) when split utilities provided</li>
</ul>
</li>
<li>diagnostics integrated in both paths through <code>build_routing_diagnostics(...)</code>:</li>
<li>selected counts/ratios</li>
<li>utility histograms</li>
<li>per-budget usage (<code>b1/b2/b3/total</code>)</li>
<li><code>mu_history</code></li>
<li>output dataclasses:</li>
<li><code>FFTrainOutput</code></li>
<li><code>FFInferOutput</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>FFModule</code></li>
<li><code>FFTrainOutput</code></li>
<li><code>FFInferOutput</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_ff_module.py</code>:<ul>
<li>train path:</li>
<li>STE + expected-cost + budget-loss outputs</li>
<li>diagnostics presence</li>
<li>dual-<code>mu</code> history update</li>
<li>inference path:</li>
<li>deterministic budgeted L0 selection</li>
<li>optional nesting with deterministic L1 child selection under <code>B2</code></li>
<li>diagnostics coverage</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/ff_module.py apex_x/model/__init__.py tests/test_ff_module.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_ff_module.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Dual-path FPN implemented to combine PV low-res with FF high-res:</li>
<li>Added <code>apex_x/model/fpn.py</code>:<ul>
<li><code>DualPathFPN(nn.Module)</code>:</li>
<li>inputs:<ul>
<li>PV features dict <code>P3/P4/P5</code></li>
<li>FF high-res feature/detail map</li>
</ul>
</li>
<li>fusion path:<ul>
<li>lateral 1x1 projections for PV <code>P3/P4/P5</code></li>
<li>lateral 1x1 projection for FF branch</li>
<li>top-down FPN merge (<code>P5 -&gt; P4 -&gt; P3</code>)</li>
<li>explicit FF injection at <code>P3</code> after spatial alignment</li>
<li>smoothing with <code>CheapBlock</code> on <code>P3/P4/P5</code></li>
</ul>
</li>
<li>output contract via <code>DualPathFPNOutput</code>:<ul>
<li>fused pyramid dict <code>P3/P4/P5</code></li>
<li>aligned FF feature map at P3 resolution (<code>ff_aligned</code>)</li>
</ul>
</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>DualPathFPN</code></li>
<li><code>DualPathFPNOutput</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_fpn.py</code>:<ul>
<li>CPU shape and finite-value checks</li>
<li>FF-branch sensitivity (changing FF input changes fused <code>P3</code>)</li>
<li>gradient-flow checks through PV inputs, FF input, and FPN params</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/fpn.py apex_x/model/__init__.py tests/test_fpn.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_fpn.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>DET head implemented over P3..P7 (cls/box/quality):</li>
<li>Added <code>apex_x/model/det_head.py</code>:<ul>
<li><code>DetHead(nn.Module)</code>:</li>
<li>consumes pyramid features with required <code>P3/P4/P5</code></li>
<li>supports optional provided <code>P6/P7</code>; auto-generates missing levels from <code>P5</code>/<code>P6</code></li>
<li>per-level outputs:<ul>
<li><code>cls_logits</code>: <code>[B, num_classes, H, W]</code></li>
<li><code>box_reg</code>: <code>[B, 4, H, W]</code></li>
<li><code>quality</code>: <code>[B, 1, H, W]</code></li>
</ul>
</li>
<li>uses shared tower structure for cls/box/quality with GroupNorm + SiLU and export-friendly conv outputs</li>
<li>output contract via <code>DetHeadOutput</code>:</li>
<li>per-level dicts for <code>cls_logits</code>, <code>box_reg</code>, <code>quality</code></li>
<li>normalized <code>features</code> dict for effective <code>P3..P7</code> levels used by the head</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>DetHead</code></li>
<li><code>DetHeadOutput</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_det_head.py</code>:<ul>
<li>shape checks across all output levels <code>P3..P7</code> when only <code>P3..P5</code> are provided</li>
<li>behavior check that explicitly provided <code>P6/P7</code> are used as-is</li>
<li>gradient-flow checks through inputs and DET-head parameters</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/det_head.py apex_x/model/__init__.py tests/test_det_head.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_det_head.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>SimOTA/OTA cost components implemented for DET matching:</li>
<li>Added <code>apex_x/losses/simota.py</code>:<ul>
<li>classification cost:</li>
<li><code>classification_cost(...)</code> with modes:<ul>
<li>BCE-based positive-class cost</li>
<li>focal-based positive-class cost</li>
</ul>
</li>
<li>IoU cost:</li>
<li><code>iou_cost(...)</code> implementing <code>1 - IoU</code> over pairwise GT/anchor boxes</li>
<li>center prior cost:</li>
<li><code>center_prior_cost(...)</code> from GT center to anchor center distance (normalized by GT size)</li>
<li>per-GT candidate generation:</li>
<li><code>topk_center_candidates(...)</code> selecting top-k nearest anchor centers per GT</li>
<li><code>candidate_mask_from_indices(...)</code> to build per-GT candidate masks</li>
<li>integrated cost assembly:</li>
<li><code>compute_simota_cost(...)</code> combining weighted components and candidate masking</li>
<li><code>SimOTACostOutput</code> dataclass containing component matrices, combined cost, and candidates</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>classification_cost</code>, <code>iou_cost</code>, <code>center_prior_cost</code></li>
<li><code>topk_center_candidates</code>, <code>candidate_mask_from_indices</code></li>
<li><code>compute_simota_cost</code>, <code>SimOTACostOutput</code>, <code>ClassificationCostType</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_simota_cost.py</code>:<ul>
<li>per-GT top-k center candidate selection correctness on synthetic anchors/GT</li>
<li>classification-cost ranking behavior (higher positive logit -&gt; lower cost)</li>
<li>IoU cost sanity (<code>1 - IoU</code>)</li>
<li>combined SimOTA ranking on synthetic setup (reasonable anchor wins; non-candidates penalized)</li>
<li>center-prior ranking preference for nearby anchor centers</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/losses/simota.py apex_x/losses/__init__.py tests/test_simota_cost.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_simota_cost.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Dynamic-K SimOTA matching implemented (including conflict resolution):</li>
<li>Extended <code>apex_x/losses/simota.py</code>:<ul>
<li><code>DynamicKMatchingOutput</code> dataclass with:</li>
<li><code>dynamic_ks</code></li>
<li><code>matching_matrix</code></li>
<li><code>foreground_mask</code></li>
<li><code>matched_gt_indices</code></li>
<li><code>assigned_cost</code></li>
<li><code>num_foreground</code></li>
<li><code>dynamic_k_from_top_ious(...)</code>:</li>
<li>computes per-GT <code>dynamic_k</code> from sum of top IoUs (with configurable <code>topk</code> and <code>min_k</code>)</li>
<li>supports optional candidate mask</li>
<li><code>dynamic_k_matching(...)</code>:</li>
<li>selects <code>dynamic_k</code> anchors per GT by minimal total cost</li>
<li>resolves multi-GT conflicts by keeping the minimal-cost GT assignment per anchor</li>
<li>outputs deterministic one-to-one anchor-to-GT assignment for foreground anchors</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>DynamicKMatchingOutput</code></li>
<li><code>dynamic_k_from_top_ious</code></li>
<li><code>dynamic_k_matching</code></li>
</ul>
</li>
<li>Expanded <code>tests/test_simota_cost.py</code>:<ul>
<li>verifies dynamic-k computation from top-IoU sums</li>
<li>verifies crowded conflict resolution picks minimal-cost GT per anchor</li>
<li>verifies candidate-mask constraints are respected in crowded settings</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/losses/simota.py apex_x/losses/__init__.py tests/test_simota_cost.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_simota_cost.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>SimOTA assignment integrated into DET loss with target generation:</li>
<li>Added <code>apex_x/losses/det_loss.py</code>:<ul>
<li><code>build_simota_targets_for_anchors(...)</code>:</li>
<li>uses SimOTA cost + dynamic-k matching to select positive anchors</li>
<li>builds per-anchor targets:<ul>
<li><code>cls_target</code> (one-hot positives, zero background)</li>
<li><code>box_target</code> (assigned GT boxes)</li>
<li><code>quality_target</code> (matched IoU targets)</li>
</ul>
</li>
<li>returns <code>SimOTATargets</code> with matching diagnostics</li>
<li><code>det_loss_with_simota(...)</code>:</li>
<li>computes DET loss from assignment targets:<ul>
<li>classification loss (BCE or focal)</li>
<li>box loss (<code>1 - IoU</code>) on positives</li>
<li>quality BCE loss</li>
</ul>
</li>
<li>returns <code>DetLossOutput</code> with component losses and targets</li>
<li>stability features:</li>
<li>canonicalized box ordering for robust IoU math</li>
<li>optional assignment on detached predictions</li>
<li>small-object positive weighting with clipped inverse-sqrt area scaling</li>
<li>dynamic-k conflict-resolved assignment for crowded scenes</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>SimOTATargets</code></li>
<li><code>DetLossOutput</code></li>
<li><code>build_simota_targets_for_anchors</code></li>
<li><code>det_loss_with_simota</code></li>
<li><code>ClsLossType</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_det_loss_simota.py</code>:<ul>
<li>target generation and per-anchor labeling correctness</li>
<li>finite/stable loss on tiny-object crowded synthetic setup</li>
<li>toy optimization loop verifying DET loss decreases over training steps</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/losses/det_loss.py apex_x/losses/__init__.py tests/test_det_loss_simota.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_det_loss_simota.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>DET losses hardened for numerical stability and quality-focal support:</li>
<li>Updated <code>apex_x/losses/det_loss.py</code>:<ul>
<li>added logit sanitization/clipping via <code>_sanitize_logits(...)</code></li>
<li>added <code>QualityLossType</code> with <code>bce</code> and <code>qfl</code> modes</li>
<li><code>det_loss_with_simota(...)</code> now supports:</li>
<li><code>quality_loss_type=\"qfl\"</code></li>
<li><code>quality_focal_beta</code></li>
<li><code>logit_clip</code></li>
<li>focal/BCE classification and QFL/BCE quality paths now run on sanitized logits for stable behavior under extreme values</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>QualityLossType</code></li>
</ul>
</li>
<li>Expanded <code>tests/test_det_loss_simota.py</code>:<ul>
<li>toy decreasing-loss case now also exercises quality-focal path</li>
<li>added extreme-logit + tiny-box finite test with backward gradient finiteness checks</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/losses/det_loss.py apex_x/losses/__init__.py tests/test_det_loss_simota.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_det_loss_simota.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Deterministic DET decode + NMS implemented:</li>
<li>Added <code>apex_x/infer/detection.py</code>:<ul>
<li><code>decode_anchor_free_candidates(...)</code>:</li>
<li>decodes anchor-free <code>DetHeadOutput</code> maps into per-image candidate tensors</li>
<li>supports configurable level strides and image clipping</li>
<li>applies stable candidate ranking with deterministic tie behavior</li>
<li><code>deterministic_nms(...)</code>:</li>
<li>class-wise NMS with deterministic ordering</li>
<li>tie-breaking policy: score desc, then candidate index asc</li>
<li><code>batched_deterministic_nms(...)</code>:</li>
<li>fixed-shape batched outputs with padding and <code>valid_counts</code></li>
<li><code>decode_and_nms(...)</code>:</li>
<li>end-to-end decode + NMS convenience entrypoint</li>
<li>output dataclasses:</li>
<li><code>DetectionCandidates</code></li>
<li><code>DetectionBatch</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/infer/__init__.py</code>:<ul>
<li><code>DetectionCandidates</code></li>
<li><code>DetectionBatch</code></li>
<li><code>decode_anchor_free_candidates</code></li>
<li><code>deterministic_nms</code></li>
<li><code>batched_deterministic_nms</code></li>
<li><code>decode_and_nms</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_det_decode_nms.py</code>:<ul>
<li>end-to-end decode + NMS determinism and class-wise suppression behavior</li>
<li>deterministic tie handling in NMS (equal scores -&gt; lower index first)</li>
<li>cross-class overlap handling (no cross-class suppression)</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/infer/detection.py apex_x/infer/__init__.py tests/test_det_decode_nms.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/infer/detection.py apex_x/infer/__init__.py</code> passed</li>
<li><code>python -m pytest -q tests/test_det_decode_nms.py tests/test_import_smoke.py</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
</ul>
</li>
<li>Prototype-based instance segmentation forward path and mask assembly implemented:</li>
<li>Added <code>apex_x/model/inst_seg_head.py</code>:<ul>
<li><code>PrototypeInstanceSegHead(nn.Module)</code>:</li>
<li>prototype generator from feature maps (<code>prototypes: [B,M,Hp,Wp]</code>)</li>
<li>per-instance coefficient prediction (<code>coefficients: [B,N,M]</code>) from:<ul>
<li>ROI mean-pooled feature regions derived from <code>boxes_xyxy</code>, or</li>
<li>explicit <code>instance_embeddings</code></li>
</ul>
</li>
<li>mask assembly by linear prototype combination:<ul>
<li><code>mask_logits_lowres = einsum(coefficients, prototypes) -&gt; [B,N,Hp,Wp]</code></li>
</ul>
</li>
<li>output resizing to requested mask resolution</li>
<li>optional box cropping with configurable fill value for stable masked logits</li>
<li>per-instance <code>mask_scores</code> from masked probability averages</li>
<li>helper functions:</li>
<li><code>assemble_mask_logits_from_prototypes(...)</code></li>
<li><code>rasterize_box_masks(...)</code></li>
<li>output dataclass:</li>
<li><code>InstanceSegOutput</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>PrototypeInstanceSegHead</code></li>
<li><code>InstanceSegOutput</code></li>
<li><code>assemble_mask_logits_from_prototypes</code></li>
<li><code>rasterize_box_masks</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_inst_seg_head.py</code>:<ul>
<li>prototype-mask assembly correctness vs expected weighted combinations</li>
<li>forward-path shape/range checks and finite outputs</li>
<li>deterministic repeatability for same weights/inputs</li>
<li>gradient-flow checks (features + instance embeddings + parameters)</li>
<li>crop-to-box fill behavior outside ROI regions</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/inst_seg_head.py apex_x/model/__init__.py tests/test_inst_seg_head.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/model/inst_seg_head.py apex_x/model/__init__.py tests/test_inst_seg_head.py</code> passed</li>
<li><code>python -m pytest -q tests/test_inst_seg_head.py</code> passed</li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code> passed</li>
</ul>
</li>
<li>Segmentation losses implemented (BCE + Dice + boundary DT surrogate):</li>
<li>Added <code>apex_x/losses/seg_loss.py</code>:<ul>
<li><code>mask_bce_loss(...)</code>:</li>
<li>BCEWithLogits per mask with optional per-instance weighting <code>[B,N]</code></li>
<li><code>mask_dice_loss(...)</code>:</li>
<li>soft Dice loss over <code>[B,N,H,W]</code> masks with optional per-instance weighting</li>
<li><code>soft_boundary_distance_transform(...)</code>:</li>
<li>differentiable approximation of boundary distance transform using iterative
    soft-min neighborhood propagation</li>
<li><code>boundary_distance_transform_surrogate_loss(...)</code>:</li>
<li>boundary mismatch weighted by target soft distance transform</li>
<li><code>instance_segmentation_losses(...)</code>:</li>
<li>combined BCE + Dice + boundary loss returning <code>SegLossOutput</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>SegLossOutput</code></li>
<li><code>mask_bce_loss</code></li>
<li><code>mask_dice_loss</code></li>
<li><code>soft_boundary_distance_transform</code></li>
<li><code>boundary_distance_transform_surrogate_loss</code></li>
<li><code>instance_segmentation_losses</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_seg_loss.py</code>:<ul>
<li>BCE/Dice near-zero behavior for near-perfect logits</li>
<li>soft boundary-DT monotonicity sanity check</li>
<li>boundary surrogate sensitivity to shifted boundaries</li>
<li>toy optimization loop showing combined loss decreases with finite gradients</li>
<li>instance-weight support path</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/losses/seg_loss.py apex_x/losses/__init__.py tests/test_seg_loss.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/losses/seg_loss.py apex_x/losses/__init__.py tests/test_seg_loss.py</code> passed</li>
<li><code>python -m pytest -q tests/test_seg_loss.py</code> passed</li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>FF high-resolution tile-gated refinement hook implemented for instance masks:</li>
<li>Updated <code>apex_x/model/inst_seg_head.py</code>:<ul>
<li>added <code>FFTileRefinementHook(nn.Module)</code>:</li>
<li>inputs: <code>mask_logits [B,N,H,W]</code>, <code>ff_highres_features [B,C,H,W]</code>, <code>active_tile_indices [B,K]</code></li>
<li>packs only active tiles, applies FF-conditioned additive refinement on packed tiles, and unpacks back</li>
<li>guarantees inactive tiles remain unchanged via tile-scatter semantics</li>
<li>integrated optional hook into <code>PrototypeInstanceSegHead</code>:</li>
<li>new init toggles:<ul>
<li><code>enable_ff_refine</code></li>
<li><code>ff_refine_tile_size</code></li>
<li><code>ff_refine_order_mode</code></li>
<li><code>ff_refine_overlap_mode</code></li>
<li><code>ff_refine_blend_alpha</code></li>
<li><code>ff_refine_strength_init</code></li>
</ul>
</li>
<li>new forward args:<ul>
<li><code>ff_highres_features</code></li>
<li><code>active_tile_indices</code></li>
</ul>
</li>
<li>refinement is applied only when enabled and both FF features + active indices are provided</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>FFTileRefinementHook</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_inst_seg_refinement_hook.py</code>:<ul>
<li>hook updates only selected tiles and leaves non-selected tiles exactly unchanged</li>
<li>empty active-tile indices produce no-op behavior</li>
<li>head-level integration verifies refinement delta is confined to active tile regions</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/inst_seg_head.py apex_x/model/__init__.py tests/test_inst_seg_refinement_hook.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/model/inst_seg_head.py apex_x/model/__init__.py tests/test_inst_seg_refinement_hook.py</code> passed</li>
<li><code>python -m pytest -q tests/test_inst_seg_refinement_hook.py tests/test_inst_seg_head.py</code> passed</li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Panoptic output generation implemented (semantic + instance fusion):</li>
<li>Added <code>apex_x/infer/panoptic.py</code>:<ul>
<li><code>generate_panoptic_output(...)</code>:</li>
<li>combines semantic logits with instance masks into deterministic panoptic maps</li>
<li>deterministic overlap fusion:<ul>
<li>thing instances fused first, sorted by <code>(score desc, instance_index asc)</code></li>
<li>overlap resolution keeps higher-ranked instance pixels</li>
</ul>
</li>
<li>deterministic thing/stuff rules:<ul>
<li>only classes in <code>thing_class_ids</code> are accepted as thing instances</li>
<li>remaining unassigned pixels are filled by semantic stuff classes in ascending class-id order</li>
<li>segment id <code>0</code> reserved as void/unassigned</li>
</ul>
</li>
<li>supports:<ul>
<li>mask threshold, score threshold</li>
<li>minimum thing/stuff area filters</li>
<li>optional <code>masks_are_logits</code> for instance-mask logits input</li>
</ul>
</li>
<li>dataclasses:</li>
<li><code>PanopticSegmentInfo</code> (<code>id</code>, <code>category_id</code>, <code>isthing</code>, <code>area</code>, optional score/index)</li>
<li><code>PanopticOutput</code> (<code>panoptic_map</code>, <code>segments_info</code>, <code>semantic_labels</code>)</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/infer/__init__.py</code>:<ul>
<li><code>PanopticSegmentInfo</code></li>
<li><code>PanopticOutput</code></li>
<li><code>generate_panoptic_output</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_panoptic_generation.py</code>:<ul>
<li>deterministic overlap resolution on synthetic overlapping thing instances</li>
<li>thing/stuff rule verification (non-thing instances ignored, stuff preserved)</li>
<li>output contract checks on synthetic batched scenes:</li>
<li>map shape/type</li>
<li>unique segment IDs</li>
<li>per-segment area parity with panoptic map pixels</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/infer/panoptic.py apex_x/infer/__init__.py tests/test_panoptic_generation.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/infer/panoptic.py apex_x/infer/__init__.py tests/test_panoptic_generation.py</code> passed</li>
<li><code>python -m pytest -q tests/test_panoptic_generation.py</code> passed</li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Panoptic PQ evaluation wrapper implemented (official API + fallback):</li>
<li>Added <code>apex_x/infer/pq_eval.py</code>:<ul>
<li><code>evaluate_panoptic_quality(...)</code>:</li>
<li>uses official <code>panopticapi</code> evaluator when available and paths are provided</li>
<li>otherwise falls back to an in-memory deterministic minimal PQ implementation</li>
<li>deterministic fallback behavior:</li>
<li>per-category matching with IoU threshold</li>
<li>one-to-one matches with deterministic tie handling</li>
<li>computes per-class <code>(PQ, SQ, RQ)</code> and aggregate all/things/stuff metrics</li>
<li>dataclasses:</li>
<li><code>PQClassMetrics</code></li>
<li><code>PQMetrics</code></li>
<li><code>OfficialPQPaths</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/infer/__init__.py</code>:<ul>
<li><code>PQClassMetrics</code></li>
<li><code>PQMetrics</code></li>
<li><code>OfficialPQPaths</code></li>
<li><code>evaluate_panoptic_quality</code></li>
</ul>
</li>
<li>CLI integration hook added:<ul>
<li>updated <code>apex_x/cli.py</code> <code>eval</code> command with:</li>
<li><code>--panoptic-pq</code> flag</li>
<li>runs panoptic PQ hook and prints <code>panoptic_pq=&lt;value&gt;</code> and source (<code>official</code>/<code>fallback</code>)</li>
</ul>
</li>
<li>Added fixtures:<ul>
<li><code>tests/fixtures/pq_case_perfect.json</code></li>
<li><code>tests/fixtures/pq_case_partial.json</code></li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_pq_eval.py</code></li>
<li>fixture-driven perfect and partial overlap PQ checks</li>
<li>verifies official-path attempt cleanly falls back when official API is unavailable/invalid</li>
<li><code>tests/test_cli.py</code></li>
<li>new parse test for <code>eval --panoptic-pq</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/infer/pq_eval.py apex_x/infer/__init__.py apex_x/cli.py tests/test_pq_eval.py tests/test_cli.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/infer/pq_eval.py apex_x/infer/__init__.py apex_x/cli.py tests/test_pq_eval.py tests/test_cli.py</code> passed</li>
<li><code>python -m pytest -q tests/test_pq_eval.py tests/test_cli.py</code> passed</li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Tracking embedding head and association interfaces implemented:</li>
<li>Added <code>apex_x/model/track_head.py</code>:<ul>
<li><code>TrackEmbeddingHead</code>:</li>
<li>accepts feature tensor or feature dict</li>
<li>projects features, ROI-pools detections, and emits L2-normalized embeddings</li>
<li><code>TrackEmbeddingOutput</code> dataclass with:</li>
<li><code>embeddings</code></li>
<li><code>raw_embeddings</code></li>
<li><code>pooled_features</code></li>
</ul>
</li>
<li>Added <code>apex_x/infer/tracking.py</code>:<ul>
<li><code>TrackState</code> dataclass (validated tracker state contract)</li>
<li><code>AssociationResult</code> dataclass</li>
<li><code>AssociationProtocol</code> interface</li>
<li>deterministic <code>GreedyCosineAssociator</code> implementation</li>
<li>compatibility aliases:</li>
<li><code>TrackAssociatorProtocol</code></li>
<li><code>TrackAssociator</code></li>
</ul>
</li>
<li>Updated exports:<ul>
<li><code>apex_x/model/__init__.py</code> exports <code>TrackEmbeddingHead</code>, <code>TrackEmbeddingOutput</code></li>
<li><code>apex_x/infer/__init__.py</code> exports tracking dataclasses/protocols/associator</li>
<li><code>apex_x/__init__.py</code> exports <code>TrackState</code> and <code>AssociationProtocol</code></li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_track_head.py</code>:</li>
<li>output shape checks</li>
<li>embedding unit-norm checks</li>
<li>deterministic forward checks</li>
<li>gradient flow checks</li>
<li><code>tests/test_tracking_interfaces.py</code>:</li>
<li><code>TrackState.empty(...)</code> contract</li>
<li>protocol conformance checks</li>
<li>deterministic greedy matching/new-track behavior</li>
<li>aging/removal behavior with no detections</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/model/track_head.py apex_x/infer/tracking.py tests/test_track_head.py tests/test_tracking_interfaces.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/model/track_head.py apex_x/infer/tracking.py tests/test_track_head.py tests/test_tracking_interfaces.py</code></li>
<li><code>python -m pytest -q tests/test_track_head.py tests/test_tracking_interfaces.py</code></li>
<li>project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
<li>note:</li>
<li><code>python -m black --check .</code> currently reports unrelated pre-existing formatting diffs in legacy files not touched in this change:<ul>
<li><code>apex_x/routing/interfaces.py</code></li>
<li><code>apex_x/train/__init__.py</code></li>
<li><code>tests/test_pq_eval.py</code></li>
<li><code>apex_x/config/schema.py</code></li>
<li><code>apex_x/infer/pq_eval.py</code></li>
<li><code>apex_x/losses/det_loss.py</code></li>
<li><code>apex_x/model/inst_seg_head.py</code></li>
</ul>
</li>
</ul>
</li>
<li>Hungarian association with lifecycle and memory-bank updates implemented:</li>
<li>Updated <code>apex_x/infer/tracking.py</code>:<ul>
<li>added Hungarian solver utility:</li>
<li><code>hungarian_assignment(...)</code></li>
<li>added <code>HungarianAssociator</code> implementing:</li>
<li>IoU + embedding-distance gating for candidate matches</li>
<li>global cost minimization via Hungarian assignment</li>
<li>track lifecycle (<code>init</code> / <code>update</code> / <code>terminate</code>) with <code>max_age</code></li>
<li>embedding memory-bank update per track with fixed bank size</li>
<li>bank-size normalization for legacy states to keep runtime stable</li>
<li>extended <code>TrackState</code> with optional lifecycle/memory fields:</li>
<li><code>hit_counts</code></li>
<li><code>memory_bank</code></li>
<li><code>memory_counts</code></li>
<li>extended <code>AssociationResult</code> with lifecycle debug outputs:</li>
<li><code>terminated_track_indices</code></li>
<li><code>terminated_track_ids</code></li>
<li><code>created_track_ids</code></li>
<li>kept backward compatibility:</li>
<li><code>GreedyCosineAssociator</code> now delegates to Hungarian with cosine-only cost</li>
<li>protocol aliases preserved</li>
</ul>
</li>
<li>Updated <code>apex_x/infer/__init__.py</code> exports:<ul>
<li><code>HungarianAssociator</code></li>
<li><code>hungarian_assignment</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_tracking_hungarian.py</code>:<ul>
<li>Hungarian global-optimum assignment on synthetic cost matrix</li>
<li>IoU + embedding-distance gating behavior</li>
<li>lifecycle termination after <code>max_age</code></li>
<li>memory-bank update/cap behavior</li>
<li>multi-frame moving-object ID consistency across reordered detections</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/infer/tracking.py apex_x/infer/__init__.py tests/test_tracking_interfaces.py tests/test_tracking_hungarian.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/infer/tracking.py apex_x/infer/__init__.py tests/test_tracking_interfaces.py tests/test_tracking_hungarian.py</code></li>
<li><code>python -m pytest -q tests/test_tracking_interfaces.py tests/test_tracking_hungarian.py tests/test_track_head.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>PCGrad++ shared-trunk conflict projection implemented:</li>
<li>Added <code>apex_x/train/pcgrad.py</code>:<ul>
<li>canonical grouped loss ordering:</li>
<li><code>det_cls</code>, <code>det_box</code>, <code>seg_mask</code>, <code>seg_boundary</code>, then sorted extras</li>
<li><code>LossGroup</code> dataclass and <code>group_loss_terms(...)</code></li>
<li><code>apply_pcgradpp(...)</code>:</li>
<li>computes per-group gradients</li>
<li>applies projection only to shared trunk parameter gradients when <code>cos &lt; 0</code></li>
<li>leaves task-head parameter gradients as standard total-loss gradients</li>
<li><code>PCGradDiagnostics</code> + <code>diagnostics_to_dict(...)</code> for logging/debug</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/train/__init__.py</code>:<ul>
<li><code>DEFAULT_LOSS_GROUP_ORDER</code></li>
<li><code>LossGroup</code></li>
<li><code>PCGradDiagnostics</code></li>
<li><code>group_loss_terms</code></li>
<li><code>apply_pcgradpp</code></li>
<li><code>diagnostics_to_dict</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_pcgradpp.py</code>:<ul>
<li>deterministic grouped ordering for canonical loss groups + extra loss terms</li>
<li>tiny-network synthetic conflicting gradients test:</li>
<li>confirms projection resolves shared-trunk conflict</li>
<li>confirms head gradients match standard total-loss gradients (no projection on heads)</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/train/pcgrad.py apex_x/train/__init__.py tests/test_pcgradpp.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/train/pcgrad.py apex_x/train/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_pcgradpp.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Distillation losses implemented (logits KL + feature L2 + boundary distill):</li>
<li>Added <code>apex_x/losses/distill.py</code>:<ul>
<li><code>logits_kl_distill(...)</code>:</li>
<li>KL divergence distillation on logits with temperature scaling (<code>T^2</code> factor)</li>
<li><code>feature_l2_distill(...)</code>:</li>
<li>layer-selective feature L2 distillation with optional per-layer weights</li>
<li>supports optional feature normalization before L2</li>
<li><code>boundary_distill_loss(...)</code>:</li>
<li>boundary-focused distillation using Sobel-based soft boundary maps</li>
<li>teacher boundary distance-transform weighting</li>
<li><code>distillation_losses(...)</code>:</li>
<li>combined wrapper returning <code>DistillationLossOutput</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>DistillationLossOutput</code></li>
<li><code>logits_kl_distill</code></li>
<li><code>feature_l2_distill</code></li>
<li><code>boundary_distill_loss</code></li>
<li><code>distillation_losses</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_distill_loss.py</code>:<ul>
<li>KL distill near-zero when student/teacher logits match</li>
<li>feature L2 selected-layer behavior with layer weights</li>
<li>boundary distill penalizes shifted boundaries more than aligned boundaries</li>
<li>combined distillation loss decreases in toy optimization</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/losses/distill.py apex_x/losses/__init__.py tests/test_distill_loss.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/losses/distill.py apex_x/losses/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_distill_loss.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Oracle Loss targets and router utility supervision implemented:</li>
<li>Added <code>apex_x/routing/oracle_distill.py</code>:<ul>
<li><code>compute_oracle_delta_targets(...)</code>:</li>
<li>computes sampled-tile oracle targets:<ul>
<li><code>_i = L_distill(cheap, teacher) - L_distill(heavy, teacher)</code></li>
</ul>
</li>
<li>supports sampled indices <code>[S]</code> or batched <code>[B,S]</code></li>
<li>returns detached (stop-grad) oracle targets</li>
<li>optional clamping for outlier robustness</li>
<li><code>utility_regression_loss(...)</code>:</li>
<li>regression loss (<code>l1</code> / <code>mse</code> / <code>smooth_l1</code>) between router utility logits and detached  targets</li>
<li><code>utility_ranking_loss(...)</code>:</li>
<li>pairwise hinge ranking loss over sampled tiles to preserve oracle ordering</li>
<li><code>utility_oracle_loss(...)</code>:</li>
<li>combined regression + ranking objective with diagnostics (<code>num_pairs</code>)</li>
<li>dataclasses:</li>
<li><code>OracleDeltaTargets</code></li>
<li><code>UtilityOracleLossOutput</code></li>
</ul>
</li>
<li>Updated routing exports in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>RegressionLossType</code></li>
<li><code>OracleDeltaTargets</code></li>
<li><code>UtilityOracleLossOutput</code></li>
<li><code>compute_oracle_delta_targets</code></li>
<li><code>utility_regression_loss</code></li>
<li><code>utility_ranking_loss</code></li>
<li><code>utility_oracle_loss</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_oracle_distill.py</code>:<ul>
<li>sign sanity for  targets (positive when heavy distill loss is lower than cheap)</li>
<li>stop-grad behavior (no gradients into cheap/heavy distill losses via utility supervision)</li>
<li>ranking sign sanity (correct utility order yields lower ranking loss)</li>
<li>sampled-index regression correctness (only sampled tiles influence loss)</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/routing/oracle_distill.py apex_x/routing/__init__.py tests/test_oracle_distill.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/routing/oracle_distill.py apex_x/routing/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_oracle_distill.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>TeacherModel implemented for full-compute distillation outputs with optional EMA:</li>
<li>Added <code>apex_x/model/teacher.py</code>:<ul>
<li><code>TeacherModel</code>:</li>
<li>dense/full-compute teacher forward path (PV -&gt; FPN -&gt; DET) without sparse routing</li>
<li>standardized distillation output bundle:<ul>
<li>flattened logits (<code>logits</code>)</li>
<li>per-level logits (<code>logits_by_level</code>)</li>
<li>selected feature layers (<code>features</code>)</li>
<li>boundary proxy map aligned to input size (<code>boundaries</code>)</li>
</ul>
</li>
<li>optional EMA shadow modules:<ul>
<li>configurable <code>ema_decay</code></li>
<li><code>update_ema(...)</code> for parameter/buffer updates</li>
<li>runtime switch to use online or EMA weights in <code>forward(...)</code></li>
</ul>
</li>
<li><code>TeacherDistillOutput</code> dataclass</li>
<li><code>flatten_logits_for_distill(...)</code> helper with deterministic level order</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>TeacherModel</code></li>
<li><code>TeacherDistillOutput</code></li>
<li><code>flatten_logits_for_distill</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_teacher_model.py</code>:<ul>
<li>full-compute standardized output contract checks</li>
<li>deterministic logits-flatten ordering checks</li>
<li>EMA behavior checks:</li>
<li>initial online/EMA parity</li>
<li>EMA lag + update movement toward online model</li>
<li>frozen EMA parameter requirements</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/model/teacher.py apex_x/model/__init__.py tests/test_teacher_model.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/model/teacher.py apex_x/model/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_teacher_model.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Staged trainer pipeline implemented and wired into CLI <code>train</code> flow:</li>
<li>Added <code>apex_x/train/trainer.py</code>:<ul>
<li><code>ApexXTrainer</code> with required stages:</li>
<li>stage 0: baseline warmup</li>
<li>stage 1: teacher training (full compute)</li>
<li>stage 2: oracle bootstrapping</li>
<li>stage 3: continuous budgeting with dual <code>mu</code></li>
<li>stage 4: deterministic inference emulation</li>
<li>stage/result dataclasses:</li>
<li><code>StageResult</code></li>
<li><code>StagedTrainResult</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/train/__init__.py</code>:<ul>
<li><code>ApexXTrainer</code></li>
<li><code>StageResult</code></li>
<li><code>StagedTrainResult</code></li>
</ul>
</li>
<li>Updated CLI <code>train</code> command in <code>apex_x/cli.py</code>:<ul>
<li>now runs staged trainer instead of placeholder-only loop</li>
<li>new option: <code>--steps-per-stage</code></li>
<li>output includes <code>stage_count=5</code></li>
</ul>
</li>
<li>Added staged-train CPU smoke script:<ul>
<li><code>examples/train_stages_smoke.py</code></li>
</ul>
</li>
<li>Added validation coverage:<ul>
<li><code>tests/test_trainer_stages.py</code> (stage completeness + seed repeatability)</li>
<li><code>tests/test_train_stages_smoke.py</code> (subprocess smoke run)</li>
<li>updated <code>tests/test_cli.py</code> to assert staged output includes <code>stage_count=5</code></li>
</ul>
</li>
<li>Updated docs:<ul>
<li><code>README.md</code> now includes staged trainer quickstart/dev commands</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/train/trainer.py apex_x/cli.py tests/test_trainer_stages.py tests/test_train_stages_smoke.py tests/test_cli.py examples/train_stages_smoke.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/train/trainer.py apex_x/cli.py</code></li>
<li><code>python -m pytest -q tests/test_trainer_stages.py tests/test_train_stages_smoke.py tests/test_cli.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Exact COCO compatibility layer implemented with strict schema checks and mask parsing:</li>
<li>Added <code>apex_x/data/coco.py</code> with a strict COCO loader:<ul>
<li><code>load_coco_dataset(path, strict=True, use_cache=True)</code></li>
<li>strict top-level/record key validation (<code>images</code>, <code>annotations</code>, <code>categories</code>)</li>
<li>type/range checks for ids, bbox, area, iscrowd, segmentation payloads</li>
<li>referential integrity checks for <code>annotation.image_id</code> and <code>annotation.category_id</code></li>
</ul>
</li>
<li>Added complete parsing contracts:<ul>
<li>bbox parsing into <code>CocoBBox</code></li>
<li>polygon segmentation parsing into <code>CocoSegmentation(kind=\"polygon\")</code></li>
<li>RLE parsing for uncompressed list counts and compressed string counts into
  <code>CocoSegmentation(kind=\"rle\")</code></li>
<li>deterministic mask decode path via <code>segmentation_to_mask(...)</code></li>
</ul>
</li>
<li>Added category mapping + caching:<ul>
<li><code>CocoDataset.category_mapping()</code> caches contiguous category mapping:</li>
<li><code>original_to_contiguous</code></li>
<li><code>contiguous_to_original</code></li>
<li>category name lookup maps</li>
<li>loader cache for parsed datasets with mtime/size cache key</li>
<li><code>clear_coco_dataset_cache()</code> helper</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/data/__init__.py</code> for COCO dataclasses/helpers.</li>
<li>Added fixture-based tests:<ul>
<li><code>tests/test_coco_compat.py</code></li>
<li>fixtures:</li>
<li><code>tests/fixtures/coco_valid_mixed.json</code></li>
<li><code>tests/fixtures/coco_invalid_missing_top_keys.json</code></li>
<li><code>tests/fixtures/coco_invalid_bad_rle.json</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/data/coco.py apex_x/data/__init__.py tests/test_coco_compat.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/data/coco.py apex_x/data/__init__.py tests/test_coco_compat.py</code></li>
<li><code>python -m pytest -q tests/test_coco_compat.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Data transforms pipeline and Mosaic-v2 heuristic implemented:</li>
<li>Added <code>apex_x/data/transforms.py</code>:<ul>
<li>shared sample contract:</li>
<li><code>TransformSample</code> (image + <code>boxes_xyxy</code> + <code>class_ids</code> + optional masks)</li>
<li>pipeline + base transforms:</li>
<li><code>TransformPipeline</code></li>
<li><code>RandomHorizontalFlip</code></li>
<li><code>ClipBoxesAndMasks</code></li>
<li><code>sanitize_sample(...)</code> for clipping/filtering invalid boxes/masks</li>
<li>Mosaic-v2:</li>
<li><code>MosaicV2(...)</code> 4-image composition with configurable split jitter</li>
<li>heuristic crop-origin policy to protect important instances
    (by area threshold fallback-to-largest instance)</li>
<li>visibility-aware bbox filtering and mask-aware validity checks</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/data/__init__.py</code>:<ul>
<li><code>TransformSample</code>, <code>Transform</code>, <code>TransformPipeline</code></li>
<li><code>RandomHorizontalFlip</code>, <code>ClipBoxesAndMasks</code>, <code>MosaicV2</code>, <code>sanitize_sample</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_data_transforms.py</code>:<ul>
<li>transform-pipeline bbox/mask validity checks</li>
<li>mosaic output validity for bbox/mask contracts</li>
<li>heuristic regression test showing protected mosaic keeps significantly more
  important-instance area than unprotected crop selection</li>
<li>sanitize clipping behavior on out-of-bounds boxes</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/data/transforms.py apex_x/data/__init__.py tests/test_data_transforms.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/data/transforms.py apex_x/data/__init__.py tests/test_data_transforms.py</code></li>
<li><code>python -m pytest -q tests/test_data_transforms.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Eval pipeline implemented for DET/INST-SEG/SEM-SEG/PANO with report emission:</li>
<li>Added <code>apex_x/infer/eval_metrics.py</code>:<ul>
<li>metric computation for tiny-fixture evaluation:</li>
<li>COCO-style mAP (DET) over IoU thresholds <code>0.50:0.05:0.95</code></li>
<li>COCO-style mask mAP (INST-SEG) over IoU thresholds <code>0.50:0.05:0.95</code></li>
<li>mIoU (SEM-SEG)</li>
<li>PQ (PANO) via existing <code>evaluate_panoptic_quality(...)</code></li>
<li>fixture evaluators:</li>
<li><code>evaluate_fixture_payload(...)</code></li>
<li><code>evaluate_fixture_file(...)</code></li>
<li>built-in fallback payload <code>tiny_eval_fixture_payload()</code></li>
<li>report writers:</li>
<li><code>write_eval_reports(...)</code> emitting JSON + Markdown</li>
<li>structured summary dataclass <code>EvalSummary</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/infer/__init__.py</code>:<ul>
<li><code>EvalSummary</code>, <code>evaluate_fixture_file</code>, <code>evaluate_fixture_payload</code>,
  <code>tiny_eval_fixture_payload</code>, <code>write_eval_reports</code></li>
</ul>
</li>
<li>Updated CLI eval command in <code>apex_x/cli.py</code>:<ul>
<li>supports:</li>
<li><code>--fixture</code> (optional fixture JSON; defaults to built-in tiny payload)</li>
<li><code>--report-json</code></li>
<li><code>--report-md</code></li>
<li>always emits metrics in stdout:</li>
<li><code>det_map</code>, <code>mask_map</code>, <code>miou</code>, <code>panoptic_pq</code></li>
<li>writes JSON and markdown report files per invocation</li>
<li>keeps <code>--panoptic-pq</code> flag as compatibility no-op</li>
</ul>
</li>
<li>Added tiny fixture + tests:<ul>
<li>fixture: <code>tests/fixtures/eval_tiny_fixture.json</code></li>
<li><code>tests/test_eval_metrics.py</code>:</li>
<li>metric values on perfect tiny fixture</li>
<li>JSON/Markdown report emission</li>
<li>built-in tiny payload validation</li>
<li><code>tests/test_cli.py</code>:</li>
<li>eval command smoke with fixture + output report paths</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/infer/eval_metrics.py apex_x/infer/__init__.py apex_x/cli.py tests/test_eval_metrics.py tests/test_cli.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/infer/eval_metrics.py apex_x/infer/__init__.py apex_x/cli.py tests/test_eval_metrics.py tests/test_cli.py</code></li>
<li><code>python -m pytest -q tests/test_eval_metrics.py tests/test_cli.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Ablation grid runner implemented in CLI with toggle sweeps and reports:</li>
<li>Added <code>apex_x/train/ablation.py</code>:<ul>
<li>toggle grid definitions for:</li>
<li><code>router</code>, <code>budgeting</code>, <code>nesting</code>, <code>ssm</code>, <code>distill</code>,
    <code>pcgrad</code>, <code>qat</code>, <code>panoptic</code>, <code>tracking</code></li>
<li>deterministic grid builder:</li>
<li><code>build_ablation_grid(...)</code> with per-toggle modes (<code>on/off/both</code>) and max-cap</li>
<li>ablation execution:</li>
<li>fixed-seed runs over grid combinations</li>
<li>trainer invocation with <code>enable_budgeting</code> switch</li>
<li>metrics aggregation (DET mAP, mask mAP, semantic mIoU, PQ, tracking consistency)</li>
<li>routing stat aggregation (selected ratios, budget usage ratio, <code>mu_last</code>)</li>
<li>report writers:</li>
<li>CSV aggregate report</li>
<li>markdown summary report</li>
</ul>
</li>
<li>Updated <code>ApexXTrainer.run(...)</code> in <code>apex_x/train/trainer.py</code>:<ul>
<li>added <code>enable_budgeting</code> flag for explicit budgeting on/off ablations</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/train/__init__.py</code>:<ul>
<li>ablation dataclasses/functions (<code>AblationToggleSet</code>, grid runner, report writer)</li>
</ul>
</li>
<li>Updated CLI <code>ablate</code> command in <code>apex_x/cli.py</code>:<ul>
<li>added per-toggle mode flags (<code>--router/--budgeting/.../--tracking</code>)</li>
<li>added fixed seed support via repeated <code>--seed</code></li>
<li>added <code>--steps-per-stage</code>, <code>--max-experiments</code></li>
<li>added report outputs:</li>
<li><code>--output-csv</code></li>
<li><code>--output-md</code></li>
<li>command now runs grid + writes CSV/MD reports</li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_ablation.py</code>:</li>
<li>grid construction behavior</li>
<li>smoke run + CSV/MD output assertions</li>
<li>updated <code>tests/test_cli.py</code>:</li>
<li><code>ablate</code> command smoke with output artifact checks</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/train/ablation.py apex_x/train/__init__.py apex_x/train/trainer.py apex_x/cli.py tests/test_ablation.py tests/test_cli.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/train/ablation.py apex_x/train/__init__.py apex_x/train/trainer.py apex_x/cli.py tests/test_ablation.py tests/test_cli.py</code></li>
<li><code>python -m pytest -q tests/test_ablation.py tests/test_cli.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>INT8 QAT + PTQ fallback path implemented with FP16 router/gating policy:</li>
<li>Added <code>apex_x/train/qat.py</code>:<ul>
<li>activation observer + activation fake quant:</li>
<li><code>ActivationObserver</code></li>
<li><code>ActivationFakeQuant</code></li>
<li>per-channel INT8 weight fake quant:</li>
<li><code>WeightPerChannelFakeQuant</code></li>
<li>wrapped train-time fake quant modules:</li>
<li><code>FakeQuantConv2d</code></li>
<li><code>FakeQuantLinear</code></li>
<li>QAT/PTQ entrypoints:</li>
<li><code>prepare_int8_qat(...)</code></li>
<li><code>prepare_int8_ptq(...)</code></li>
<li><code>calibrate_ptq(...)</code></li>
<li>explicit wrapper traversal/state controls:</li>
<li><code>iter_qat_wrappers(...)</code></li>
<li><code>set_qat_state(...)</code></li>
</ul>
</li>
<li>Updated <code>apex_x/train/trainer.py</code>:<ul>
<li>quantization preparation step added before staged training:</li>
<li>uses QAT when <code>train.qat_enable &amp;&amp; train.qat_int8</code></li>
<li>uses PTQ calibration fallback when <code>runtime.precision_profile=edge</code> and QAT is off</li>
<li>added deterministic calibration batch builder for PTQ fallback</li>
<li>added quantization diagnostics to <code>train_summary["quantization"]</code>:</li>
<li><code>mode</code>, <code>wrapped_modules</code>, <code>calibration_batches</code>, <code>router_gating_fp16</code></li>
<li>stage-3 routing gate path now keeps FP16 utility gating math and uses FP32 expected-cost accumulation</li>
</ul>
</li>
<li>Updated <code>apex_x/train/__init__.py</code>:<ul>
<li>exported QAT module types/functions for public train API surface</li>
</ul>
</li>
<li>Added tests in <code>tests/test_qat.py</code>:<ul>
<li>QAT wrapper conversion with router/gating skip policy</li>
<li>PTQ calibration state transitions (observer off + fake quant on after calibration)</li>
<li>trainer-level QAT/PTQ toggle smoke with finite loss/output checks</li>
</ul>
</li>
<li>Added documentation:<ul>
<li><code>docs/QAT.md</code> with INT8 policy, module behavior, trainer integration, and validation scope</li>
<li>linked in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/train/qat.py apex_x/train/trainer.py apex_x/train/__init__.py tests/test_qat.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/train/qat.py apex_x/train/trainer.py apex_x/train/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_qat.py tests/test_trainer_stages.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>FP8-ready precision policy implemented with safe FP16 fallback:</li>
<li>Added <code>apex_x/runtime/precision.py</code>:<ul>
<li>precision policy dataclass:</li>
<li><code>PrecisionPolicy</code></li>
<li>runtime detection + resolution:</li>
<li><code>resolve_precision_policy(...)</code></li>
<li>conservative CUDA FP8 support gate (<code>sm90+</code> + torch FP8 dtype presence)</li>
<li>dtype helpers:</li>
<li><code>dtype_name(...)</code></li>
<li>execution context helper:</li>
<li><code>heavy_ops_autocast_context(...)</code><ul>
<li>FP16 autocast path on CPU/CUDA</li>
<li>FP8-ready no-op context pending specialized kernels/plugins</li>
</ul>
</li>
</ul>
</li>
<li>Updated <code>apex_x/runtime/__init__.py</code> exports:<ul>
<li><code>PrecisionPolicy</code>, <code>resolve_precision_policy</code>, <code>dtype_name</code>, <code>heavy_ops_autocast_context</code></li>
</ul>
</li>
<li>Updated <code>apex_x/train/trainer.py</code>:<ul>
<li>resolves precision policy at trainer init</li>
<li>applies heavy-op autocast context during stage-1 teacher forward</li>
<li>adds stage metrics:</li>
<li><code>heavy_ops_dtype</code>, <code>fp8_enabled</code></li>
<li>adds precision diagnostics in <code>train_summary["precision"]</code>:</li>
<li><code>profile</code>, <code>device</code>, <code>heavy_ops_dtype</code></li>
<li><code>fp8_requested</code>, <code>fp8_enabled</code>, <code>fallback_reason</code></li>
<li><code>router_dtype</code>, <code>kan_dtype</code></li>
</ul>
</li>
<li>Updated <code>apex_x/train/qat.py</code>:<ul>
<li>expanded INT8 wrapper skip policy to preserve FP16 for KAN-like modules:</li>
<li>default skip tokens now include <code>"kan"</code> in addition to router/gating names</li>
</ul>
</li>
<li>Added tests in <code>tests/test_precision_policy.py</code>:<ul>
<li>CPU fallback smoke (<code>balanced</code> -&gt; FP16 fallback with explicit reason)</li>
<li>mocked supported CUDA path enabling FP8 for heavy ops</li>
<li>trainer summary smoke verifying fallback diagnostics</li>
</ul>
</li>
<li>Added docs:<ul>
<li><code>docs/FP8.md</code> documenting FP8 request rules, support detection, fallback contract, and smoke coverage</li>
<li>linked from <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/runtime/precision.py apex_x/runtime/__init__.py apex_x/train/trainer.py apex_x/train/qat.py tests/test_precision_policy.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/runtime/precision.py apex_x/runtime/__init__.py apex_x/train/trainer.py</code></li>
<li><code>python -m pytest -q tests/test_precision_policy.py tests/test_trainer_stages.py tests/test_qat.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Triton fused gather+gate+scatter path scaffolded with clean fallback to reference:</li>
<li>Environment check result for this workspace:<ul>
<li><code>torch.cuda.is_available() == False</code></li>
<li>Triton package not installed</li>
<li>therefore Triton kernel implementation path is unavailable in this run</li>
</ul>
</li>
<li>Added <code>apex_x/runtime/triton_fused.py</code>:<ul>
<li>availability model:</li>
<li><code>TritonAvailability</code></li>
<li><code>get_triton_availability()</code></li>
<li>fused-result contract:</li>
<li><code>FusedTileScatterResult</code></li>
<li>reference fused pipeline:</li>
<li><code>gather_gate_scatter_reference(...)</code></li>
<li>implements:<ul>
<li>gather selected heavy/base/proxy tiles</li>
<li>per-pixel fusion gate application</li>
<li>scatter with overlap priority semantics via <code>TileUnpackTorch</code></li>
</ul>
</li>
<li>dispatch API:</li>
<li><code>gather_gate_scatter(...)</code></li>
<li>attempts Triton path when requested and available</li>
<li>cleanly falls back to reference path when unavailable or stubbed</li>
<li>explicit Triton kernel stub:</li>
<li><code>_triton_fused_kernel_stub(...)</code> raises <code>NotImplementedError</code> (by design in no-Triton env)</li>
</ul>
</li>
<li>Updated <code>apex_x/runtime/__init__.py</code> exports:<ul>
<li><code>get_triton_availability</code></li>
<li><code>gather_gate_scatter_reference</code></li>
<li><code>gather_gate_scatter</code></li>
<li>availability/result/backend dataclasses/types</li>
</ul>
</li>
<li>Added microbenchmark script:<ul>
<li><code>scripts/triton_fused_bench.py</code></li>
<li>compares reference path vs dispatched fused path</li>
<li>reports backend, fallback reason, and speed ratio</li>
<li>works on CPU fallback path</li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_triton_fused.py</code>:</li>
<li>reference fused path parity vs explicit reference composition</li>
<li>dispatch fallback behavior in no-Triton/no-CUDA case</li>
<li>forced Triton/no-fallback path raises stub error</li>
<li><code>tests/test_triton_bench.py</code>:</li>
<li>CPU smoke for benchmark utility</li>
</ul>
</li>
<li>Added runtime docs:<ul>
<li><code>docs/runtime/TRITON.md</code> describing dispatch contracts, fallback behavior, and benchmark usage</li>
<li>linked in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/runtime/triton_fused.py apex_x/runtime/__init__.py tests/test_triton_fused.py tests/test_triton_bench.py scripts/triton_fused_bench.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/runtime/triton_fused.py apex_x/runtime/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_triton_fused.py tests/test_triton_bench.py tests/test_tile_pack_torch.py tests/test_tile_unpack_torch.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>CPU performance regression suite implemented with baseline comparison gates:</li>
<li>Added reusable perf suite module:<ul>
<li><code>apex_x/bench/perf.py</code></li>
<li>fixed-size infer benchmark (<code>ApexXModel.forward</code> on <code>[1,3,128,128]</code>)</li>
<li>microbenchmarks:</li>
<li><code>TilePackTorch</code></li>
<li><code>TileUnpackTorch</code></li>
<li><code>FusionGate</code></li>
<li>report + compare helpers:</li>
<li><code>run_cpu_perf_suite(...)</code></li>
<li><code>compare_against_baseline(...)</code></li>
<li>JSON read/write helpers</li>
</ul>
</li>
<li>Updated <code>apex_x/bench/__init__.py</code> exports:<ul>
<li>perf suite and compare utilities exposed</li>
</ul>
</li>
<li>Replaced <code>scripts/perf_regression.py</code>:<ul>
<li>runs suite and writes current JSON report</li>
<li>optional baseline-template emit</li>
<li>compare mode with pass/fail exit status for CI gating</li>
<li>artifacts:</li>
<li>current report JSON</li>
<li>comparison summary JSON</li>
</ul>
</li>
<li>Added committed CPU baseline:<ul>
<li><code>scripts/perf_baseline_cpu.json</code></li>
<li>per-metric tolerances via:</li>
<li><code>max_regression_ratio</code></li>
<li><code>max_regression_abs_ms</code></li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_perf_regression.py</code></li>
<li>suite smoke coverage</li>
<li>baseline compare pass/fail behavior</li>
</ul>
</li>
<li>Added documentation:<ul>
<li><code>docs/PERF.md</code></li>
<li>linked from <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Updated CI workflow:<ul>
<li><code>.github/workflows/ci.yml</code> now includes <code>perf-regression</code> job on <code>ubuntu-latest</code> (CPU-only)</li>
<li>job executes <code>scripts/perf_regression.py --compare ...</code></li>
<li>job uploads perf artifacts (<code>perf_current_ci.json</code>, <code>perf_compare_ci.json</code>)</li>
</ul>
</li>
<li>
<p>Verification status:</p>
<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/bench/perf.py apex_x/bench/__init__.py scripts/perf_regression.py tests/test_perf_regression.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/bench/perf.py apex_x/bench/__init__.py scripts/perf_regression.py</code></li>
<li><code>python -m pytest -q tests/test_perf_regression.py</code></li>
<li><code>python scripts/perf_regression.py --compare --baseline scripts/perf_baseline_cpu.json --output artifacts/perf_current_test.json --summary artifacts/perf_compare_test.json --infer-iters 15 --micro-iters 25 --infer-warmup 3 --micro-warmup 3</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>
<p>TensorRT + Go runtime scaffolding added (Task A/B):</p>
</li>
<li>TensorRT C++ scaffold created under <code>runtime/tensorrt/</code>:<ul>
<li><code>CMakeLists.txt</code> with optional feature probes:</li>
<li><code>APEXX_ENABLE_TENSORRT</code> only when <code>NvInfer.h</code> is found</li>
<li><code>APEXX_ENABLE_CUDA</code> only when CUDA compiler is available</li>
<li>stub plugin interfaces/sources:</li>
<li><code>TilePack</code></li>
<li><code>TileSSMScan</code></li>
<li><code>TileUnpackFusion</code></li>
<li>optional <code>DecodeNMS</code></li>
<li>utility binary:</li>
<li><code>apexx_trt_plugin_info</code> (prints build summary and plugin flags)</li>
</ul>
</li>
<li>TensorRT docs added:<ul>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li>contract mapping from plugin spec to scaffold classes</li>
<li>guarded build instructions:</li>
<li><code>cd runtime/tensorrt &amp;&amp; cmake -S . -B build &amp;&amp; cmake --build build -j</code></li>
</ul>
</li>
<li>Go microservice scaffold created under <code>runtime/go/</code>:<ul>
<li>service entrypoint:</li>
<li><code>runtime/go/cmd/apexx-runtime/main.go</code></li>
<li>endpoints:</li>
<li><code>POST /predict</code></li>
<li><code>GET /health</code></li>
<li><code>GET /metrics</code></li>
<li>short-window batching queue with per-request budget profile support (<code>quality|balanced|edge</code>)</li>
<li>adapters:</li>
<li>ONNX Runtime CPU baseline scaffold (<code>ORTAdapter</code>)</li>
<li>TensorRT CGO scaffold with build tags:<ul>
<li><code>//go:build tensorrt &amp;&amp; cgo</code></li>
<li>default fallback returns clear unavailable error</li>
</ul>
</li>
<li>containerization:</li>
<li><code>runtime/go/Dockerfile</code></li>
<li><code>runtime/go/docker-compose.yml</code></li>
<li>tests:</li>
<li><code>runtime/go/internal/service/batcher_test.go</code></li>
<li><code>runtime/go/internal/service/http_test.go</code></li>
</ul>
</li>
<li>CI/docs integration updates:<ul>
<li><code>.github/workflows/ci.yml</code> now includes <code>go-runtime</code> job (<code>go test ./...</code> in <code>runtime/go</code>)</li>
<li><code>mkdocs.yml</code> + <code>docs/index.md</code> now link <code>docs/runtime/TENSORRT.md</code></li>
<li><code>runtime/README.md</code> and root <code>README.md</code> updated with runtime scaffold usage</li>
</ul>
</li>
<li>Build/run commands verified for scaffolds:<ul>
<li>Go tests:</li>
<li><code>cd runtime/go &amp;&amp; go test ./...</code></li>
<li>Go service:</li>
<li><code>cd runtime/go &amp;&amp; go run ./cmd/apexx-runtime -addr :8080 -adapter onnxruntime</code></li>
<li>TensorRT scaffold build commands documented (not executed in this environment due missing <code>cmake</code>):</li>
<li><code>cd runtime/tensorrt &amp;&amp; cmake -S . -B build &amp;&amp; cmake --build build -j</code></li>
</ul>
</li>
<li>
<p>Remaining work from this milestone:</p>
<ul>
<li>implement real TensorRT plugin classes (<code>IPluginV2DynamicExt</code>) + serialization</li>
<li>replace ORT stub adapter with true ONNX Runtime session execution</li>
<li>implement TensorRT CGO adapter bridge to compiled plugin/runtime binaries</li>
<li>add optional gRPC server for the Go service (HTTP baseline is complete)</li>
</ul>
</li>
<li>
<p>Runtime capability detection module implemented:</p>
</li>
<li>Added <code>apex_x/runtime/caps.py</code> with unified runtime probe object:<ul>
<li><code>RuntimeCaps</code></li>
<li><code>cuda: CudaCaps</code></li>
<li><code>triton: TritonCaps</code></li>
<li><code>tensorrt: TensorRTCaps</code></li>
<li><code>fp8: FP8Caps</code></li>
<li>exported from <code>apex_x/runtime/__init__.py</code></li>
</ul>
</li>
<li>Detection coverage:<ul>
<li>CUDA availability + device name + compute capability</li>
<li>Triton availability + version</li>
<li>TensorRT:</li>
<li>Python package/module availability</li>
<li>header availability (<code>NvInfer.h</code>/<code>NvInferRuntime.h</code>) via:<ul>
<li>explicit <code>header_search_paths</code></li>
<li>env hints (<code>TENSORRT_INCLUDE_DIR</code>, <code>TRT_INCLUDE_DIR</code>, <code>TENSORRT_ROOT</code>, <code>TRT_ROOT</code>, <code>CUDA_HOME</code>, <code>CUDA_PATH</code>)</li>
<li>common include directories</li>
</ul>
</li>
<li>INT8 availability gate for TRT usage (<code>BuilderFlag.INT8</code> + CUDA)</li>
<li>FP8 availability gate:</li>
<li>torch FP8 dtype support</li>
<li>CUDA presence</li>
<li>compute capability <code>sm90+</code></li>
</ul>
</li>
<li>Added tests (CPU-safe, mock-driven):<ul>
<li><code>tests/test_caps_runtime.py</code></li>
<li><code>tests/test_caps_tensorrt_fp8.py</code></li>
</ul>
</li>
<li>Added docs:<ul>
<li><code>docs/runtime/CAPS.md</code></li>
<li>linked in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Usage instructions:<ul>
<li>basic:</li>
<li><code>from apex_x.runtime import detect_runtime_caps</code></li>
<li><code>caps = detect_runtime_caps()</code></li>
<li><code>caps.to_dict()</code></li>
<li>explicit TRT header path:</li>
<li><code>detect_runtime_caps(header_search_paths=["/usr/local/TensorRT/include"])</code></li>
</ul>
</li>
<li>
<p>Validation status:</p>
<ul>
<li><code>python -m pytest -q tests/test_caps_runtime.py tests/test_caps_tensorrt_fp8.py</code></li>
<li><code>python -m ruff check apex_x/runtime/caps.py tests/test_caps_runtime.py tests/test_caps_tensorrt_fp8.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/runtime/caps.py apex_x/runtime/__init__.py</code></li>
</ul>
</li>
<li>
<p>Runtime parity framework implemented:</p>
</li>
<li>Added <code>apex_x/runtime/parity.py</code> with backend-agnostic parity APIs:<ul>
<li><code>ParityCase</code>, <code>run_parity_case(...)</code>, <code>evaluate_parity_outputs(...)</code></li>
<li>tolerance controls:</li>
<li><code>NumericTolerance</code></li>
<li><code>ToleranceConfig</code> (<code>default</code>, <code>fp16</code>, <code>bf16</code>, <code>int8</code>)</li>
<li>reporting objects:</li>
<li><code>TensorParityStats</code></li>
<li><code>ParityReport</code></li>
<li><code>format_parity_report(...)</code></li>
</ul>
</li>
<li>Determinism contract:<ul>
<li><code>run_parity_case(...)</code> calls <code>seed_all(seed, deterministic=...)</code> before input generation</li>
</ul>
</li>
<li>Metrics emitted per compared tensor:<ul>
<li><code>max_abs_err</code>, <code>mean_abs_err</code></li>
<li><code>max_rel_err</code>, <code>mean_rel_err</code></li>
<li><code>mismatch_count</code>, <code>total_count</code>, <code>mismatch_ratio</code></li>
<li>pass/fail against configured tolerance + mismatch-ratio limit</li>
</ul>
</li>
<li>Exported from <code>apex_x/runtime/__init__.py</code> for direct runtime use</li>
<li>Added tests:<ul>
<li><code>tests/test_parity_framework_core.py</code></li>
<li><code>tests/test_parity_framework_tolerances.py</code></li>
<li>tests are CPU-safe and use small shapes for CI speed</li>
</ul>
</li>
<li>Added documentation:<ul>
<li><code>docs/runtime/PARITY.md</code></li>
<li>linked in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Usage instructions:<ul>
<li>create a <code>ParityCase</code> with <code>input_factory</code>, <code>reference_fn</code>, and <code>candidate_fn</code></li>
<li>run <code>run_parity_case(case, seed=..., deterministic=True)</code></li>
<li>serialize/report with <code>report.to_dict()</code> or <code>format_parity_report(report)</code></li>
</ul>
</li>
<li>
<p>Validation status:</p>
<ul>
<li><code>python -m ruff check apex_x/runtime/parity.py apex_x/runtime/__init__.py tests/test_parity_framework_core.py tests/test_parity_framework_tolerances.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/runtime/parity.py apex_x/runtime/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_parity_framework_core.py tests/test_parity_framework_tolerances.py</code></li>
<li><code>.venv/bin/mkdocs build --strict</code></li>
</ul>
</li>
<li>
<p>Triton TilePack gather kernel implemented with fallback dispatch:</p>
</li>
<li>Added new kernel module:<ul>
<li><code>apex_x/kernels/triton/tilepack.py</code></li>
</ul>
</li>
<li>Added package exports:<ul>
<li><code>apex_x/kernels/__init__.py</code></li>
<li><code>apex_x/kernels/triton/__init__.py</code></li>
</ul>
</li>
<li>Implemented Triton kernel contract:<ul>
<li>Input: <code>F[B,C,H,W]</code> contiguous <code>NCHW</code></li>
<li>Input indices: <code>idx[B,K]</code> integer (<code>int32</code> kernel path; <code>int64</code> accepted and cast)</li>
<li>Output: <code>P[B,K,C,t,t]</code> contiguous</li>
</ul>
</li>
<li>Kernel path support:<ul>
<li><code>fp16</code>, <code>bf16</code> on CUDA</li>
<li>no Python tile loops in kernel gather path</li>
</ul>
</li>
<li>Added vectorized reference fallback:<ul>
<li><code>tilepack_reference(...)</code> uses tensor gather (no per-tile Python loops)</li>
</ul>
</li>
<li>Added dispatch behavior:<ul>
<li><code>tilepack_dispatch(...)</code></li>
<li>falls back when Triton/CUDA unavailable</li>
<li>falls back when <code>requires_grad</code> and <code>inference_only=True</code></li>
<li>reason: Triton path is inference-oriented without custom backward registration</li>
</ul>
</li>
<li>Added parity tests:<ul>
<li><code>tests/test_triton_tilepack_parity_dispatch.py</code></li>
<li><code>tests/test_triton_tilepack_parity_gpu.py</code></li>
<li>GPU parity auto-skips when Triton/CUDA unavailable</li>
</ul>
</li>
<li>Added benchmark:<ul>
<li><code>apex_x/bench/triton_tilepack_bench.py</code></li>
</ul>
</li>
<li>Added docs:<ul>
<li><code>docs/runtime/TRITON_TILEPACK.md</code></li>
<li><code>docs/runtime/TRITON.md</code> updated with TilePack status</li>
<li>docs navigation updated in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Run commands:<ul>
<li>tests:</li>
<li><code>python -m pytest -q tests/test_triton_tilepack_parity_dispatch.py tests/test_triton_tilepack_parity_gpu.py</code></li>
<li>bench (module):</li>
<li><code>python -m apex_x.bench.triton_tilepack_bench --iters 50 --warmup 10 --batch 1 --channels 128 --height 128 --width 128 --tile-size 8 --kmax 32 --dtype fp16</code></li>
<li>lint/type:</li>
<li><code>python -m ruff check apex_x/kernels/triton/tilepack.py apex_x/bench/triton_tilepack_bench.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/tilepack.py apex_x/bench/triton_tilepack_bench.py</code></li>
</ul>
</li>
<li>
<p>Validation status:</p>
<ul>
<li><code>python -m ruff check ...</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null ...</code> passed</li>
<li><code>python -m pytest -q tests/test_triton_tilepack_parity_dispatch.py tests/test_triton_tilepack_parity_gpu.py</code> passed (GPU tests skipped on CPU-only env)</li>
<li><code>.venv/bin/mkdocs build --strict</code> passed</li>
</ul>
</li>
<li>
<p>Triton TileUnpack scatter kernel extended to overlap + priority semantics:</p>
</li>
<li>Added kernel module:<ul>
<li><code>apex_x/kernels/triton/tileunpack.py</code></li>
</ul>
</li>
<li>Added Triton kernel dispatch/availability API:<ul>
<li><code>get_triton_tileunpack_availability()</code></li>
<li><code>tileunpack_reference(...)</code></li>
<li><code>tileunpack_triton(...)</code></li>
<li><code>tileunpack_dispatch(...)</code></li>
</ul>
</li>
<li>Added exports:<ul>
<li><code>apex_x/kernels/triton/__init__.py</code></li>
</ul>
</li>
<li>Implemented semantics:<ul>
<li>Inputs: <code>F_base[B,C,H,W]</code>, <code>P_out[B,K,C,t,t]</code>, and <code>idx/meta</code></li>
<li>Output: <code>F_merged[B,C,H,W]</code></li>
<li>deterministic overlap overwrite with priorities:</li>
<li>per-tile <code>levels[B,K]</code> (higher level wins)</li>
<li>or pre-sorted K-order (<code>assume_priority_sorted=True</code>) as implicit priority</li>
<li>default mode: <code>overlap_mode=\"override\"</code> (priority overwrite)</li>
<li>optional mode: <code>overlap_mode=\"blend\"</code> (currently reference fallback)</li>
</ul>
</li>
<li>Updated tests:<ul>
<li><code>tests/test_triton_tileunpack_parity_dispatch.py</code></li>
<li><code>tests/test_triton_tileunpack_parity_gpu.py</code></li>
<li><code>tests/test_triton_tileunpack_overlap_dispatch.py</code></li>
<li><code>tests/test_triton_tileunpack_overlap_gpu.py</code></li>
<li>includes synthetic overlap fixtures and parity against reference behavior</li>
</ul>
</li>
<li>Updated microbenchmark:<ul>
<li><code>apex_x/bench/triton_tileunpack_bench.py</code></li>
<li>supports overlap stress via <code>--overlap-shift</code></li>
<li>supports level-aware runs via default levels (<code>--no-levels</code> to disable)</li>
</ul>
</li>
<li>Added docs:<ul>
<li><code>docs/runtime/TRITON_TILEUNPACK.md</code></li>
<li>updated <code>docs/runtime/TRITON.md</code></li>
<li>updated docs nav (<code>docs/index.md</code>, <code>mkdocs.yml</code>)</li>
</ul>
</li>
<li>Run commands:<ul>
<li>parity tests:</li>
<li><code>python -m pytest -q tests/test_triton_tileunpack_parity_dispatch.py tests/test_triton_tileunpack_parity_gpu.py tests/test_triton_tileunpack_overlap_dispatch.py tests/test_triton_tileunpack_overlap_gpu.py</code></li>
<li>microbench:</li>
<li><code>python -m apex_x.bench.triton_tileunpack_bench --batch 1 --channels 128 --height 128 --width 128 --tile-size 8 --kmax 32 --overlap-shift 4 --warmup 10 --iters 50 --dtype fp16</code></li>
<li>lint/type:</li>
<li><code>python -m ruff check apex_x/kernels/triton/tileunpack.py apex_x/bench/triton_tileunpack_bench.py tests/test_triton_tileunpack_parity_dispatch.py tests/test_triton_tileunpack_parity_gpu.py tests/test_triton_tileunpack_overlap_dispatch.py tests/test_triton_tileunpack_overlap_gpu.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/tileunpack.py apex_x/bench/triton_tileunpack_bench.py</code></li>
</ul>
</li>
<li>
<p>Validation status:</p>
<ul>
<li><code>python -m ruff check ...</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null ...</code> passed</li>
<li><code>python -m pytest -q tests/test_triton_tileunpack_parity_dispatch.py tests/test_triton_tileunpack_parity_gpu.py tests/test_triton_tileunpack_overlap_dispatch.py tests/test_triton_tileunpack_overlap_gpu.py</code> passed (GPU tests skipped on CPU-only env)</li>
<li><code>python -m apex_x.bench.triton_tileunpack_bench --iters 3 --warmup 1 --batch 1 --channels 8 --height 32 --width 32 --tile-size 4 --kmax 4 --overlap-shift 2 --dtype fp16</code> executed successfully (reference backend on CPU)</li>
<li><code>.venv/bin/mkdocs build --strict</code> passed</li>
</ul>
</li>
<li>
<p>Triton FusionGate alpha/fusion kernels implemented with fallback dispatch:</p>
</li>
<li>Added kernel module:<ul>
<li><code>apex_x/kernels/triton/fusiongate.py</code></li>
</ul>
</li>
<li>Added exports:<ul>
<li><code>apex_x/kernels/triton/__init__.py</code></li>
</ul>
</li>
<li>Implemented kernels and dispatch:<ul>
<li>alpha kernel:</li>
<li>inputs: boundary/uncertainty proxies (<code>[B,1,H,W]</code> or <code>[B,H,W]</code>)</li>
<li>output: <code>alpha[B,1,H,W]</code></li>
<li>formula: <code>alpha = sigmoid(softplus(w_b) * boundary + softplus(w_u) * uncertainty + bias)</code></li>
<li>optional fusion kernel:</li>
<li><code>fused = base + alpha * (detail - base)</code></li>
<li>supports optional in-place output in dispatch API</li>
<li>fallback semantics:</li>
<li>falls back to reference when Triton/CUDA unavailable</li>
<li>falls back when autograd is requested and <code>inference_only=True</code></li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_triton_fusiongate_parity_dispatch.py</code></li>
<li><code>tests/test_triton_fusiongate_parity_gpu.py</code></li>
<li>coverage:</li>
<li>parity vs <code>apex_x.model.FusionGate.compute_alpha</code> (simplified alpha path)</li>
<li>alpha range checks (<code>[0,1]</code>)</li>
<li>optional fusion parity</li>
<li>GPU parity auto-skip without CUDA+Triton</li>
</ul>
</li>
<li>Added microbenchmark:<ul>
<li><code>apex_x/bench/triton_fusiongate_bench.py</code></li>
<li>measures:</li>
<li>alpha reference vs dispatch</li>
<li>alpha+fusion reference vs dispatch</li>
</ul>
</li>
<li>Added docs:<ul>
<li><code>docs/runtime/TRITON_FUSION.md</code></li>
<li>updated:</li>
<li><code>docs/runtime/TRITON.md</code></li>
<li><code>docs/index.md</code></li>
<li><code>mkdocs.yml</code></li>
</ul>
</li>
<li>Run commands:<ul>
<li>tests:</li>
<li><code>python -m pytest -q tests/test_triton_fusiongate_parity_dispatch.py tests/test_triton_fusiongate_parity_gpu.py</code></li>
<li>benchmark:</li>
<li><code>python -m apex_x.bench.triton_fusiongate_bench --batch 1 --channels 128 --height 128 --width 128 --warmup 10 --iters 50 --dtype fp16</code></li>
<li>lint/type:</li>
<li><code>python -m ruff check apex_x/kernels/triton/fusiongate.py apex_x/bench/triton_fusiongate_bench.py tests/test_triton_fusiongate_parity_dispatch.py tests/test_triton_fusiongate_parity_gpu.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/fusiongate.py apex_x/bench/triton_fusiongate_bench.py</code></li>
</ul>
</li>
<li>Validation status:<ul>
<li><code>python -m ruff check ...</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null ...</code> passed</li>
<li><code>python -m pytest -q tests/test_triton_fusiongate_parity_dispatch.py tests/test_triton_fusiongate_parity_gpu.py</code> passed (GPU tests skipped on CPU-only env)</li>
<li><code>python -m apex_x.bench.triton_fusiongate_bench --iters 3 --warmup 1 --batch 1 --channels 8 --height 32 --width 32 --dtype fp16</code> executed successfully (reference backend on CPU)</li>
<li><code>.venv/bin/mkdocs build --strict</code> passed</li>
</ul>
</li>
</ul>
<h2 id="invariants-to-preserve">Invariants to Preserve</h2>
<ul>
<li>Deterministic inference tile selection under fixed config</li>
<li>Fixed <code>Kmax</code>-buffer shape contract for runtime compatibility</li>
<li>No Python-side dynamic control flow in future export graph path</li>
<li>CPU baseline must remain runnable at all times</li>
</ul>
<h2 id="open-risks">Open Risks</h2>
<ul>
<li>Tile-SSM is currently a placeholder scan, not final kernel-equivalent behavior</li>
<li>Detection/segmentation heads are minimal baseline stubs</li>
<li>Runtime plugins are currently specification-only, not implemented</li>
</ul>
<h2 id="immediate-next-steps">Immediate Next Steps</h2>
<ol>
<li>Expand baseline heads to full DET + INST-SEG proto path per spec.</li>
<li>Add explicit continuous-budget training loop example with dual <code>mu</code> update.</li>
<li>Add deterministic quadtree <code>L1/L2</code> split implementation and tests.</li>
<li>Add export smoke tests (ONNX contract checks with fixed <code>Kmax</code>).</li>
<li>Add perf threshold config file and CI perf guard for CPU baseline.</li>
<li>Add CLI entrypoints (Typer + Rich) for <code>run</code>, <code>test</code>, and <code>perf</code> commands.</li>
<li>Add initial concrete <code>losses/</code>, <code>train/</code>, <code>infer/</code>, and <code>export/</code> implementations beyond placeholders.</li>
<li>Add a typed Typer command for <code>config validate --config path.yaml --set key=value</code> using new loader/override utilities.</li>
<li>Add logging configuration knobs into <code>RuntimeConfig</code> (log level/format) and route through <code>configure_logging()</code>.</li>
<li>Add <code>apex-x config validate</code> and <code>apex-x config dump</code> subcommands for explicit config workflows.</li>
<li>Add docs deployment workflow (e.g., GitHub Pages) after docs structure stabilizes.</li>
<li>Add real TRT/ORT <code>RuntimeAdapterProtocol</code> implementations behind feature flags.</li>
<li>Add smoke example invocation to README and optionally CI as a dedicated quick check.</li>
<li>Add ADR template/checklist for future decisions to keep decision records uniform.</li>
<li>Integrate L0 mapping helpers directly inside pack/unpack metadata paths (store tile <code>(ty,tx)</code> alongside pixel origins) for easier runtime plugin parity checks.</li>
<li>Add non-square grid Hilbert fixture coverage (e.g., <code>3x5</code>, <code>5x3</code>) to lock padded-power-of-two traversal behavior.</li>
<li>Add explicit fixture snapshots for scan modes (<code>l2r/r2l/u2d/d2u</code>) on representative non-square grids and enforce them in CI.</li>
<li>Connect split-budget selection (<code>B2/B3</code>) in inference path to quadtree depth-2 mappings/metadata and add end-to-end selection tests.</li>
<li>Integrate <code>TileSelection</code>/<code>TileSelectionTrace</code> emission into model inference outputs and add CLI flag to dump selection traces for ablations.</li>
<li>Add optional CLI command to generate overlay images from stored <code>TileSelectionTrace</code> JSON for quick qualitative routing inspection.</li>
<li>Wire <code>StaticCostModel</code> into routing/inference selection path so budgeting uses per-level <code>C_c/C_h</code> + pack/unpack/split overhead directly instead of scalar placeholders.</li>
<li>Integrate <code>sample_oracle_set(...)</code> into training loops so oracle subset <code>S</code> is produced from random + uncertainty-biased policies directly from PV <code>u_hat</code>.</li>
<li>Add budget-selection debug artifact that logs per-tile score/rank and final stable tie-break order for exact replay in ablation runs.</li>
<li>Integrate PV aggregation output <code>x_i</code> into router training/inference path so utility heads consume pooled <code>mean/max/var</code> vectors instead of placeholder signals.</li>
<li>Wire <code>RouterTinyMLP</code> into model/routing execution path as the default trainable router backend (with config-selectable fallback to <code>IdentityRouter</code>).</li>
<li>Add config switch for router backend (<code>identity</code> / <code>tiny_mlp</code> / <code>kan_like</code>) and wire <code>RouterKANLike</code> into inference/training stubs.</li>
<li>Integrate <code>ste_gate_from_utilities(...)</code> into training stubs so router utilities produce <code>p_i</code>/<code>g_i</code> directly in continuous-budget examples.</li>
<li>Wire <code>BudgetDualController</code> into training stubs so <code>mu</code>, <code>E[C]</code>, and budget term are tracked/updated per step with debug logs.</li>
<li>Use <code>GreedySelectionResult.kmax_buffer</code> + <code>valid_count</code> directly in model inference outputs to mirror runtime plugin shape contracts.</li>
<li>Integrate <code>deterministic_two_stage_selection(...)</code> into model inference path so <code>B1/B2</code> and <code>L1</code> routing are exercised end-to-end in CPU baseline outputs.</li>
<li>Use <code>hysteresis_rollout(...)</code> in temporal/video inference stubs and log <code>count_mask_toggles(...)</code> as an anti-flicker metric.</li>
<li>Extend routing diagnostics to include L1/L2 selection once two-stage routing is wired into the model forward path.</li>
<li>Add optional artifact export for diagnostics snapshots (JSON + histogram plots) from CLI train/predict commands for ablation workflows.</li>
<li>Wire toggle states into YAML examples/README config snippets so users can reproduce dense/no-SSM/no-nesting baselines quickly.</li>
<li>Integrate torch tile pack/unpack path into runtime adapter abstractions and add a CPU fallback selection path for adapter-level smoke tests.</li>
<li>Integrate <code>FusionGate</code> into the model forward path (or runtime adapter path) to replace direct heavy overwrite with proxy-conditioned fusion in CPU baseline experiments.</li>
<li>Integrate <code>CheapBlock</code> into PV/FF cheap path stubs and add micro-benchmarks for block latency under CPU profiles.</li>
<li>Integrate <code>TileRefineBlock</code> after Tile-SSM in the model forward path so packed-tile local refinement is exercised end-to-end in baseline outputs.</li>
<li>Wire <code>PVBackbone</code> into model execution path as the canonical PV stream source (<code>P3/P4/P5</code>) and align routing signals to these outputs.</li>
<li>Integrate <code>PVModule</code> into <code>ApexXModel.forward</code> so routing and diagnostics consume PV coarse proxies instead of handcrafted tile-signal placeholders.</li>
<li>Replace/augment NumPy <code>tile_ssm_scan</code> usage in <code>ApexXModel.forward</code> with <code>StableStateSpaceScan</code> in torch execution paths and add parity checks for inference outputs.</li>
<li>Add <code>ApexXModel</code> config switch for scan direction mode (<code>forward</code> vs <code>bidirectional</code>) and wire merge-gated bidirectional scan into packed-tile path.</li>
<li>Wire <code>decode_and_nms(...)</code> into model/inference outputs so DET head predictions use the new deterministic decode/NMS path in end-to-end CPU runs.</li>
<li>Wire <code>PrototypeInstanceSegHead</code> into end-to-end model/infer path (using DET-selected instances) and expose assembled masks in CLI <code>predict</code> outputs.</li>
<li>Integrate <code>instance_segmentation_losses(...)</code> into training stubs with mask/box matching targets and log BCE/Dice/boundary components in trainer diagnostics.</li>
<li>Wire <code>FFTileRefinementHook</code> active-tile indices from routing outputs in model/infer path so refinement uses real FF-selected tiles end-to-end.</li>
<li>Wire <code>generate_panoptic_output(...)</code> into inference/CLI outputs so panoptic maps and <code>segments_info</code> are emitted from DET + INST-SEG + SEM-SEG predictions end-to-end.</li>
<li>Wire <code>evaluate_panoptic_quality(...)</code> into dataset evaluation loops so <code>apex-x eval</code> can consume real predicted/GT panoptic artifacts and report dataset-level PQ metrics.</li>
<li>Integrate <code>TrackEmbeddingHead</code> into model/infer outputs and add config-controlled tracking head enable/disable behavior.</li>
<li>Add a basic association loop wrapper in <code>apex_x/infer</code> that keeps <code>TrackState</code> across frames and emits stable track IDs in CLI <code>predict</code>.</li>
<li>Add optional motion gating term into Hungarian cost/gate path (for video mode) and verify flicker reduction with temporal fixtures.</li>
<li>Integrate <code>apply_pcgradpp(...)</code> into concrete training step codepath so DET/SEG grouped losses are projected on shared trunk params during optimization and surfaced in trainer diagnostics.</li>
<li>Integrate <code>distillation_losses(...)</code> into the concrete training path with config-driven weights/temperature/feature-layer selection and expose per-component values in trainer diagnostics.</li>
<li>Integrate <code>compute_oracle_delta_targets(...)</code> + <code>utility_oracle_loss(...)</code> into router training loops so sampled set <code>S</code> drives utility regression/ranking with detached oracle targets.</li>
<li>Wire <code>TeacherModel</code> into train/eval loops so EMA updates, distill outputs, and student-teacher loss plumbing are exercised end-to-end with config toggles.</li>
<li>Expand <code>ApexXTrainer</code> stage loop from smoke-level synthetic batches to dataset-backed dataloaders with checkpointing/resume support.</li>
<li>Add stage-aware CLI logging/artifacts (<code>stage_metrics.json</code>, <code>mu_history.json</code>) for ablation reproducibility.</li>
<li>Add CI smoke command for staged training CLI (<code>apex-x train --steps-per-stage 1</code>) to guard regressions in train wiring.</li>
<li>Wire <code>TransformPipeline</code> and <code>MosaicV2</code> into an actual dataset/dataloader path controlled by <code>DataConfig</code> knobs (<code>flip_prob</code>, <code>mosaic_prob</code>, scale range).</li>
<li>Add serialization/debug helpers to visualize transformed boxes/masks and mosaic split/crop decisions for reproducible augmentation ablations.</li>
<li>Add dataset-wide evaluation loops that consume real model predictions and emit the new eval report (JSON/MD) directly from inference artifacts, beyond tiny fixture mode.</li>
<li>Extend ablation runner to ingest real dataset eval outputs (instead of tiny fixture metrics) and add per-toggle significance summaries across seeds.</li>
<li>Expand QAT coverage beyond Conv/Linear wrappers to selected normalization-sensitive blocks with explicit parity gates versus FP16 baseline.</li>
<li>Add runtime-backed FP8 kernel probe path (beyond capability check) and enforce parity/perf gates before enabling FP8-by-default on compatible GPUs.</li>
<li>Implement real Triton fused gather+gate+scatter kernel and wire it under <code>gather_gate_scatter(...)</code> dispatch when CUDA+Triton are available; add parity + perf thresholds against reference path.</li>
<li>Add dataset/profile-specific perf baselines (e.g., quality/balanced/edge configs) and split tolerances by CPU model class for stricter regression gates.</li>
</ol>
<h2 id="latest-update-2026-02-08-triton-fused-stage-1-pipeline">Latest Update (2026-02-08): Triton Fused Stage-1 Pipeline</h2>
<ul>
<li>Added a new practical fused Triton fast path module:</li>
<li><code>apex_x/kernels/triton/fused_pack_op_unpack.py</code></li>
<li>Implements <code>gather -&gt; pointwise affine + ReGLU-like gate -&gt; scatter</code> in one Triton kernel launch sequence.</li>
<li>Added dispatch + fallback API:<ul>
<li><code>get_triton_fused_stage1_availability()</code></li>
<li><code>fused_pack_op_unpack_reference(...)</code></li>
<li><code>fused_pack_op_unpack_triton(...)</code></li>
<li><code>fused_pack_op_unpack_dispatch(...)</code></li>
</ul>
</li>
<li>Determinism rule for Stage-1 path:<ul>
<li>requires unique tile indices per batch row to avoid overlap write races.</li>
</ul>
</li>
<li>Added exports:</li>
<li><code>apex_x/kernels/triton/__init__.py</code> now exports fused Stage-1 APIs.</li>
<li>Added parity tests:</li>
<li><code>tests/test_triton_fused_stage1_dispatch.py</code></li>
<li><code>tests/test_triton_fused_stage1_gpu.py</code></li>
<li>Added microbenchmark:</li>
<li><code>apex_x/bench/triton_fused_stage1_bench.py</code></li>
<li>compares:<ul>
<li>explicit reference composition (<code>pack -&gt; op -&gt; unpack</code>)</li>
<li>separate dispatch composition (<code>TilePack dispatch -&gt; op -&gt; TileUnpack dispatch</code>)</li>
<li>fused Stage-1 dispatch</li>
</ul>
</li>
<li>Added docs:</li>
<li><code>docs/runtime/TRITON_FUSED_STAGE1.md</code></li>
<li>updated:<ul>
<li><code>docs/runtime/TRITON.md</code></li>
<li><code>docs/index.md</code></li>
<li><code>mkdocs.yml</code></li>
</ul>
</li>
</ul>
<h3 id="run-commands">Run Commands</h3>
<ul>
<li>Tests:</li>
<li><code>python -m pytest -q tests/test_triton_fused_stage1_dispatch.py tests/test_triton_fused_stage1_gpu.py</code></li>
<li>Microbenchmark:</li>
<li><code>python -m apex_x.bench.triton_fused_stage1_bench --batch 1 --channels 128 --height 128 --width 128 --tile-size 8 --kmax 32 --warmup 10 --iters 50 --dtype fp16</code></li>
<li>Lint/type quick checks:</li>
<li><code>python -m ruff check apex_x/kernels/triton/fused_pack_op_unpack.py tests/test_triton_fused_stage1_dispatch.py tests/test_triton_fused_stage1_gpu.py apex_x/bench/triton_fused_stage1_bench.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/fused_pack_op_unpack.py apex_x/bench/triton_fused_stage1_bench.py</code></li>
</ul>
<h3 id="remaining-work">Remaining Work</h3>
<ul>
<li>Wire Stage-1 fused kernel into legacy runtime entrypoint:</li>
<li><code>apex_x/runtime/triton_fused.py::gather_gate_scatter(...)</code></li>
<li>Extend fused kernel beyond Stage-1 local transform:</li>
<li>add overlap-priority semantics in-kernel where needed</li>
<li>integrate Tile-SSM-related fused blocks (next stages)</li>
<li>Add GPU CI perf threshold gates for <code>speedup_separate_over_fused</code>.</li>
</ul>
<h2 id="latest-update-2026-02-08-triton-tilessm-scan-baseline">Latest Update (2026-02-08): Triton TileSSM Scan Baseline</h2>
<ul>
<li>Added Triton TileSSM scan module:</li>
<li><code>apex_x/kernels/triton/tilessm_scan.py</code></li>
<li>Forward-only recurrence scan over tokens <code>tokens[B,K,C]</code> with stable sanitization/clamping.</li>
<li>Outputs:<ul>
<li><code>y[B,K,C]</code></li>
<li><code>final_state[B,C]</code></li>
</ul>
</li>
<li>Added availability + dispatch API:<ul>
<li><code>get_triton_tilessm_availability()</code></li>
<li><code>tilessm_scan_reference(...)</code></li>
<li><code>tilessm_scan_triton(...)</code></li>
<li><code>tilessm_scan_dispatch(...)</code></li>
</ul>
</li>
<li>Dispatch keeps training-safe behavior:<ul>
<li><code>inference_only=True</code> falls back to reference when autograd is active.</li>
</ul>
</li>
<li>Exported TileSSM API:</li>
<li><code>apex_x/kernels/triton/__init__.py</code></li>
<li>Integrated inference path into model heavy FF scan:</li>
<li>updated <code>apex_x/model/ff_heavy_path.py</code><ul>
<li>new <code>use_triton_inference_scan</code> toggle</li>
<li>eval mode uses <code>tilessm_scan_dispatch(...)</code></li>
<li>train mode keeps torch scan path (<code>StableStateSpaceScan</code> / <code>StableBidirectionalStateSpaceScan</code>)</li>
</ul>
</li>
<li>updated <code>apex_x/model/ff_module.py</code><ul>
<li>routes <code>RuntimeConfig.enable_runtime_plugins</code> to <code>FFHeavyPath(..., use_triton_inference_scan=...)</code></li>
</ul>
</li>
<li>Added tests:</li>
<li><code>tests/test_triton_tilessm_parity_dispatch.py</code></li>
<li><code>tests/test_triton_tilessm_parity_gpu.py</code></li>
<li><code>tests/test_ff_heavy_path_tilessm_dispatch.py</code></li>
<li>Added throughput benchmark:</li>
<li><code>apex_x/bench/triton_tilessm_bench.py</code></li>
<li>Added docs:</li>
<li><code>docs/runtime/TRITON_SSM.md</code></li>
<li>updated:<ul>
<li><code>docs/runtime/TRITON.md</code></li>
<li><code>docs/index.md</code></li>
<li><code>mkdocs.yml</code></li>
</ul>
</li>
</ul>
<h3 id="run-commands_1">Run Commands</h3>
<ul>
<li>Tests:</li>
<li><code>python -m pytest -q tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py tests/test_ff_heavy_path_tilessm_dispatch.py tests/test_ff_heavy_path.py</code></li>
<li>Benchmark:</li>
<li><code>python -m apex_x.bench.triton_tilessm_bench --batch 2 --steps 256 --channels 128 --warmup 10 --iters 50 --dtype fp16</code></li>
<li>Lint/type checks:</li>
<li><code>python -m ruff check apex_x/kernels/triton/tilessm_scan.py apex_x/model/ff_heavy_path.py apex_x/model/ff_module.py apex_x/bench/triton_tilessm_bench.py tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py tests/test_ff_heavy_path_tilessm_dispatch.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/tilessm_scan.py apex_x/model/ff_heavy_path.py apex_x/model/ff_module.py apex_x/bench/triton_tilessm_bench.py tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py tests/test_ff_heavy_path_tilessm_dispatch.py</code></li>
<li>Docs:</li>
<li><code>.venv/bin/mkdocs build --strict</code></li>
</ul>
<h3 id="validation-status">Validation Status</h3>
<ul>
<li><code>ruff</code>: passed on changed TileSSM files.</li>
<li><code>mypy</code>: passed on changed TileSSM files.</li>
<li><code>pytest</code>: passed for new parity/integration tests (GPU tests auto-skipped on CPU-only environment).</li>
<li>benchmark smoke run: completed on CPU fallback path.</li>
<li>docs build: passed with strict mode.</li>
</ul>
<h3 id="remaining-work_1">Remaining Work</h3>
<ul>
<li>Add multi-direction scan execution mode in Triton TileSSM path (current kernel is forward-only baseline).</li>
<li>Add a fused TileSSM + tile-local refine path after this baseline.</li>
<li>Add GPU CI lane for TileSSM parity/perf thresholds when CUDA runners are available.</li>
</ul>
<h2 id="latest-update-2026-02-08-triton-tilessm-multi-direction">Latest Update (2026-02-08): Triton TileSSM Multi-Direction</h2>
<ul>
<li>Extended <code>apex_x/kernels/triton/tilessm_scan.py</code> to support directional scanning:</li>
<li><code>direction</code>: <code>forward</code>, <code>backward</code>, <code>bidirectional</code></li>
<li><code>merge_mode</code> for bidirectional: <code>sum</code>, <code>avg</code>, <code>gated</code></li>
<li>optional torch-computed <code>merge_gate</code> for gated merge (<code>[C]</code> or <code>[B,1,C]</code>)</li>
<li>Added clean directional API:</li>
<li><code>scan(tokens, direction=...) -&gt; y</code></li>
<li>routes through dispatch with fallback behavior</li>
<li>Kept training/inference separation:</li>
<li>training/backward still uses torch scan path</li>
<li>inference dispatch can use Triton path (<code>inference_only=True</code>)</li>
<li>Updated FF inference integration:</li>
<li><code>apex_x/model/ff_heavy_path.py</code></li>
<li>Triton inference path now uses directional dispatch (<code>forward</code> and <code>backward</code>) and applies learned torch gate for merge in bidirectional mode.</li>
<li>Updated exports:</li>
<li><code>apex_x/kernels/triton/__init__.py</code> now exports:<ul>
<li><code>ScanDirection</code></li>
<li><code>BidirectionalMergeMode</code></li>
<li><code>scan</code></li>
</ul>
</li>
<li>Updated benchmark for multi-direction overhead:</li>
<li><code>apex_x/bench/triton_tilessm_bench.py</code></li>
<li>now reports forward/backward/bidirectional timings and overhead ratios vs forward.</li>
<li>Updated tests:</li>
<li><code>tests/test_triton_tilessm_parity_dispatch.py</code><ul>
<li>added backward parity vs torch manual recurrence</li>
<li>added bidirectional parity for <code>sum/avg/gated</code></li>
<li>added clean API <code>scan(...)</code> test</li>
</ul>
</li>
<li><code>tests/test_triton_tilessm_parity_gpu.py</code><ul>
<li>added bidirectional avg parity test (GPU)</li>
</ul>
</li>
<li>Updated docs:</li>
<li><code>docs/runtime/TRITON_SSM.md</code></li>
<li><code>docs/runtime/TRITON.md</code></li>
</ul>
<h3 id="run-commands_2">Run Commands</h3>
<ul>
<li>Tests:</li>
<li><code>python -m pytest -q tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py tests/test_ff_heavy_path_tilessm_dispatch.py tests/test_ff_heavy_path.py</code></li>
<li>Benchmark:</li>
<li><code>python -m apex_x.bench.triton_tilessm_bench --batch 2 --steps 256 --channels 128 --warmup 10 --iters 50 --dtype fp16</code></li>
<li>Lint/type:</li>
<li><code>python -m ruff check apex_x/kernels/triton/tilessm_scan.py apex_x/kernels/triton/__init__.py apex_x/model/ff_heavy_path.py apex_x/bench/triton_tilessm_bench.py tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/tilessm_scan.py apex_x/kernels/triton/__init__.py apex_x/model/ff_heavy_path.py apex_x/bench/triton_tilessm_bench.py tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py</code></li>
<li>Docs:</li>
<li><code>.venv/bin/mkdocs build --strict</code></li>
</ul>
<h3 id="validation-status_1">Validation Status</h3>
<ul>
<li><code>ruff</code>: passed</li>
<li><code>mypy</code>: passed</li>
<li><code>pytest</code>: passed (GPU tests skipped on CPU-only environment)</li>
<li>benchmark smoke run: passed (reference fallback on CPU)</li>
<li>docs build (<code>mkdocs --strict</code>): passed</li>
</ul>
<h2 id="latest-update-2026-02-08-tensorrt-build-hardening-harness">Latest Update (2026-02-08): TensorRT Build Hardening + Harness</h2>
<ul>
<li>Read runtime specs from:</li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code> (canonical)</li>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li>Added alias page: <code>docs/runtime/PLUGIN_SPECS.md</code> -&gt; points to canonical spec</li>
<li>Hardened TensorRT CMake in <code>runtime/tensorrt/CMakeLists.txt</code>:</li>
<li>shared plugin library support:<ul>
<li><code>apexx_trt_plugins</code> (SHARED)</li>
</ul>
</li>
<li>added always-build static core:<ul>
<li><code>apexx_trt_plugin_core</code> (STATIC, PIC)</li>
</ul>
</li>
<li>compile-guard behavior:<ul>
<li>shared plugin library builds only when TensorRT headers and CUDA compiler are found</li>
<li>if TRT/CUDA unavailable, shared build is skipped cleanly and repo remains buildable</li>
</ul>
</li>
<li>plugin info target kept available:<ul>
<li><code>apexx_trt_plugin_info</code></li>
</ul>
</li>
<li>harness target added conditionally (only with shared build):<ul>
<li><code>apexx_trt_plugin_harness</code></li>
</ul>
</li>
<li>Added minimal plugin enqueue-like path for stubs:</li>
<li><code>runtime/tensorrt/include/apexx_trt/plugin_stub.hpp</code><ul>
<li><code>DummyTensor</code>, <code>PluginEnqueueInputs</code>, <code>PluginEnqueueOutputs</code>, <code>PluginStub::enqueue(...)</code></li>
</ul>
</li>
<li>implemented enqueue methods in:<ul>
<li><code>runtime/tensorrt/src/tile_pack_plugin.cpp</code></li>
<li><code>runtime/tensorrt/src/tile_ssm_scan_plugin.cpp</code></li>
<li><code>runtime/tensorrt/src/tile_unpack_fusion_plugin.cpp</code></li>
<li><code>runtime/tensorrt/src/decode_nms_plugin.cpp</code></li>
</ul>
</li>
<li>Added shared-library C ABI entrypoints in:</li>
<li><code>runtime/tensorrt/include/apexx_trt/common.hpp</code></li>
<li><code>runtime/tensorrt/src/common.cpp</code></li>
<li>symbols:<ul>
<li><code>apexx_trt_abi_version()</code></li>
<li><code>apexx_trt_build_summary_cstr()</code></li>
<li><code>apexx_trt_invoke_minimal(...)</code></li>
</ul>
</li>
<li>Added minimal runtime harness executable source:</li>
<li><code>runtime/tensorrt/tests/plugin_harness_main.cpp</code></li>
<li>harness behavior:<ul>
<li>loads plugin shared library via <code>dlopen</code>/<code>LoadLibrary</code></li>
<li>resolves C ABI symbols</li>
<li>creates dummy tensors</li>
<li>invokes minimal plugin call path for TilePack/TileSSMScan/TileUnpackFusion/DecodeNMS</li>
</ul>
</li>
<li>Added build doc:</li>
<li><code>docs/runtime/TENSORRT_BUILD.md</code></li>
<li>Updated docs navigation and runtime note cross-links:</li>
<li><code>mkdocs.yml</code></li>
<li><code>docs/index.md</code></li>
<li><code>docs/runtime/TENSORRT.md</code></li>
</ul>
<h3 id="exact-build-commands">Exact Build Commands</h3>
<ul>
<li>Auto-detect build:</li>
<li><code>cd runtime/tensorrt</code></li>
<li><code>cmake -S . -B build</code></li>
<li><code>cmake --build build -j</code></li>
<li><code>./build/apexx_trt_plugin_info</code></li>
<li>Explicit TRT/CUDA paths:</li>
<li><code>cd runtime/tensorrt</code></li>
<li><code>cmake -S . -B build -DTENSORRT_INCLUDE_DIR=\"${TENSORRT_ROOT}/include\" -DCMAKE_CUDA_COMPILER=\"${CUDA_HOME}/bin/nvcc\"</code></li>
<li><code>cmake --build build -j</code></li>
<li>Force skip shared plugin build (portable/CI machines):</li>
<li><code>cd runtime/tensorrt</code></li>
<li><code>cmake -S . -B build -DAPEXX_ENABLE_TENSORRT=OFF -DAPEXX_ENABLE_CUDA=OFF -DAPEXX_BUILD_PLUGIN_TEST_HARNESS=OFF</code></li>
<li><code>cmake --build build -j</code></li>
<li>Harness run (when shared plugin target is built):</li>
<li><code>./build/apexx_trt_plugin_harness ./build/libapexx_trt_plugins.so</code></li>
<li>or:</li>
<li><code>export APEXX_TRT_PLUGIN_LIB=./build/libapexx_trt_plugins.so</code></li>
<li><code>./build/apexx_trt_plugin_harness</code></li>
</ul>
<h3 id="environment-variables">Environment Variables</h3>
<ul>
<li><code>TENSORRT_ROOT</code>: TensorRT install root (optional)</li>
<li><code>CUDA_HOME</code>: CUDA root (optional)</li>
<li><code>CMAKE_PREFIX_PATH</code>: dependency discovery override (optional)</li>
<li><code>APEXX_TRT_PLUGIN_LIB</code>: path to shared plugin library for harness runtime loading</li>
</ul>
<h3 id="validation-status_2">Validation Status</h3>
<ul>
<li><code>mkdocs build --strict</code>: passed</li>
<li><code>pytest tests/test_import_smoke.py</code>: passed</li>
<li>Local CMake configure/build execution could not be run in this environment because <code>cmake</code> binary is not installed (<code>command not found</code>).</li>
</ul>
<h2 id="latest-update-2026-02-08-tensorrt-tilepack-plugin-real-implementation">Latest Update (2026-02-08): TensorRT TilePack Plugin (Real Implementation)</h2>
<ul>
<li>Read and aligned implementation to:</li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li><code>docs/runtime/PLUGIN_SPECS.md</code> (alias page)</li>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li>Implemented real TensorRT TilePack plugin under:</li>
<li><code>runtime/tensorrt/plugins/tilepack.h</code></li>
<li><code>runtime/tensorrt/plugins/tilepack.cpp</code></li>
<li><code>runtime/tensorrt/plugins/tilepack.cu</code></li>
<li>Implemented plugin contract and behavior:</li>
<li>plugin type/version/namespace:<ul>
<li><code>TilePack</code> / <code>1</code> / <code>apexx</code></li>
</ul>
</li>
<li>tensor contract:<ul>
<li>input0: <code>F[B,C,H,W]</code> FP16</li>
<li>input1: <code>idx[B,K]</code> INT32</li>
<li>output0: <code>P[B,K,C,t,t]</code> FP16</li>
</ul>
</li>
<li><code>getOutputDimensions(...)</code> shape inference for dynamic dims.</li>
<li><code>supportsFormatCombination(...)</code> with linear format + required dtypes.</li>
<li>serialization/deserialization of <code>tile_size</code>.</li>
<li><code>enqueue(...)</code> calls CUDA helper <code>launch_tilepack_fp16(...)</code>.</li>
<li>Implemented CUDA gather kernel:</li>
<li>launches over total elements in <code>P</code></li>
<li>maps each output element to source <code>F</code> via tile index and local <code>(dy, dx)</code></li>
<li>zero-fills invalid tile indices / out-of-bounds accesses</li>
<li>contiguous output layout <code>[B,K,C,t,t]</code>.</li>
<li>Added C++ integration/parity test harness:</li>
<li><code>runtime/tensorrt/tests/tilepack_plugin_test.cpp</code></li>
<li>test covers:<ul>
<li>creator-based plugin construction</li>
<li>plugin serialization/deserialization</li>
<li><code>enqueue(...)</code> execution on CUDA buffers</li>
<li>parity vs host reference implementation.</li>
</ul>
</li>
<li>Added Python parity test for engine-level integration:</li>
<li><code>tests/test_tensorrt_tilepack_parity.py</code></li>
<li>builds TRT engine with TilePack plugin (when TRT Python + CUDA available)</li>
<li>compares output to PyTorch reference (<code>tilepack_reference</code>).</li>
<li>Hardened CMake wiring for real plugin path in <code>runtime/tensorrt/CMakeLists.txt</code>:</li>
<li>fixed runtime library detection guard so <code>nvinfer/cudart</code> discovery actually runs.</li>
<li>gated shared plugin target creation on runtime library availability to avoid configure/link failures on partial installs.</li>
<li>real plugin build remains optional and guarded.</li>
<li><code>apexx_trt_tilepack_test</code> only builds when real plugin path is enabled.</li>
<li>Updated docs:</li>
<li><code>docs/runtime/TENSORRT_BUILD.md</code></li>
<li><code>docs/runtime/TENSORRT.md</code></li>
</ul>
<h3 id="run-commands_3">Run Commands</h3>
<ul>
<li>Python-level checks:</li>
<li><code>python -m pytest -q tests/test_tensorrt_tilepack_parity.py tests/test_import_smoke.py</code></li>
<li>TensorRT C++ build/test (when <code>cmake</code>, TensorRT, CUDA available):</li>
<li><code>cd runtime/tensorrt</code></li>
<li><code>cmake -S . -B build -DAPEXX_ENABLE_REAL_TILEPACK_PLUGIN=ON</code></li>
<li><code>cmake --build build -j</code></li>
<li><code>./build/apexx_trt_tilepack_test</code></li>
<li>Python TRT parity (optional):</li>
<li><code>export APEXX_TRT_PLUGIN_LIB=/abs/path/to/libapexx_trt_plugins.so</code></li>
<li><code>python -m pytest -q tests/test_tensorrt_tilepack_parity.py</code></li>
</ul>
<h3 id="validation-status_3">Validation Status</h3>
<ul>
<li><code>python -m pytest -q tests/test_tensorrt_tilepack_parity.py tests/test_import_smoke.py</code>:</li>
<li>passed</li>
<li>TRT parity test skipped on CPU-only environment (expected).</li>
<li>Local CMake build/test for TensorRT plugin could not be executed in this environment because <code>cmake</code> is unavailable.</li>
</ul>
<h3 id="remaining-work_2">Remaining Work</h3>
<ul>
<li>Add INT8 support path for TilePack plugin (currently FP16-only).</li>
<li>Add stronger shape/stride guard coverage for dynamic-shape edge cases in C++ tests.</li>
<li>Add CI GPU lane for TensorRT plugin parity/perf once CUDA runners are available.</li>
</ul>
<h2 id="latest-update-2026-02-08-tensorrt-tileunpackfusion-plugin-priority-alpha">Latest Update (2026-02-08): TensorRT TileUnpackFusion Plugin (Priority + Alpha)</h2>
<ul>
<li>Read and aligned implementation to:</li>
<li><code>docs/CONTEXT.md</code></li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li><code>docs/runtime/PLUGIN_SPECS.md</code></li>
<li>Implemented real TensorRT <code>TileUnpackFusion</code> plugin:</li>
<li><code>runtime/tensorrt/plugins/tileunpackfusion.h</code></li>
<li><code>runtime/tensorrt/plugins/tileunpackfusion.cpp</code></li>
<li><code>runtime/tensorrt/plugins/tileunpackfusion.cu</code></li>
<li>Plugin contract implemented (TensorRT dynamic ext):</li>
<li>inputs:<ul>
<li><code>F_base[B,C,H,W]</code> FP16</li>
<li><code>P_out[B,K,C,t,t]</code> FP16</li>
<li><code>idx[B,K]</code> INT32</li>
<li><code>levels[B,K]</code> INT32 (priority source for deterministic nesting semantics)</li>
<li>optional <code>alpha[B,1,H,W]</code> FP16</li>
</ul>
</li>
<li>output:<ul>
<li><code>F_merged[B,C,H,W]</code> FP16</li>
</ul>
</li>
<li>Runtime semantics implemented:</li>
<li>deterministic overwrite priority per pixel:<ul>
<li>higher <code>levels</code> wins (e.g. <code>L2 &gt; L1 &gt; L0</code>)</li>
<li>tie-break inside same level by tile order <code>k</code> (later <code>k</code> wins)</li>
</ul>
</li>
<li>two-pass CUDA path:<ul>
<li>pass 1: atomic winner-key map over <code>[B,H,W]</code></li>
<li>pass 2: scatter only winner tile pixels</li>
</ul>
</li>
<li>fusion behavior:<ul>
<li>without alpha: overwrite winner pixel value</li>
<li>with alpha: <code>F = F_base + alpha * (F_winner - F_base)</code> (per pixel/channel)</li>
</ul>
</li>
<li>output map starts from dense base copy, so non-selected pixels stay unchanged</li>
<li>CMake/runtime wiring:</li>
<li>updated <code>runtime/tensorrt/CMakeLists.txt</code></li>
<li>added build option:<ul>
<li><code>APEXX_ENABLE_REAL_TILEUNPACKFUSION_PLUGIN</code> (default <code>ON</code>)</li>
</ul>
</li>
<li>real plugin sources are linked into shared plugin library when TRT/CUDA libs are available</li>
<li>added C++ test target:<ul>
<li><code>apexx_trt_tileunpackfusion_test</code></li>
</ul>
</li>
<li>Added C++ priority correctness harness:</li>
<li><code>runtime/tensorrt/tests/tileunpackfusion_plugin_test.cpp</code></li>
<li>crafted overlap case validates <code>L2</code> overwrite over <code>L1/L0</code> on same region</li>
<li>Added Python TensorRT parity test vs PyTorch reference path:</li>
<li><code>tests/test_tensorrt_tileunpackfusion_parity.py</code></li>
<li>compares TRT plugin output to <code>TileUnpackTorch + FusionGate</code> composed reference</li>
<li>Updated docs:</li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li><code>docs/runtime/TENSORRT_BUILD.md</code></li>
</ul>
<h3 id="run-commands_4">Run Commands</h3>
<ul>
<li>Python checks (CPU env will skip CUDA-dependent TRT tests):</li>
<li><code>python -m ruff check tests/test_tensorrt_tileunpackfusion_parity.py</code></li>
<li><code>python -m pytest -q tests/test_tensorrt_tileunpackfusion_parity.py tests/test_tensorrt_tilepack_parity.py tests/test_import_smoke.py</code></li>
<li>C++ build/test (when <code>cmake</code> + TensorRT + CUDA available):</li>
<li><code>cd runtime/tensorrt</code></li>
<li><code>cmake -S . -B build -DAPEXX_ENABLE_REAL_TILEUNPACKFUSION_PLUGIN=ON</code></li>
<li><code>cmake --build build -j</code></li>
<li><code>./build/apexx_trt_tileunpackfusion_test</code></li>
<li>Optional Python parity run with plugin library:</li>
<li><code>export APEXX_TRT_PLUGIN_LIB=/abs/path/to/libapexx_trt_plugins.so</code></li>
<li><code>python -m pytest -q tests/test_tensorrt_tileunpackfusion_parity.py</code></li>
</ul>
<h3 id="validation-status_4">Validation Status</h3>
<ul>
<li><code>ruff</code> on new parity test: passed.</li>
<li><code>pytest</code> targeted run:</li>
<li>passed for non-TRT tests</li>
<li>TRT parity tests skipped in this CPU-only environment (expected).</li>
<li>Local TensorRT C++ compile/run for the new plugin was not executed here because <code>cmake</code> is unavailable in this environment.</li>
</ul>
<h3 id="remaining-work_3">Remaining Work</h3>
<ul>
<li>Add native blend-mode merge path inside TensorRT plugin (currently overwrite + optional alpha fusion path).</li>
<li>Add stricter input-range safeguards for very large/negative <code>levels</code> to prevent key-overflow edge cases.</li>
<li>Add GPU CI lane that builds <code>apexx_trt_tileunpackfusion_test</code> and runs Python TRT parity.</li>
</ul>
<h2 id="latest-update-2026-02-08-tensorrt-tilessmscan-plugin-forward-backward-flag">Latest Update (2026-02-08): TensorRT TileSSMScan Plugin (Forward + Backward Flag)</h2>
<ul>
<li>Read and aligned implementation to:</li>
<li><code>docs/CONTEXT.md</code></li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li><code>docs/runtime/PLUGIN_SPECS.md</code></li>
<li>Implemented real TensorRT <code>TileSSMScan</code> plugin:</li>
<li><code>runtime/tensorrt/plugins/tilessm_scan.h</code></li>
<li><code>runtime/tensorrt/plugins/tilessm_scan.cpp</code></li>
<li><code>runtime/tensorrt/plugins/tilessm_scan.cu</code></li>
<li>Plugin contract implemented (TensorRT dynamic ext):</li>
<li>inputs:<ul>
<li><code>tokens[B,K,C]</code> FP16</li>
<li><code>decay[C]</code>, <code>input_gain[C]</code>, <code>output_gain[C]</code>, <code>state_bias[C]</code> FP16</li>
<li>optional <code>init_state[B,C]</code> FP16</li>
</ul>
</li>
<li>outputs:<ul>
<li><code>y[B,K,C]</code> FP16</li>
<li><code>final_state[B,C]</code> FP16</li>
</ul>
</li>
<li>plugin fields:<ul>
<li><code>direction</code> (<code>0=forward</code>, <code>1=backward</code>)</li>
<li><code>clamp_value</code> (default <code>1e4</code>)</li>
</ul>
</li>
<li>Runtime recurrence semantics implemented to match torch placeholder:</li>
<li>per-channel recurrence across <code>K</code>:<ul>
<li><code>state = decay * state + (1 - decay) * (input_gain * token + state_bias)</code></li>
<li><code>y = output_gain * state</code></li>
</ul>
</li>
<li>stability constraints:<ul>
<li><code>decay</code> clamped to <code>(1e-6, 1-1e-6)</code></li>
<li><code>token</code> NaN sanitization + clamp to <code>[-clamp_value, clamp_value]</code></li>
</ul>
</li>
<li>backward direction scans from <code>K-1</code> to <code>0</code> while writing outputs in original index positions.</li>
<li>CMake/runtime wiring:</li>
<li>updated <code>runtime/tensorrt/CMakeLists.txt</code></li>
<li>added build option:<ul>
<li><code>APEXX_ENABLE_REAL_TILESSM_PLUGIN</code> (default <code>ON</code>)</li>
</ul>
</li>
<li>real plugin sources are linked into shared plugin library when TRT/CUDA libs are available</li>
<li>added C++ test/benchmark target:<ul>
<li><code>apexx_trt_tilessm_test</code></li>
</ul>
</li>
<li>Added C++ plugin test + microbenchmark harness:</li>
<li><code>runtime/tensorrt/tests/tilessm_scan_plugin_test.cpp</code></li>
<li>validates plugin output vs host reference for:<ul>
<li>forward direction</li>
<li>backward direction</li>
</ul>
</li>
<li>prints lightweight performance metrics from CUDA-event timing:<ul>
<li>average latency (ms)</li>
<li>token throughput (tok/s)</li>
</ul>
</li>
<li>Added Python TensorRT parity tests:</li>
<li><code>tests/test_tensorrt_tilessm_parity.py</code></li>
<li>compares TensorRT engine outputs to <code>tilessm_scan_reference(...)</code> for forward/backward on small shapes.</li>
<li>Updated docs:</li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li><code>docs/runtime/TENSORRT_BUILD.md</code></li>
</ul>
<h3 id="run-commands_5">Run Commands</h3>
<ul>
<li>Python checks (CPU env will skip CUDA-dependent TRT tests):</li>
<li><code>python -m ruff check tests/test_tensorrt_tilessm_parity.py</code></li>
<li><code>python -m pytest -q tests/test_tensorrt_tilessm_parity.py tests/test_tensorrt_tilepack_parity.py tests/test_tensorrt_tileunpackfusion_parity.py tests/test_import_smoke.py</code></li>
<li>C++ build/test/bench (when <code>cmake</code> + TensorRT + CUDA available):</li>
<li><code>cd runtime/tensorrt</code></li>
<li><code>cmake -S . -B build -DAPEXX_ENABLE_REAL_TILESSM_PLUGIN=ON</code></li>
<li><code>cmake --build build -j</code></li>
<li><code>./build/apexx_trt_tilessm_test</code></li>
<li>Optional Python parity run with plugin library:</li>
<li><code>export APEXX_TRT_PLUGIN_LIB=/abs/path/to/libapexx_trt_plugins.so</code></li>
<li><code>python -m pytest -q tests/test_tensorrt_tilessm_parity.py</code></li>
</ul>
<h3 id="validation-status_5">Validation Status</h3>
<ul>
<li><code>ruff</code> on new TRT TileSSM parity test: passed.</li>
<li><code>pytest</code> targeted run:</li>
<li>passed for non-TRT tests</li>
<li>TRT parity tests skipped in this CPU-only environment (expected).</li>
<li>Local TensorRT C++ compile/run for new TileSSM plugin was not executed here because <code>cmake</code> is unavailable in this environment.</li>
</ul>
<h3 id="remaining-work_4">Remaining Work</h3>
<ul>
<li>Add TensorRT-side multi-direction merge modes (<code>sum/avg/gated</code>) beyond single-direction plugin field.</li>
<li>Add broader dtype support (<code>fp32</code>/<code>bf16</code>) if needed for debugging and parity triage.</li>
<li>Add GPU CI lane that builds and runs <code>apexx_trt_tilessm_test</code> and Python TRT parity tests.</li>
</ul>
<h2 id="latest-update-2026-02-08-tensorrt-decodenms-plugin-det-postprocessing-in-engine">Latest Update (2026-02-08): TensorRT Decode+NMS Plugin (DET Postprocessing In-Engine)</h2>
<ul>
<li>Read and aligned implementation to:</li>
<li><code>docs/CONTEXT.md</code></li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li><code>docs/ENGINEERING_SPEC.md</code> (DET decode/NMS behavior)</li>
<li>Implemented real TensorRT Decode+NMS plugin:</li>
<li><code>runtime/tensorrt/plugins/nms_decode.h</code></li>
<li><code>runtime/tensorrt/plugins/nms_decode.cpp</code></li>
<li><code>runtime/tensorrt/plugins/nms_decode.cu</code></li>
<li>Plugin contract implemented (TensorRT dynamic ext):</li>
<li>inputs:<ul>
<li><code>cls_logits[B,N,C]</code> FP16</li>
<li><code>box_reg[B,N,4]</code> FP16 (<code>l,t,r,b</code> logits)</li>
<li><code>quality[B,N]</code> FP16</li>
<li><code>centers[N,2]</code> FP16</li>
<li><code>strides[N]</code> FP16</li>
</ul>
</li>
<li>outputs:<ul>
<li><code>boxes[B,max_det,4]</code> FP16</li>
<li><code>scores[B,max_det]</code> FP16</li>
<li><code>class_ids[B,max_det]</code> INT32</li>
<li><code>valid_counts[B]</code> INT32</li>
</ul>
</li>
<li>plugin fields:<ul>
<li><code>max_detections</code></li>
<li><code>pre_nms_topk</code></li>
<li><code>score_threshold</code></li>
<li><code>iou_threshold</code></li>
</ul>
</li>
<li>Runtime semantics implemented to match project PyTorch path:</li>
<li>decode:<ul>
<li><code>dist = softplus(clamp(box_reg,-20,20)) * stride</code></li>
<li><code>xyxy</code> from <code>(cx,cy)</code> and decoded distances</li>
</ul>
</li>
<li>score:<ul>
<li><code>sigmoid(clamp(cls,-60,60)) * sigmoid(clamp(quality,-60,60))</code></li>
</ul>
</li>
<li>candidate selection:<ul>
<li>threshold by <code>score_threshold</code></li>
<li>top-k by <code>pre_nms_topk</code> with deterministic tie-break (<code>pair_id = anchor*C + class</code>)</li>
</ul>
</li>
<li>class-wise deterministic NMS:<ul>
<li>IoU suppression per class</li>
<li>final ordering by score descending, tie-break by pair-id ascending</li>
</ul>
</li>
<li>padding semantics:<ul>
<li>invalid rows use <code>class_ids=-1</code>, <code>scores=0</code>, <code>boxes=0</code></li>
</ul>
</li>
<li>CMake/runtime wiring:</li>
<li>updated <code>runtime/tensorrt/CMakeLists.txt</code></li>
<li>added build option:<ul>
<li><code>APEXX_ENABLE_REAL_NMS_DECODE_PLUGIN</code> (default <code>ON</code>)</li>
</ul>
</li>
<li>added C++ test target:<ul>
<li><code>apexx_trt_nms_decode_test</code></li>
</ul>
</li>
<li>Added C++ plugin parity/benchmark harness:</li>
<li><code>runtime/tensorrt/tests/nms_decode_plugin_test.cpp</code></li>
<li>compares plugin outputs to host reference</li>
<li>includes corner case checks:<ul>
<li>no boxes (high threshold)</li>
<li>many candidates</li>
</ul>
</li>
<li>includes lightweight latency metric printout</li>
<li>Added Python parity tests vs PyTorch decode+nms reference:</li>
<li><code>tests/test_tensorrt_nms_decode_parity.py</code></li>
<li>covers:<ul>
<li>fixed-seed parity</li>
<li>no boxes corner case</li>
<li>many boxes corner case</li>
</ul>
</li>
<li>Updated docs:</li>
<li>new:<ul>
<li><code>docs/runtime/TENSORRT_POST.md</code></li>
</ul>
</li>
<li>updated:<ul>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li><code>docs/runtime/TENSORRT_BUILD.md</code></li>
<li><code>docs/index.md</code></li>
<li><code>mkdocs.yml</code></li>
</ul>
</li>
</ul>
<h3 id="run-commands_6">Run Commands</h3>
<ul>
<li>Python checks (CPU env will skip CUDA/TRT tests):</li>
<li><code>python -m ruff check tests/test_tensorrt_nms_decode_parity.py tests/test_tensorrt_tilepack_parity.py</code></li>
<li><code>python -m pytest -q tests/test_tensorrt_nms_decode_parity.py tests/test_tensorrt_tilepack_parity.py tests/test_tensorrt_tilessm_parity.py tests/test_tensorrt_tileunpackfusion_parity.py tests/test_det_decode_nms.py tests/test_import_smoke.py</code></li>
<li>C++ build/test (when <code>cmake</code> + TensorRT + CUDA available):</li>
<li><code>cd runtime/tensorrt</code></li>
<li><code>cmake -S . -B build -DAPEXX_ENABLE_REAL_NMS_DECODE_PLUGIN=ON</code></li>
<li><code>cmake --build build -j</code></li>
<li><code>./build/apexx_trt_nms_decode_test</code></li>
<li>Optional Python TRT parity:</li>
<li><code>export APEXX_TRT_PLUGIN_LIB=/abs/path/to/libapexx_trt_plugins.so</code></li>
<li><code>python -m pytest -q tests/test_tensorrt_nms_decode_parity.py</code></li>
</ul>
<h3 id="validation-status_6">Validation Status</h3>
<ul>
<li><code>ruff</code> on changed TensorRT parity tests: passed.</li>
<li><code>pytest</code> targeted suite:</li>
<li>passed for CPU-safe tests</li>
<li>TRT tests skipped on CPU-only environment (expected).</li>
<li><code>mkdocs build --strict</code> could not run in this environment because <code>mkdocs</code> is not installed.</li>
<li>Local TensorRT C++ compile/run for new Decode+NMS plugin was not executed here because <code>cmake</code> is unavailable in this environment.</li>
</ul>
<h3 id="remaining-work_5">Remaining Work</h3>
<ul>
<li>Optional backend integration path to TensorRT EfficientNMS (when exact deterministic parity requirements are satisfied).</li>
<li>Performance optimization of CUDA kernel (current implementation prioritizes correctness/determinism over throughput).</li>
<li>GPU CI lane to compile/run <code>apexx_trt_nms_decode_test</code> and Python TRT decode+NMS parity tests.</li>
</ul>
<h2 id="latest-update-2026-02-08-tensorrt-python-engine-builder-int8-calibrator">Latest Update (2026-02-08): TensorRT Python Engine Builder + INT8 Calibrator</h2>
<ul>
<li>Read and aligned implementation to:</li>
<li><code>docs/CONTEXT.md</code></li>
<li><code>docs/ENGINEERING_SPEC.md</code></li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li><code>docs/runtime/TENSORRT_BUILD.md</code></li>
<li><code>docs/runtime/TENSORRT_POST.md</code></li>
<li>Added Python TensorRT builder package:</li>
<li><code>apex_x/runtime/tensorrt/__init__.py</code></li>
<li><code>apex_x/runtime/tensorrt/builder.py</code></li>
<li><code>apex_x/runtime/tensorrt/calibrator.py</code></li>
<li>Added API exports:</li>
<li>updated <code>apex_x/runtime/__init__.py</code></li>
<li>runtime now exposes:<ul>
<li><code>TensorRTEngineBuilder</code></li>
<li><code>TensorRTEngineBuildConfig</code></li>
<li><code>EngineBuildResult</code></li>
<li><code>TensorRTEntropyCalibrator</code></li>
<li>calibration typing/config objects</li>
</ul>
</li>
<li>Builder capabilities implemented:</li>
<li>build from ONNX:<ul>
<li><code>TensorRTEngineBuilder.build_from_onnx(...)</code></li>
</ul>
</li>
<li>build from direct TRT network factory:<ul>
<li><code>TensorRTEngineBuilder.build_from_network(...)</code></li>
</ul>
</li>
<li>optional plugin-library loading via <code>ctypes</code> with global symbol visibility</li>
<li>custom plugin registry checks for:<ul>
<li>required: <code>TilePack</code>, <code>TileSSMScan</code>, <code>TileUnpackFusion</code></li>
<li>optional: <code>DecodeNMS</code></li>
</ul>
</li>
<li>FP16 build support</li>
<li>INT8 build support with calibrator attachment and cache path</li>
<li>router/KAN FP16 constraints during INT8 builds via layer-name keywords</li>
<li>Calibrator capabilities implemented:</li>
<li><code>TensorRTEntropyCalibrator</code> (IInt8EntropyCalibrator2-backed when TRT is available)</li>
<li>streams calibration batches from iterable loader</li>
<li>supports batch format:<ul>
<li>single-input <code>np.ndarray</code></li>
<li>multi-input <code>dict[str, np.ndarray]</code></li>
</ul>
</li>
<li>stable cache I/O:<ul>
<li><code>read_calibration_cache()</code></li>
<li><code>write_calibration_cache(...)</code></li>
</ul>
</li>
<li>keeps device tensors alive across <code>get_batch(...)</code> calls</li>
<li>Added docs:</li>
<li>new:<ul>
<li><code>docs/runtime/TENSORRT_INT8.md</code></li>
</ul>
</li>
<li>updated:<ul>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li><code>docs/index.md</code></li>
<li><code>mkdocs.yml</code></li>
</ul>
</li>
<li>Added tests:</li>
<li><code>tests/test_tensorrt_builder_smoke.py</code></li>
<li>coverage:<ul>
<li>no-TRT failure path (deterministic error)</li>
<li>FP16 tiny-network smoke build (skip with capability guards)</li>
<li>INT8 tiny-network + calibration smoke build (skip with capability guards)</li>
</ul>
</li>
</ul>
<h3 id="engine-build-commands">Engine Build Commands</h3>
<ul>
<li>FP16 direct-network smoke:</li>
<li><code>python -m pytest -q tests/test_tensorrt_builder_smoke.py -k fp16</code></li>
<li>INT8 direct-network smoke:</li>
<li><code>python -m pytest -q tests/test_tensorrt_builder_smoke.py -k int8</code></li>
<li>Python build usage (programmatic):</li>
<li>use <code>TensorRTEngineBuilder.build_from_network(...)</code> or <code>build_from_onnx(...)</code></li>
<li>recommended artifact paths:<ul>
<li>engines: <code>artifacts/trt/*.engine</code></li>
<li>calibration caches: <code>artifacts/trt/*.cache</code></li>
</ul>
</li>
</ul>
<h3 id="artifact-locations">Artifact Locations</h3>
<ul>
<li>Engine outputs:</li>
<li>path passed to <code>engine_path</code> (recommended: <code>artifacts/trt/</code>)</li>
<li>INT8 calibration cache:</li>
<li>path passed via <code>TensorRTEngineBuildConfig.calibration_cache_path</code></li>
<li>recommended: <code>artifacts/trt/int8.cache</code></li>
</ul>
<h3 id="validation-status_7">Validation Status</h3>
<ul>
<li><code>ruff</code> on changed runtime TRT builder/calibrator files: passed.</li>
<li><code>mypy</code> on changed runtime TRT builder/calibrator files: passed.</li>
<li><code>pytest</code> targeted run:</li>
<li>passed for CPU-safe tests</li>
<li>CUDA/TRT-dependent tests skipped in this environment (expected).</li>
<li><code>mkdocs build --strict</code> could not run in this environment because <code>mkdocs</code> is not installed.</li>
</ul>
<h3 id="remaining-work_6">Remaining Work</h3>
<ul>
<li>Add CLI wrapper command for Python TRT builder workflow (currently programmatic API only).</li>
<li>Add ONNX custom-op placeholder integration example with concrete node/plugin mapping.</li>
<li>Add GPU CI lane executing TRT builder smoke tests with plugin library loading.</li>
</ul>
<h2 id="latest-update-2026-02-08-unified-gpu-benchmark-suite-torchtritontrt">Latest Update (2026-02-08): Unified GPU Benchmark Suite (Torch/Triton/TRT)</h2>
<ul>
<li>Read and aligned implementation to:</li>
<li><code>docs/CONTEXT.md</code></li>
<li><code>docs/PRD.md</code></li>
<li><code>docs/ENGINEERING_SPEC.md</code></li>
<li><code>docs/PERF.md</code></li>
<li><code>docs/runtime/TRITON.md</code></li>
<li>Added unified CUDA benchmark runner:</li>
<li><code>apex_x/bench/gpu_bench.py</code></li>
<li>Runner coverage implemented:</li>
<li>Tile ops microbench:<ul>
<li><code>TilePack</code> (torch reference vs Triton dispatch)</li>
<li><code>TileUnpack</code> (torch reference vs Triton dispatch)</li>
<li><code>FusionGate</code> (torch reference vs Triton dispatch)</li>
</ul>
</li>
<li>TileSSM microbench:<ul>
<li>torch reference vs Triton dispatch</li>
<li>TensorRT plugin path benchmark for <code>TileSSMScan</code> (when TensorRT Python + plugin library are available)</li>
</ul>
</li>
<li>End-to-end FF inference benchmark:<ul>
<li>torch eager path</li>
<li>torch+Triton fast-path (Triton requested for inference scan with fallback guard)</li>
<li>optional TensorRT engine benchmark (<code>--trt-engine-path</code>)</li>
</ul>
</li>
<li>Report outputs implemented:</li>
<li>JSON: <code>artifacts/perf_gpu.json</code> (default)</li>
<li>Markdown: <code>artifacts/perf_gpu.md</code> (default)</li>
<li>Metrics include <code>p50/p95</code>, throughput (<code>tiles/tokens/elements/frames per second</code>), and CUDA peak memory (<code>max_memory_allocated</code>).</li>
<li>Added GPU perf documentation:</li>
<li><code>docs/PERF_GPU.md</code></li>
<li>Updated docs navigation:</li>
<li><code>docs/index.md</code></li>
<li><code>mkdocs.yml</code></li>
</ul>
<h3 id="run-commands_7">Run Commands</h3>
<ul>
<li>Default fixed-profile GPU benchmark:</li>
<li><code>python -m apex_x.bench.gpu_bench --output-json artifacts/perf_gpu.json --output-md artifacts/perf_gpu.md</code></li>
<li>Faster smoke-like run:</li>
<li><code>python -m apex_x.bench.gpu_bench --warmup 3 --iters 10 --output-json artifacts/perf_gpu_smoke.json --output-md artifacts/perf_gpu_smoke.md</code></li>
<li>Enable TensorRT plugin TileSSM bench:</li>
<li><code>export APEXX_TRT_PLUGIN_LIB=/abs/path/to/libapexx_trt_plugins.so</code></li>
<li><code>python -m apex_x.bench.gpu_bench</code></li>
<li>Optional TensorRT engine benchmark:</li>
<li><code>python -m apex_x.bench.gpu_bench --trt-engine-path artifacts/trt/apex_x.engine --trt-input-shape input=1x3x128x128</code></li>
</ul>
<h3 id="artifact-locations_1">Artifact Locations</h3>
<ul>
<li>JSON report:</li>
<li><code>artifacts/perf_gpu.json</code> (or <code>--output-json</code>)</li>
<li>Markdown summary:</li>
<li><code>artifacts/perf_gpu.md</code> (or <code>--output-md</code>)</li>
</ul>
<h3 id="validation-status_8">Validation Status</h3>
<ul>
<li>Local run in this environment:</li>
<li>suite executes with capability guards</li>
<li>when CUDA is unavailable, output is <code>status=skipped</code> with explicit reason.</li>
<li>Static checks and mypy/test status are tracked per current session commands.</li>
</ul>
<h3 id="remaining-work_7">Remaining Work</h3>
<ul>
<li>Add GPU CI lane to run <code>apex_x/bench/gpu_bench.py</code> on fixed CUDA runners and compare against a committed GPU baseline.</li>
<li>Add optional CSV/time-series exporter for long-run perf trend tracking.</li>
<li>Add explicit TRT engine profile presets for common deployed input signatures.</li>
</ul>
<h2 id="latest-update-2026-02-08-gpu-perf-regression-ci-workflow-baseline-compare">Latest Update (2026-02-08): GPU Perf Regression CI Workflow + Baseline Compare</h2>
<ul>
<li>Read and aligned implementation to:</li>
<li><code>docs/CONTEXT.md</code></li>
<li><code>docs/PRD.md</code></li>
<li><code>docs/ENGINEERING_SPEC.md</code></li>
<li>Added GPU perf regression workflow:</li>
<li><code>.github/workflows/perf_gpu.yml</code></li>
<li>Workflow behavior:</li>
<li>skipped by default on manual dispatch (<code>run_mode=skip</code>)</li>
<li>executes only when:<ul>
<li>manual dispatch sets <code>run_mode=self-hosted-gpu</code>, or</li>
<li>nightly schedule runs with repository variable <code>APEXX_ENABLE_GPU_NIGHTLY=true</code></li>
</ul>
</li>
<li>runs on <code>runs-on: [self-hosted, linux, x64, gpu]</code></li>
<li>keeps CPU perf regression intact in <code>.github/workflows/ci.yml</code> (<code>perf-regression</code> job unchanged)</li>
<li>Added GPU regression compare script:</li>
<li><code>scripts/perf_regression_gpu.py</code></li>
<li>runs <code>apex_x/bench/gpu_bench.py</code> via Python module API and compares against stored baseline thresholds</li>
<li>Added stored GPU baseline JSON:</li>
<li><code>scripts/perf_baseline_gpu.json</code></li>
<li>Added documentation:</li>
<li><code>docs/CI_GPU.md</code> (self-hosted setup, nightly switch, baseline maintenance, security notes)</li>
<li>updated docs nav in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
<h3 id="run-commands_8">Run Commands</h3>
<ul>
<li>Local GPU regression compare:</li>
<li><code>python scripts/perf_regression_gpu.py --compare --baseline scripts/perf_baseline_gpu.json --output artifacts/perf_gpu_current_local.json --summary artifacts/perf_gpu_compare_local.json</code></li>
<li>Regenerate baseline template on target GPU runner:</li>
<li><code>python scripts/perf_regression_gpu.py --emit-baseline-template --baseline scripts/perf_baseline_gpu.json</code></li>
<li>Manual workflow run:</li>
<li>dispatch <code>GPU Perf Regression</code> with <code>run_mode=self-hosted-gpu</code></li>
</ul>
<h3 id="artifact-locations_2">Artifact Locations</h3>
<ul>
<li>GPU current run report:</li>
<li><code>artifacts/perf_gpu_current_ci.json</code></li>
<li>GPU compare summary:</li>
<li><code>artifacts/perf_gpu_compare_ci.json</code></li>
<li>Uploaded artifact name in workflow:</li>
<li><code>perf-gpu-regression-artifacts</code></li>
</ul>
<h3 id="validation-status_9">Validation Status</h3>
<ul>
<li>Local validation in this environment:</li>
<li><code>python scripts/perf_regression_gpu.py --help</code>: passed</li>
<li><code>python scripts/perf_regression_gpu.py --compare ...</code>: executed and failed as expected (<code>status=skipped</code> on CPU-only host)</li>
<li><code>ruff check scripts/perf_regression_gpu.py</code>: passed</li>
<li><code>python -m py_compile scripts/perf_regression_gpu.py</code>: passed</li>
<li><code>ruff check .github/workflows/perf_gpu.yml</code>: not applicable (YAML)</li>
</ul>
<h3 id="remaining-work_8">Remaining Work</h3>
<ul>
<li>Calibrate <code>scripts/perf_baseline_gpu.json</code> on the real self-hosted GPU runner and tighten tolerances.</li>
<li>Add optional GPU matrix (per GPU class) with separate baselines when heterogeneous runners are used.</li>
<li>Add GPU docs build validation on the same self-hosted environment if needed.</li>
</ul>
<h2 id="latest-update-2026-02-08-go-runtime-hardening-loaders-batching-metrics-logging-integration">Latest Update (2026-02-08): Go Runtime Hardening (Loaders, Batching Metrics, Logging, Integration)</h2>
<ul>
<li>Read and aligned implementation to:</li>
<li><code>docs/CONTEXT.md</code></li>
<li><code>docs/PRD.md</code></li>
<li><code>docs/ENGINEERING_SPEC.md</code></li>
<li><code>runtime/go/README.md</code></li>
<li>Hardened engine loader paths in <code>runtime/go/internal/service/</code>:</li>
<li>ONNX CPU baseline loader:<ul>
<li><code>adapter_ort.go</code></li>
<li><code>NewORTAdapter(...)</code> now validates and loads model path from flag or <code>APEXX_ORT_MODEL_PATH</code></li>
<li>rejects missing/empty model files</li>
</ul>
</li>
<li>TensorRT loader via CGO:<ul>
<li><code>adapter_tensorrt_cgo.go</code></li>
<li>implements C-side engine file loader/free wrapper</li>
<li>validates engine file path from flag or <code>APEXX_TRT_ENGINE_PATH</code></li>
<li>retains inference execution as baseline/mock response path while loader is real</li>
</ul>
</li>
<li>Implemented dynamic batching observability:</li>
<li><code>batcher.go</code><ul>
<li>tracks enqueue timestamps per request</li>
<li>computes per-batch average queue wait and inference time</li>
<li>records batch errors and structured batch logs</li>
</ul>
</li>
<li><code>metrics.go</code><ul>
<li>added metrics:</li>
<li>batch size avg/max</li>
<li>queue latency avg/max</li>
<li>inference latency avg/max</li>
<li>batch errors</li>
</ul>
</li>
<li>Added structured logging + optional telemetry hooks:</li>
<li><code>http.go</code>, <code>batcher.go</code>, <code>cmd/apexx-runtime/main.go</code></li>
<li>configurable structured logger (<code>json|text</code>, level)</li>
<li>optional hook interface:<ul>
<li><code>telemetry.go</code> (<code>TelemetryHooks</code>, <code>NopTelemetryHooks</code>)</li>
</ul>
</li>
<li>request and batch lifecycle now expose hook call points for OTel integration</li>
<li>Added integration and loader tests:</li>
<li><code>runtime/go/internal/service/integration_test.go</code><ul>
<li>starts HTTP server</li>
<li>validates <code>/health</code></li>
<li>validates structured <code>/predict</code> response</li>
<li>load simulation verifies batching groups requests under pressure</li>
<li>validates expanded <code>/metrics</code> keys</li>
</ul>
</li>
<li><code>runtime/go/internal/service/adapter_ort_test.go</code><ul>
<li>ONNX loader success/failure/env override coverage</li>
</ul>
</li>
<li>Updated runtime docs:</li>
<li>new: <code>docs/runtime/GO_SERVICE.md</code></li>
<li>updated: <code>runtime/go/README.md</code></li>
<li>docs nav updates:<ul>
<li><code>docs/index.md</code></li>
<li><code>mkdocs.yml</code></li>
</ul>
</li>
</ul>
<h3 id="run-commands_9">Run Commands</h3>
<ul>
<li>Go unit + integration tests:</li>
<li><code>cd runtime/go &amp;&amp; go test ./...</code></li>
<li>Go tests with TensorRT build tags and CGO:</li>
<li><code>cd runtime/go &amp;&amp; CGO_ENABLED=1 go test -tags tensorrt ./...</code></li>
<li>Run CPU service mode:</li>
<li><code>cd runtime/go</code></li>
<li><code>mkdir -p models</code></li>
<li>place a non-empty ONNX model at <code>models/apex-x.onnx</code></li>
<li><code>go run ./cmd/apexx-runtime -adapter onnxruntime -model-path models/apex-x.onnx</code></li>
<li>Run TensorRT service mode (loader path):</li>
<li><code>cd runtime/go</code></li>
<li><code>CGO_ENABLED=1 go run -tags tensorrt ./cmd/apexx-runtime -adapter tensorrt -engine-path models/apex-x.plan</code></li>
</ul>
<h3 id="validation-status_10">Validation Status</h3>
<ul>
<li><code>go test ./...</code>: passed</li>
<li><code>CGO_ENABLED=1 go test -tags tensorrt ./...</code>: passed</li>
<li>YAML parse check for docs nav (<code>mkdocs.yml</code>): passed</li>
</ul>
<h3 id="remaining-work_9">Remaining Work</h3>
<ul>
<li>Replace TensorRT adapter mock inference path with actual engine execution and tensor bindings.</li>
<li>Add optional native OpenTelemetry implementation module (tracer/meter exporters) wired to current telemetry hooks.</li>
<li>Add TLS/auth/rate-limit hardening around external-facing runtime service deployments.</li>
</ul>
<h2 id="update-protocol-every-significant-change">Update Protocol (Every Significant Change)</h2>
<ul>
<li>Update this file with:</li>
<li>what changed</li>
<li>why it changed</li>
<li>what to do next</li>
<li>If architecture changed, also update <code>docs/DECISIONS.md</code></li>
<li>If requirements changed, update PRD/spec first, then code</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["navigation.tabs", "navigation.sections", "navigation.top", "search.suggest", "search.highlight", "content.code.copy"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>