<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="https://example.com/apex-x/CONTEXT/">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Context - Apex-X Docs</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/fontawesome.min.css" rel="stylesheet">
        <link href="../css/brands.min.css" rel="stylesheet">
        <link href="../css/solid.min.css" rel="stylesheet">
        <link href="../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Apex-X Docs</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="nav-item">
                                <a href=".." class="nav-link">Home</a>
                            </li>
                            <li class="nav-item">
                                <a href="../PRD/" class="nav-link">PRD</a>
                            </li>
                            <li class="nav-item">
                                <a href="../ENGINEERING_SPEC/" class="nav-link">Engineering Spec</a>
                            </li>
                            <li class="nav-item">
                                <a href="../QAT/" class="nav-link">QAT Policy</a>
                            </li>
                            <li class="nav-item">
                                <a href="../FP8/" class="nav-link">FP8 Policy</a>
                            </li>
                            <li class="nav-item">
                                <a href="../PERF/" class="nav-link">Performance Regression</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/PLUGIN_SPEC/" class="nav-link">Runtime Plugin Spec</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/PLUGIN_SPECS/" class="nav-link">Runtime Plugin Specs Alias</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/CAPS/" class="nav-link">Runtime Capability Detection</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/PARITY/" class="nav-link">Runtime Parity Framework</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/TENSORRT/" class="nav-link">TensorRT Runtime Notes</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/TENSORRT_BUILD/" class="nav-link">TensorRT Build Guide</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/TRITON/" class="nav-link">Triton Runtime Notes</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/TRITON_TILEPACK/" class="nav-link">Triton TilePack</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/TRITON_TILEUNPACK/" class="nav-link">Triton TileUnpack</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/TRITON_FUSION/" class="nav-link">Triton FusionGate</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/TRITON_SSM/" class="nav-link">Triton TileSSM Scan</a>
                            </li>
                            <li class="nav-item">
                                <a href="../runtime/TRITON_FUSED_STAGE1/" class="nav-link">Triton Fused Stage-1</a>
                            </li>
                            <li class="nav-item">
                                <a href="./" class="nav-link active" aria-current="page">Context</a>
                            </li>
                            <li class="nav-item">
                                <a href="../DECISIONS/" class="nav-link">Decisions</a>
                            </li>
                            <li class="nav-item">
                                <a href="../TODO/" class="nav-link">TODO</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../runtime/TRITON_FUSED_STAGE1/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../DECISIONS/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://example.com/apex-x" class="nav-link">apex-x</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#apex-x-project-context-persistent-memory" class="nav-link">Apex-X Project Context (Persistent Memory)</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#authoritative-links-mandatory" class="nav-link">Authoritative Links (Mandatory)</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#project-identity" class="nav-link">Project Identity</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#current-architecture-snapshot" class="nav-link">Current Architecture Snapshot</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#what-exists-right-now-2026-02-07" class="nav-link">What Exists Right Now (2026-02-07)</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#invariants-to-preserve" class="nav-link">Invariants to Preserve</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#open-risks" class="nav-link">Open Risks</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#immediate-next-steps" class="nav-link">Immediate Next Steps</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#latest-update-2026-02-08-triton-fused-stage-1-pipeline" class="nav-link">Latest Update (2026-02-08): Triton Fused Stage-1 Pipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#latest-update-2026-02-08-triton-tilessm-scan-baseline" class="nav-link">Latest Update (2026-02-08): Triton TileSSM Scan Baseline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#latest-update-2026-02-08-triton-tilessm-multi-direction" class="nav-link">Latest Update (2026-02-08): Triton TileSSM Multi-Direction</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#latest-update-2026-02-08-tensorrt-build-hardening-harness" class="nav-link">Latest Update (2026-02-08): TensorRT Build Hardening + Harness</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#update-protocol-every-significant-change" class="nav-link">Update Protocol (Every Significant Change)</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="apex-x-project-context-persistent-memory">Apex-X Project Context (Persistent Memory)</h1>
<h2 id="authoritative-links-mandatory">Authoritative Links (Mandatory)</h2>
<ul>
<li>PRD: <code>docs/PRD.md</code></li>
<li>Engineering spec: <code>docs/ENGINEERING_SPEC.md</code></li>
<li>Runtime plugin spec: <code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li>Decisions log: <code>docs/DECISIONS.md</code></li>
<li>Active worklist: <code>docs/TODO.md</code></li>
</ul>
<h2 id="project-identity">Project Identity</h2>
<ul>
<li>Name: <code>apex-x</code></li>
<li>Version: <code>0.1.0</code></li>
<li>License: <code>Apache-2.0</code></li>
<li>Current baseline: CPU-only reference implementation</li>
</ul>
<h2 id="current-architecture-snapshot">Current Architecture Snapshot</h2>
<ul>
<li>Dual-stream concept established in docs (PV dense + FF sparse)</li>
<li>Utility-based router contracts defined</li>
<li>Continuous and deterministic budgeting contracts defined</li>
<li>Quadtree nesting policy defined (<code>L0/L1/L2</code>)</li>
<li>TilePack/TileUnpack and ordering contracts defined</li>
<li>Tile-SSM placeholder behavior defined</li>
</ul>
<h2 id="what-exists-right-now-2026-02-07">What Exists Right Now (2026-02-07)</h2>
<ul>
<li>Repository scaffold created:</li>
<li><code>apex_x/</code>, <code>tests/</code>, <code>docs/</code>, <code>docs/runtime/</code>, <code>examples/</code>, <code>scripts/</code>, <code>runtime/</code>, <code>.github/workflows/</code></li>
<li>Governance/Open-source files added:</li>
<li><code>LICENSE</code>, <code>CODE_OF_CONDUCT.md</code>, <code>CONTRIBUTING.md</code>, <code>SECURITY.md</code></li>
<li>Authoritative docs added/updated:</li>
<li><code>docs/PRD.md</code> (full)</li>
<li><code>docs/ENGINEERING_SPEC.md</code> (full)</li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code></li>
<li>CPU baseline code added:</li>
<li><code>apex_x/config/schema.py</code></li>
<li><code>apex_x/routing/core.py</code></li>
<li><code>apex_x/tiles/ops.py</code></li>
<li><code>apex_x/utils/ssm.py</code></li>
<li><code>apex_x/model/core.py</code></li>
<li>Validation assets added:</li>
<li><code>tests/test_router.py</code></li>
<li><code>tests/test_tile_ops.py</code></li>
<li><code>tests/test_model.py</code></li>
<li><code>scripts/perf_regression.py</code></li>
<li><code>.github/workflows/ci.yml</code></li>
<li>Tooling and developer workflow baseline:</li>
<li><code>pyproject.toml</code> now targets <code>python&gt;=3.11</code></li>
<li>runtime deps: <code>torch</code>, <code>numpy</code>, <code>typer</code>, <code>rich</code>, <code>pydantic</code></li>
<li>dev deps/tools: <code>pytest</code>, <code>ruff</code>, <code>black</code>, <code>mypy</code>, <code>pre-commit</code></li>
<li>pre-commit hooks: <code>.pre-commit-config.yaml</code></li>
<li>CI now runs lint + typecheck + tests on <code>ubuntu-latest</code> with CPU torch index</li>
<li>Package skeleton and public API surfaces:</li>
<li>Created package layout: <code>apex_x/config/</code>, <code>apex_x/model/</code>, <code>apex_x/tiles/</code>, <code>apex_x/routing/</code>, <code>apex_x/losses/</code>, <code>apex_x/train/</code>, <code>apex_x/infer/</code>, <code>apex_x/data/</code>, <code>apex_x/export/</code>, <code>apex_x/bench/</code>, <code>apex_x/runtime/</code>, <code>apex_x/utils/</code></li>
<li>Root API now exports required surfaces in <code>apex_x/__init__.py</code>:<ul>
<li><code>ApexXConfig</code>, <code>ApexXModel</code></li>
<li><code>Router</code>, <code>BudgetController</code></li>
<li><code>TilePack</code>, <code>TileUnpack</code></li>
<li><code>Exporter</code></li>
</ul>
</li>
<li>Added import smoke coverage in <code>tests/test_import_smoke.py</code></li>
<li>Migrated baseline code into package modules and removed legacy flat modules to avoid namespace ambiguity</li>
<li>Nested configuration system implemented:</li>
<li>New nested config domains in <code>apex_x/config/schema.py</code>:<ul>
<li><code>ModelConfig</code> (profiles, channels, strides, tile sizes, Kmax, nesting depth)</li>
<li><code>RoutingConfig</code> (budgets B/B1/B2/B3, costs, hysteresis/split thresholds)</li>
<li><code>TrainConfig</code> (curriculum, dual-<code>mu</code> parameters, distill weights, PCGrad++, QAT toggles)</li>
<li><code>DataConfig</code> (COCO paths and augmentation knobs)</li>
<li><code>RuntimeConfig</code> (precision profile, export/runtime toggles)</li>
</ul>
</li>
<li>Top-level <code>ApexXConfig</code> now nests all sections and performs cross-section validation</li>
<li>Added YAML + CLI-style override support in <code>apex_x/config/io.py</code>:<ul>
<li><code>load_yaml_config(path, overrides=...)</code></li>
<li><code>apply_overrides(cfg, [\"section.key=value\", ...])</code></li>
</ul>
</li>
<li>Added config validation test coverage in <code>tests/test_config.py</code> + fixture <code>tests/fixtures/apex_x_config.yaml</code></li>
<li>Updated model to consume nested config fields in <code>apex_x/model/core.py</code></li>
<li>Added <code>PyYAML</code> + <code>types-PyYAML</code> to project dependencies for runtime + typing support</li>
<li>Reproducibility and logging utilities implemented:</li>
<li>Added <code>apex_x/utils/repro.py</code>:<ul>
<li><code>seed_all()</code></li>
<li><code>set_deterministic_mode()</code></li>
<li><code>deterministic_mode()</code> context manager</li>
<li><code>get_determinism_state()</code></li>
<li><code>reproducibility_notes()</code> (CPU vs CUDA behavior notes)</li>
</ul>
</li>
<li>Added <code>apex_x/utils/logging.py</code>:<ul>
<li><code>configure_logging()</code></li>
<li><code>get_logger()</code> shared <code>apex_x.*</code> logger namespace</li>
<li><code>log_event()</code> structured key/value logging with <code>rich</code></li>
</ul>
</li>
<li>Wired shared logger usage in:<ul>
<li><code>apex_x/config/io.py</code></li>
<li><code>apex_x/model/core.py</code></li>
</ul>
</li>
<li>Added determinism tests in <code>tests/test_repro.py</code></li>
<li>CLI surface implemented:</li>
<li>Added Typer CLI entrypoint in <code>apex_x/cli.py</code> with commands:<ul>
<li><code>apex-x train</code></li>
<li><code>apex-x eval</code></li>
<li><code>apex-x predict</code></li>
<li><code>apex-x bench</code></li>
<li><code>apex-x ablate</code></li>
<li><code>apex-x export</code></li>
</ul>
</li>
<li>All commands load config via YAML and support repeated <code>--set section.key=value</code> overrides</li>
<li>Added console script entrypoint in <code>pyproject.toml</code>:<ul>
<li><code>[project.scripts] apex-x = \"apex_x.cli:main\"</code></li>
</ul>
</li>
<li>Added CLI parsing/behavior tests in <code>tests/test_cli.py</code></li>
<li>Documentation scaffold implemented:</li>
<li>Added MkDocs config in <code>mkdocs.yml</code></li>
<li>Added docs home page in <code>docs/index.md</code> linking PRD/spec/runtime/context/decisions/TODO</li>
<li>Added docs build instructions in <code>docs/index.md</code> and <code>README.md</code></li>
<li>Added docs dependency group in <code>pyproject.toml</code>:<ul>
<li><code>.[docs]</code> with <code>mkdocs</code></li>
</ul>
</li>
<li>Added CI docs build job in <code>.github/workflows/ci.yml</code> running:<ul>
<li><code>mkdocs build --strict</code></li>
</ul>
</li>
<li>Protocol typing standardization implemented:</li>
<li>Added explicit protocol names and aliases for consistency:<ul>
<li><code>RouterProtocol</code></li>
<li><code>BudgetControllerProtocol</code></li>
<li><code>TilePackerProtocol</code></li>
<li><code>RuntimeAdapterProtocol</code></li>
</ul>
</li>
<li>Kept backward-compatible aliases in existing modules (<code>Router</code>, <code>BudgetController</code>, <code>TilePack</code>, etc.)</li>
<li>Added runtime adapter interface + reference adapter:<ul>
<li><code>apex_x/runtime/interfaces.py</code></li>
<li><code>apex_x/runtime/adapters.py</code> (<code>NullRuntimeAdapter</code>)</li>
</ul>
</li>
<li>Updated model typing to consume protocol-based interfaces in <code>apex_x/model/core.py</code></li>
<li>Added minimal protocol-conformance tests:<ul>
<li><code>tests/test_protocols.py</code></li>
</ul>
</li>
<li>Updated import-smoke expectations in <code>tests/test_import_smoke.py</code></li>
<li>CPU smoke example added:</li>
<li>Added <code>examples/smoke_cpu.py</code> that:<ul>
<li>loads YAML config</li>
<li>instantiates <code>ApexXModel</code> stub</li>
<li>runs one forward pass on random input</li>
</ul>
</li>
<li>Added <code>examples/smoke_cpu.yaml</code> default config for fast CPU smoke runs</li>
<li>Added <code>tests/test_smoke_cpu_example.py</code> as a quick smoke pytest</li>
<li>Documentation governance updates:</li>
<li>Added initial convention ADRs in <code>docs/DECISIONS.md</code> for:<ul>
<li>naming conventions</li>
<li>tensor shape contracts</li>
<li>determinism rules</li>
</ul>
</li>
<li>Expanded <code>docs/TODO.md</code> with known future implementation tracks:<ul>
<li>full Triton fused kernels</li>
<li>full TensorRT plugin stack</li>
<li>ONNX Runtime custom-op sparse path and parity gates</li>
</ul>
</li>
<li>Strengthened <code>CONTRIBUTING.md</code> policy to require:<ul>
<li><code>docs/CONTEXT.md</code> update in every significant PR</li>
<li><code>docs/DECISIONS.md</code> update when architectural/convention decisions change</li>
</ul>
</li>
<li>L0 tiling mapping implemented and validated:</li>
<li>Added <code>apex_x/tiles/mapping.py</code> with explicit L0 mapping API:<ul>
<li><code>l0_grid_shape(feature_h, feature_w, tile_size)</code> with strict divisibility checks</li>
<li><code>l0_tile_to_index(ty, tx, grid_h, grid_w)</code> and <code>l0_index_to_tile(index, grid_h, grid_w)</code> with bounds checks</li>
<li>batched helpers:</li>
<li><code>l0_indices_to_coords(indices[B,K], grid_h, grid_w) -&gt; coords[B,K,2]</code></li>
<li><code>l0_coords_to_indices(coords[B,K,2], grid_h, grid_w) -&gt; indices[B,K]</code></li>
</ul>
</li>
<li>Wired tile ops grid sizing to strict mapping validation:<ul>
<li><code>apex_x/tiles/ops.py::tile_grid_shape</code> now uses <code>l0_grid_shape(...)</code></li>
</ul>
</li>
<li>Exported mapping API through <code>apex_x/tiles/__init__.py</code></li>
<li>Added focused tests in <code>tests/test_tile_mapping.py</code>:<ul>
<li>index/coord bijection</li>
<li>batched <code>[B,K]</code> roundtrip</li>
<li>invalid size/divisibility</li>
<li>out-of-bounds and shape/dtype validation</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Hilbert ordering implemented for coordinates and indices:</li>
<li>Added <code>apex_x/tiles/ordering.py</code> with explicit Hilbert APIs:<ul>
<li><code>hilbert_distance(tx, ty, order_n)</code></li>
<li><code>hilbert_order_coords(grid_h, grid_w)</code> for full-grid coordinate traversal</li>
<li><code>hilbert_order_indices(indices, grid_h, grid_w)</code> for subset index ordering</li>
<li><code>hilbert_full_indices(grid_h, grid_w)</code> for complete index traversal</li>
</ul>
</li>
<li>Updated <code>apex_x/tiles/ops.py</code>:<ul>
<li><code>order_idx(..., mode=\"hilbert\")</code> now uses <code>hilbert_order_indices(...)</code></li>
</ul>
</li>
<li>Exported ordering APIs from <code>apex_x/tiles/__init__.py</code></li>
<li>Added fixtures:<ul>
<li><code>tests/fixtures/hilbert_2x2.json</code></li>
<li><code>tests/fixtures/hilbert_4x4.json</code></li>
<li><code>tests/fixtures/hilbert_8x8.json</code></li>
</ul>
</li>
<li>Added fixture-driven tests in <code>tests/test_tile_hilbert.py</code>:<ul>
<li>exact traversal match vs fixtures</li>
<li>determinism across repeated calls</li>
<li>full coverage of all coordinates/indices</li>
<li>subset index ordering stability + parity with <code>order_idx(..., mode=\"hilbert\")</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Scan ordering variants and stable dispatcher implemented:</li>
<li>Extended <code>apex_x/tiles/ordering.py</code> with scan modes and dispatcher utilities:<ul>
<li>Scan variants: <code>l2r</code>, <code>r2l</code>, <code>u2d</code>, <code>d2u</code></li>
<li>Stable dispatcher: <code>order_tile_indices(indices, grid_h, grid_w, mode=...)</code></li>
<li>Mode normalization and aliases: <code>normalize_order_mode(...)</code></li>
<li>supports <code>scan_lr/scan_rl/scan_ud/scan_du</code> + short aliases + canonical names</li>
<li>Scan inverse mapping helper: <code>inverse_scan_mode(...)</code></li>
<li>Explicit scan ordering APIs:</li>
<li><code>scan_order_coords(grid_h, grid_w, mode)</code></li>
<li><code>scan_order_indices(indices, grid_h, grid_w, mode)</code></li>
</ul>
</li>
<li>Updated <code>apex_x/tiles/ops.py</code>:<ul>
<li><code>order_idx(...)</code> now delegates to <code>order_tile_indices(...)</code> (single path for ordering semantics)</li>
</ul>
</li>
<li>Exported new ordering APIs from <code>apex_x/tiles/__init__.py</code></li>
<li>Added tests in <code>tests/test_tile_scan_ordering.py</code>:<ul>
<li>deterministic ordering for all scan variants</li>
<li>alias/normalization correctness</li>
<li>stable ordering behavior on duplicate indices</li>
<li>reversible mapping checks:</li>
<li><code>L2R &lt;-&gt; R2L</code> by horizontal mirror</li>
<li><code>U2D &lt;-&gt; D2U</code> by vertical mirror</li>
<li>dispatcher parity with <code>order_idx(...)</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>L0-&gt;L1 quadtree mapping and metadata implemented:</li>
<li>Added <code>apex_x/tiles/quadtree.py</code> with deterministic L0/L1 mapping APIs:<ul>
<li><code>l1_grid_shape_from_l0(l0_grid_h, l0_grid_w)</code></li>
<li><code>l0_l1_grid_shapes_from_feature(feature_h, feature_w, tile_size_l0, tile_size_l1)</code></li>
<li><code>l0_to_l1_children_coords(l0_ty, l0_tx, l0_grid_h, l0_grid_w)</code> (TL, TR, BL, BR order)</li>
<li><code>l0_to_l1_children_indices(l0_index, l0_grid_h, l0_grid_w)</code></li>
<li>reverse mapping:</li>
<li><code>l1_to_l0_parent_coord(l1_ty, l1_tx, l0_grid_h, l0_grid_w)</code></li>
<li><code>l1_to_l0_parent_index(l1_index, l0_grid_h, l0_grid_w)</code></li>
<li>metadata builder:</li>
<li><code>build_l0_l1_quadtree_meta(parent_indices, l0_grid_h, l0_grid_w) -&gt; L0L1QuadtreeMeta</code></li>
</ul>
</li>
<li>Exported new quadtree APIs in <code>apex_x/tiles/__init__.py</code></li>
<li>Added tests in <code>tests/test_tile_quadtree.py</code>:<ul>
<li>boundary tile mapping correctness (bottom-right L0 tile to L1 children)</li>
<li>reverse parent mapping across full L1 grids</li>
<li>multiple config coverage via <code>(feature_h, feature_w, tile_size_l0, tile_size_l1)</code> parametrization</li>
<li>metadata shape/content checks</li>
<li>invalid ratio/divisibility/out-of-bounds validation checks</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>L2 nesting and overlap priority contract implemented:</li>
<li>Extended <code>apex_x/tiles/quadtree.py</code> with L1-&gt;L2 and combined depth-2 utilities:<ul>
<li>grid shapes:</li>
<li><code>l2_grid_shape_from_l1(...)</code></li>
<li><code>l1_l2_grid_shapes_from_feature(...)</code></li>
<li><code>l0_l1_l2_grid_shapes_from_feature(...)</code></li>
<li>mappings:</li>
<li><code>l1_to_l2_children_coords(...)</code>, <code>l1_to_l2_children_indices(...)</code></li>
<li><code>l2_to_l1_parent_coord(...)</code>, <code>l2_to_l1_parent_index(...)</code></li>
<li><code>l0_to_l2_descendant_indices(...)</code></li>
<li>metadata:</li>
<li><code>L1L2QuadtreeMeta</code></li>
<li><code>L0L1L2QuadtreeMeta</code></li>
<li><code>build_l1_l2_quadtree_meta(...)</code></li>
<li><code>build_l0_l1_l2_quadtree_meta(...)</code></li>
</ul>
</li>
<li>Defined explicit overlap priority tags and helper:<ul>
<li><code>OVERLAP_PRIORITY_L0 = 1</code></li>
<li><code>OVERLAP_PRIORITY_L1 = 2</code></li>
<li><code>OVERLAP_PRIORITY_L2 = 3</code></li>
<li><code>overlap_priority_for_level(...)</code></li>
<li>contract enforces <code>L2 &gt; L1 &gt; L0</code></li>
</ul>
</li>
<li>Exported new L2 and priority APIs through <code>apex_x/tiles/__init__.py</code></li>
<li>Added/expanded tests:<ul>
<li><code>tests/test_tile_quadtree.py</code>:</li>
<li>L1-&gt;L2 mapping correctness (including boundary tiles)</li>
<li>L2-&gt;L1 reverse mapping correctness</li>
<li>L0-&gt;L2 descendant index correctness</li>
<li>combined <code>L0/L1/L2</code> metadata consistency</li>
<li>priority tag contract checks</li>
<li>multi-config and validation coverage for depth-2 shapes</li>
<li><code>tests/test_tile_ops.py</code>:</li>
<li>overlap behavior check using unpack priorities confirming <code>L2</code> overrides <code>L1</code> and <code>L0</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Tile selection debug dataclasses implemented:</li>
<li>Added <code>apex_x/tiles/selection.py</code> with:<ul>
<li><code>TileSelection</code></li>
<li>fields: <code>level</code>, <code>indices</code>, <code>ordered_indices</code>, <code>meta</code>, <code>budgets_used</code></li>
<li>validation:<ul>
<li><code>level</code> constrained to <code>l0/l1/l2</code></li>
<li><code>ordered_indices</code> must be a permutation of <code>indices</code></li>
<li>budgets must be finite and non-negative</li>
</ul>
</li>
<li>JSON persistence:<ul>
<li><code>to_dict()/from_dict()</code></li>
<li><code>save_json()/load_json()</code></li>
</ul>
</li>
<li><code>TileSelectionTrace</code> for multi-level selection records</li>
<li>fields: <code>selections</code>, <code>run_meta</code></li>
<li>helpers:<ul>
<li><code>to_dict()/from_dict()</code></li>
<li><code>save_json()/load_json()</code></li>
<li><code>for_level(level)</code></li>
</ul>
</li>
</ul>
</li>
<li>JSON serialization includes recursive normalization of NumPy arrays/scalars for debug/ablation dumps.</li>
<li>Exported APIs via <code>apex_x/tiles/__init__.py</code>:<ul>
<li><code>TileSelection</code></li>
<li><code>TileSelectionTrace</code></li>
</ul>
</li>
<li>Added unit tests in <code>tests/test_tile_selection.py</code>:<ul>
<li>roundtrip dict serialization</li>
<li>file save/load JSON</li>
<li>validation error cases</li>
<li>trace roundtrip and level lookup</li>
<li>non-empty trace guard</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Tile overlay visualization utility implemented:</li>
<li>Added <code>apex_x/utils/visualization.py</code> with dependency-free overlay rendering:<ul>
<li><code>draw_selected_tiles_overlay(...)</code></li>
<li>supports <code>HWC</code>, <code>CHW</code>, and batch-size-1 image inputs</li>
<li>deterministic tile overlay rendering from selected tile indices + grid/tile size</li>
<li>fill + border blending with deterministic integer alpha math</li>
<li><code>save_overlay_ppm(...)</code></li>
<li>saves overlay to <code>.ppm</code> for debug/ablation without extra image libraries</li>
<li><code>draw_and_save_selected_tiles_overlay(...)</code></li>
<li>convenience wrapper combining render + save</li>
</ul>
</li>
<li>Exported visualization utilities through <code>apex_x/utils/__init__.py</code></li>
<li>Added deterministic tests in <code>tests/test_visualization.py</code>:<ul>
<li>overlay output shape/dtype checks</li>
<li>stable SHA256 hash checks for rendered overlay bytes</li>
<li>stable SHA256 hash checks for saved PPM file bytes</li>
<li>save-path extension validation for <code>.ppm</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Cost model interface and reference implementation added:</li>
<li>Extended routing interfaces in <code>apex_x/routing/interfaces.py</code>:<ul>
<li><code>CostModelProtocol</code></li>
<li>backward-compatible alias <code>CostModel</code></li>
</ul>
</li>
<li>Added <code>apex_x/routing/cost_model.py</code>:<ul>
<li><code>LevelCost</code>:</li>
<li>per-level cost terms:<ul>
<li><code>c_cheap (C_c)</code></li>
<li><code>c_heavy (C_h)</code></li>
<li><code>pack_overhead</code></li>
<li><code>unpack_overhead</code></li>
<li><code>split_overhead (O_split)</code></li>
</ul>
</li>
<li><code>CalibrationRecord</code>:</li>
<li>stores empirical calibration measurements, blend factor, and apply flag</li>
<li><code>StaticCostModel</code>:</li>
<li>level-aware cost computations:<ul>
<li><code>cheap_cost(...)</code></li>
<li><code>heavy_cost(...)</code></li>
<li><code>delta_cost(...)</code></li>
<li><code>split_overhead(...)</code></li>
<li><code>expected_level_cost(...)</code></li>
<li><code>total_cost(...)</code></li>
</ul>
</li>
<li>optional empirical calibration hook:<ul>
<li><code>apply_empirical_calibration(level, measured_timings, blend, apply)</code></li>
<li>stores records in <code>calibration_history</code></li>
</ul>
</li>
<li>serialization:<ul>
<li><code>to_dict()/from_dict()</code></li>
<li><code>save_json()/load_json()</code></li>
</ul>
</li>
</ul>
</li>
<li>Exported cost model symbols through:<ul>
<li><code>apex_x/routing/__init__.py</code></li>
<li><code>apex_x/__init__.py</code> (public API now includes <code>CostModel</code>, <code>CostModelProtocol</code>, <code>StaticCostModel</code>)</li>
</ul>
</li>
<li>Added tests in <code>tests/test_cost_model.py</code>:<ul>
<li>deterministic cost computations and totals</li>
<li>calibration update behavior and history storage</li>
<li>JSON serialization roundtrip</li>
<li>validation/error paths</li>
<li>protocol conformance check (<code>isinstance(..., CostModelProtocol)</code>)</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Oracle set sampler implemented (<code>S</code> sampling for utility oracle training):</li>
<li>Added <code>apex_x/routing/oracle_sampling.py</code>:<ul>
<li><code>OracleSetSample</code> dataclass:</li>
<li><code>indices</code></li>
<li><code>random_indices</code></li>
<li><code>uncertainty_indices</code></li>
<li><code>sample_oracle_set(u_hat, random_fraction, uncertainty_fraction, seed)</code>:</li>
<li>random fraction sampling over all tiles</li>
<li>uncertainty-biased sampling over remaining tiles using PV uncertainty <code>u_hat</code></li>
<li>deterministic behavior under fixed seed</li>
</ul>
</li>
<li>Exported sampler APIs through <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>OracleSetSample</code></li>
<li><code>sample_oracle_set</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_oracle_sampling.py</code>:<ul>
<li>seed determinism checks</li>
<li>count/uniqueness checks for random + uncertainty components</li>
<li>uncertainty-biased distribution check across many seeds</li>
<li>validation/error checks for fraction bounds and invalid uncertainty values</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>Stable tie-breaking helper for selections implemented:</li>
<li>Updated <code>apex_x/routing/core.py</code>:<ul>
<li>added <code>stable_rank_tile_ids(scores)</code> with deterministic ordering policy:</li>
<li>primary key: score descending</li>
<li>secondary key: tile id ascending</li>
<li>wired <code>greedy_utility_per_cost(...)</code> to use <code>stable_rank_tile_ids(...)</code> for score-ratio ranking</li>
</ul>
</li>
<li>Exported helper via <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>stable_rank_tile_ids</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_router.py</code>:<ul>
<li>explicit tie-break behavior validation</li>
<li>repeat-run determinism checks</li>
<li>integration check that greedy selection follows stable tie-breaking under equal utility/cost ratios</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>PV-&gt;FF tile vector aggregation implemented:</li>
<li>Added <code>apex_x/routing/aggregation.py</code>:<ul>
<li><code>compute_ff_tile_bounds_on_pv_grid(...)</code></li>
<li>computes PV-aligned bounds for each FF tile on coarse PV maps</li>
<li><code>aggregate_pv_maps_to_ff_tile_vectors(...)</code></li>
<li>pools per-tile stats from PV maps aligned to FF grid</li>
<li>supported stats: <code>mean</code>, <code>max</code>, <code>var</code></li>
<li>deterministic feature ordering using sorted PV map names</li>
<li><code>PVTileAggregation</code> dataclass:</li>
<li><code>vectors</code> (<code>[B, K, D]</code>)</li>
<li><code>tile_bounds_pv</code> (<code>[K,4]</code>)</li>
<li><code>feature_layout</code> (feature names per channel/stat/map)</li>
</ul>
</li>
<li>Exported aggregation APIs via <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>PVTileAggregation</code></li>
<li><code>compute_ff_tile_bounds_on_pv_grid</code></li>
<li><code>aggregate_pv_maps_to_ff_tile_vectors</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_pv_aggregation.py</code>:<ul>
<li>alignment on simple integer scale mapping</li>
<li>pooled stat correctness (<code>mean/max/var</code>)</li>
<li>output shape and feature layout checks</li>
<li>deterministic outputs across map ordering</li>
<li>non-integer scale edge/boundary alignment</li>
<li>validation error paths</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m pytest -q</code> passed</li>
<li><code>ruff check .</code> passed</li>
<li><code>mypy</code> passed</li>
</ul>
</li>
<li>RouterTinyMLP implemented with utility/split/temporal outputs:</li>
<li>Added <code>apex_x/routing/tiny_mlp.py</code>:<ul>
<li><code>RouterTinyOutput</code> dataclass carrying per-tile tensors:</li>
<li><code>U</code> (<code>[B,K]</code>) utility logits</li>
<li><code>S</code> (<code>[B,K]</code>) split utility logits</li>
<li>optional <code>T</code> (<code>[B,K]</code>) temporal keep logits</li>
<li><code>RouterTinyMLP(nn.Module)</code>:</li>
<li>configurable <code>input_dim</code>, <code>hidden_dim</code>, <code>num_layers</code>, <code>temporal_head</code></li>
<li>forward contract on <code>x[B,K,D]</code> with strict input validation</li>
<li>compatibility method <code>predict_utilities(...)</code> for <code>RouterProtocol</code> usage (<code>input_dim=1</code>)</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>RouterTinyOutput</code></li>
<li><code>RouterTinyMLP</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_router_tiny_mlp.py</code>:<ul>
<li>shape checks for <code>U/S</code> and optional <code>T</code></li>
<li>deterministic outputs for fixed seed/model initialization</li>
<li>backward/gradient-flow checks through router outputs</li>
<li><code>predict_utilities(...)</code> behavior and validation paths</li>
<li>runtime protocol conformance (<code>isinstance(..., RouterProtocol)</code>)</li>
</ul>
</li>
<li>Minor typing fix to keep strict typecheck green:<ul>
<li><code>apex_x/utils/visualization.py</code> now uses an explicit typed cast in <code>_as_hwc_uint8(...)</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Lightweight spline activation + RouterKANLike implemented:</li>
<li>Added <code>apex_x/routing/kan_like.py</code>:<ul>
<li><code>LightweightSplineActivation</code>:</li>
<li>compact per-feature piecewise-linear spline on fixed knot grid</li>
<li>identity initialization for stable startup</li>
<li>explicit <code>nan/inf</code> sanitization + bounded input clamp</li>
<li><code>RouterKANLike</code>:</li>
<li>small-parameter KAN-like router (<code>LayerNorm -&gt; Linear -&gt; Spline -&gt; Linear</code>)</li>
<li>outputs <code>U</code>, <code>S</code>, and optional <code>T</code> via <code>RouterKANOutput</code></li>
<li>bounded head logits via configurable <code>logit_clip</code></li>
<li>protocol-compatible <code>predict_utilities(...)</code> and <code>parameter_count()</code></li>
</ul>
</li>
<li>Exported via <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>LightweightSplineActivation</code></li>
<li><code>RouterKANOutput</code></li>
<li><code>RouterKANLike</code></li>
</ul>
</li>
<li>Added numerical stability tests in <code>tests/test_router_kan_like.py</code>:<ul>
<li>finite outputs under extreme/nonnumeric input values</li>
<li>finite gradients for spline params and inputs</li>
<li>router output shape + finite output checks at large input magnitudes</li>
<li>deterministic initialization/output checks under fixed seeds</li>
<li>small-parameter-count guard</li>
<li><code>RouterProtocol</code> conformance check</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Tensor STE gating implemented for continuous-budget training path:</li>
<li>Added <code>apex_x/routing/gating.py</code>:<ul>
<li><code>sigmoid_probabilities(U, temperature)</code>:</li>
<li>computes <code>p = sigmoid(U)</code> with temperature support</li>
<li>clamps/sanitizes extreme and non-finite logits for numerical stability</li>
<li><code>ste_hard_gate(p, mode, threshold)</code>:</li>
<li>forward hard gate modes:<ul>
<li><code>threshold</code>: <code>g = 1[p &gt;= threshold]</code></li>
<li><code>bernoulli</code>: <code>g ~ Bernoulli(p)</code></li>
</ul>
</li>
<li>backward straight-through estimator via detach trick (<code>dg/dp = 1</code>)</li>
<li><code>ste_gate_from_utilities(U, ...) -&gt; (p, g)</code> convenience function</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>GateMode</code></li>
<li><code>sigmoid_probabilities</code></li>
<li><code>ste_hard_gate</code></li>
<li><code>ste_gate_from_utilities</code></li>
</ul>
</li>
<li>Added autograd and numerical tests in <code>tests/test_ste_gating.py</code>:<ul>
<li>non-zero and finite gradient checks w.r.t. <code>U</code> in threshold mode</li>
<li>non-zero and finite gradient checks w.r.t. <code>U</code> in Bernoulli mode</li>
<li>explicit gradient-form check against sigmoid derivative under linear loss</li>
<li>finite probability checks under extreme/non-finite utility inputs</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>BudgetDualController implemented for continuous-budget dual optimization:</li>
<li>Added <code>apex_x/routing/dual_budget.py</code>:<ul>
<li><code>BudgetDualController</code> (stateful dual variable controller) with:</li>
<li>expected cost:<ul>
<li><code>E[C] = sum_i(p_i * C_h + (1 - p_i) * C_c)</code> via <code>expected_cost(...)</code></li>
</ul>
</li>
<li>budget term:<ul>
<li><code>L_budget = mu * (E[C] - B)</code> via <code>budget_loss(...)</code></li>
</ul>
</li>
<li>projected/clamped dual update:<ul>
<li><code>mu &lt;- clamp(mu + mu_lr * (E[C] - B), [mu_min, mu_max])</code> via <code>update_mu(...)</code></li>
</ul>
</li>
<li>structured debug logging on each update (<code>event='dual_mu_update'</code>) including:<ul>
<li><code>expected_cost</code>, <code>budget</code>, <code>delta</code>, <code>mu_prev</code>, <code>mu_next</code>, <code>clamped</code></li>
</ul>
</li>
<li>support for both sequence and tensor probabilities in expected-cost path</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>BudgetDualController</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_budget_dual_controller.py</code>:<ul>
<li>expected-cost and budget-loss formula checks</li>
<li><code>mu</code> moves in correct direction (<code>E[C] &gt; B</code> increases, <code>E[C] &lt; B</code> decreases)</li>
<li><code>mu</code> clamp bounds respected (<code>mu_min</code> / <code>mu_max</code>)</li>
<li>tensor-path budget loss backpropagates with finite non-zero gradients</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Deterministic greedy inference budgeting implemented with explicit Kmax buffer contract:</li>
<li>Added <code>apex_x/routing/inference_budget.py</code>:<ul>
<li><code>deterministic_greedy_selection(...)</code>:</li>
<li>computes scores exactly as <code>score_i = U_i / DeltaC_i</code></li>
<li>deterministic ordering by:<ul>
<li>primary: score descending</li>
<li>secondary: tile id ascending</li>
</ul>
</li>
<li>selects until budget exhausted and <code>kmax</code> reached</li>
<li>returns <code>GreedySelectionResult</code> with:<ul>
<li><code>selected_indices</code></li>
<li><code>spent_budget</code></li>
<li><code>ordered_candidates</code></li>
<li><code>scores</code></li>
<li><code>kmax_buffer</code> (fixed-length padded buffer)</li>
<li><code>valid_count</code></li>
</ul>
</li>
<li><code>build_kmax_buffer(...)</code> helper for fixed-size runtime buffers</li>
</ul>
</li>
<li>Wired existing public helper to the new deterministic path:<ul>
<li><code>apex_x/routing/core.py::greedy_utility_per_cost(...)</code> now delegates to
  <code>deterministic_greedy_selection(...)</code> and preserves existing return signature</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>GreedySelectionResult</code></li>
<li><code>build_kmax_buffer</code></li>
<li><code>deterministic_greedy_selection</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_inference_budget.py</code>:<ul>
<li>repeat-run determinism for ordering and selections</li>
<li>budget enforcement and <code>kmax</code> cap behavior</li>
<li>stable tie handling (<code>tile_id</code> ascending under equal scores)</li>
<li>Kmax buffer padding/truncation semantics</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Two-stage nesting selection implemented (<code>L0</code> under <code>B1</code>, split under <code>B2</code>):</li>
<li>Extended <code>apex_x/routing/inference_budget.py</code>:<ul>
<li><code>TwoStageSelectionResult</code> dataclass carrying:</li>
<li><code>l0</code> selection result</li>
<li>split parent ordering/selection</li>
<li>spent split budget</li>
<li>generated <code>L1</code> indices</li>
<li>ordered <code>L1</code> indices + fixed-size <code>L1</code> Kmax buffer</li>
<li><code>deterministic_two_stage_selection(...)</code>:</li>
<li>stage 1: deterministic <code>L0</code> selection using <code>U / DeltaC</code> under <code>budget_b1</code> + <code>kmax_l0</code></li>
<li>stage 2: split parent ranking by <code>S / O_split</code> under <code>budget_b2</code></li>
<li>expands selected <code>L0</code> parents to <code>L1</code> children via quadtree mapping</li>
<li>enforces <code>kmax_l1</code> capacity during split expansion</li>
<li>applies deterministic <code>L1</code> ordering via configured order mode (Hilbert/scan)</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>TwoStageSelectionResult</code></li>
<li><code>deterministic_two_stage_selection</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_two_stage_selection.py</code>:<ul>
<li><code>L0</code> selection under <code>B1</code></li>
<li>split candidate selection under <code>B2</code> with <code>S/O_split</code></li>
<li>deterministic tie handling on split parents (<code>tile_id</code> ascending)</li>
<li><code>L1</code> children generation and ordering behavior</li>
<li>determinism across repeated runs</li>
<li><code>kmax_l1</code> capacity/buffer enforcement</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Temporal hysteresis rollout and toggle analysis implemented:</li>
<li>Extended <code>apex_x/routing/core.py</code> hysteresis APIs:<ul>
<li><code>hysteresis_update(...)</code> now validates:</li>
<li><code>theta_on &gt; theta_off</code></li>
<li>equal lengths for <code>utilities_t</code> and <code>prev_mask</code></li>
<li>added <code>hysteresis_rollout(...)</code>:</li>
<li>applies rule over full time sequence with carried <code>z(t-1)</code> state</li>
<li>added <code>count_mask_toggles(...)</code>:</li>
<li>counts total 0/1 transitions across time (for anti-flicker evaluation)</li>
</ul>
</li>
<li>Exported in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>hysteresis_rollout</code></li>
<li><code>count_mask_toggles</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_hysteresis_temporal.py</code>:<ul>
<li>deadband behavior preserves previous mask state (<code>z(t-1)</code>) when utility remains between thresholds</li>
<li>synthetic noisy sequence shows reduced toggling vs single-threshold baseline</li>
<li>validation/error-path checks for threshold ordering and shape consistency</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Routing diagnostics implemented and surfaced in model/train/infer paths:</li>
<li>Added <code>apex_x/routing/diagnostics.py</code>:<ul>
<li><code>utility_histogram(...)</code> for per-level utility histogram summaries</li>
<li><code>build_routing_diagnostics(...)</code> producing:</li>
<li>selected ratios/counts per level</li>
<li>utility histograms per level</li>
<li>budget usage (<code>used</code>, <code>budget</code>, <code>ratio</code>)</li>
<li>dual variable history (<code>mu_history</code>)</li>
</ul>
</li>
<li>Exported diagnostics APIs through <code>apex_x/routing/__init__.py</code></li>
<li>Integrated diagnostics into <code>apex_x/model/core.py</code>:<ul>
<li>model outputs now include <code>routing_diagnostics</code></li>
<li>dual controller (<code>BudgetDualController</code>) state tracked in <code>mu_history</code></li>
<li>optional dual update path enabled via <code>forward(..., update_dual=True)</code></li>
<li>structured logs now include selected ratio, budget usage ratio, and latest <code>mu</code></li>
</ul>
</li>
<li>Updated <code>apex_x/train/__init__.py</code> and <code>apex_x/infer/__init__.py</code>:<ul>
<li>train placeholder logs/returns routing diagnostics summary fields</li>
<li>infer placeholder returns diagnostics from model outputs</li>
</ul>
</li>
<li>Updated CLI integration in <code>apex_x/cli.py</code>:<ul>
<li><code>train</code> now performs short warmup forwards with dual updates and reports diagnostics</li>
<li><code>predict</code> now reads infer diagnostics and logs budget usage ratio</li>
</ul>
</li>
<li>Added tests in <code>tests/test_routing_diagnostics.py</code>:<ul>
<li>diagnostics presence in inference outputs</li>
<li>diagnostics propagation through train/infer placeholders</li>
<li><code>mu_history</code> progression when dual updates are enabled</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Config-driven feature toggles added for forced-off routing/training paths:</li>
<li>Extended <code>apex_x/config/schema.py</code>:<ul>
<li><code>ModelConfig</code> toggles:</li>
<li><code>force_dense_routing</code> (router off =&gt; dense tile activation)</li>
<li><code>disable_nesting</code> (effective nesting depth forced to 0)</li>
<li><code>disable_ssm</code> (bypass Tile-SSM mixing)</li>
<li><code>TrainConfig</code> toggles:</li>
<li><code>disable_distill</code></li>
<li><code>disable_pcgradpp</code></li>
<li>Added helper methods:</li>
<li><code>ModelConfig.effective_nesting_depth()</code></li>
<li><code>ModelConfig.router_enabled()</code></li>
<li><code>ModelConfig.ssm_enabled()</code></li>
<li><code>TrainConfig.distill_enabled()</code></li>
<li><code>TrainConfig.pcgradpp_enabled()</code></li>
<li>Validation updated so <code>disable_nesting=true</code> can force nesting off without requiring manual <code>kmax_l1/l2</code> and <code>budget_b3</code> cleanup.</li>
</ul>
</li>
<li>Updated <code>apex_x/model/core.py</code> runtime behavior:<ul>
<li>router-off mode forces dense <code>L0</code> selection and skips budget controller routing selection</li>
<li>no-SSM mode bypasses <code>tile_ssm_scan(...)</code> and uses zero modulation/state</li>
<li>no-nesting mode uses effective depth for diagnostics totals (<code>L1/L2</code> counts become zero)</li>
<li>output now includes <code>feature_toggles</code> summary for debug/smoke assertions</li>
</ul>
</li>
<li>Updated <code>apex_x/train/__init__.py</code> + <code>apex_x/cli.py</code>:<ul>
<li>train placeholder now accepts config and reports effective distill/PCGrad++ enabled flags</li>
<li>CLI <code>train</code> passes config through to preserve toggle behavior in logs/output paths</li>
</ul>
</li>
<li>Added smoke coverage:<ul>
<li><code>tests/test_feature_toggle_smoke.py</code></li>
<li>validates override behavior for <code>disable_nesting</code></li>
<li>executes all <code>2^5=32</code> toggle combinations:<ul>
<li>router off / on</li>
<li>no nesting / nesting</li>
<li>no SSM / SSM</li>
<li>no distill / distill</li>
<li>no PCGrad++ / PCGrad++</li>
</ul>
</li>
<li>asserts forward + train placeholder run without crashes and toggle semantics hold</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check .</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
</ul>
</li>
<li>Torch tile packer implemented with contiguous output contract:</li>
<li>Added <code>apex_x/tiles/torch_ops.py</code>:<ul>
<li><code>TilePackTorch.pack(...)</code>:</li>
<li>input: <code>F[B,C,H,W]</code>, <code>idx[B,K]</code>, <code>tile_size</code></li>
<li>output: <code>P[B,K,C,t,t]</code>, <code>meta</code></li>
<li>deterministic ordering via shared ordering dispatcher (<code>order_idx(...)</code>)</li>
<li>strict shape/dtype/bounds validation</li>
<li>guarantees contiguous packed tensor via <code>.contiguous()</code></li>
<li><code>pack_tiles_torch(...)</code> convenience wrapper</li>
<li><code>TorchTileMeta</code> type alias (<code>dict[str, torch.Tensor]</code>)</li>
</ul>
</li>
<li>Exported through <code>apex_x/tiles/__init__.py</code>:<ul>
<li><code>TorchTileMeta</code></li>
<li><code>TilePackTorch</code></li>
<li><code>pack_tiles_torch</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_tile_pack_torch.py</code>:<ul>
<li>correctness vs NumPy reference <code>pack_tiles(...)</code></li>
<li>contiguous output assertion</li>
<li>autograd gradient-flow check from packed output back to source feature map</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check ...</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_tile_pack_torch.py tests/test_tile_ops.py</code> passed</li>
</ul>
</li>
<li>Torch tile unpacker implemented with overlap priority modes:</li>
<li>Extended <code>apex_x/tiles/torch_ops.py</code>:<ul>
<li><code>TileUnpackTorch.unpack(...)</code>:</li>
<li>input: <code>base_map[B,C,H,W]</code>, <code>packed_out[B,K,C,t,t]</code>, <code>meta</code>, <code>level_priority</code>, optional <code>priority_map</code></li>
<li>overlap modes:<ul>
<li><code>override</code>: incoming tile values replace existing values where priority allows</li>
<li><code>blend</code>: weighted fusion <code>out = (1-alpha)*current + alpha*incoming</code> where priority allows</li>
</ul>
</li>
<li>priority contract preserved via per-pixel <code>priority_map</code> updates</li>
<li>strict validation for tensor ranks/shapes, bounds, and mode/alpha values</li>
<li><code>unpack_tiles_torch(...)</code> convenience wrapper</li>
<li><code>OverlapMode</code> type alias</li>
</ul>
</li>
<li>Exported through <code>apex_x/tiles/__init__.py</code>:<ul>
<li><code>OverlapMode</code></li>
<li><code>TileUnpackTorch</code></li>
<li><code>unpack_tiles_torch</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_tile_unpack_torch.py</code>:<ul>
<li>override-mode parity vs NumPy <code>unpack_tiles(...)</code></li>
<li>overlap priority enforcement and blend-mode numeric behavior</li>
<li>autograd gradient-flow checks for blend mode (<code>base</code> and <code>packed_out</code>)</li>
<li>helper/function parity (<code>TileUnpackTorch().unpack</code> vs <code>unpack_tiles_torch</code>)</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/tiles/torch_ops.py apex_x/tiles/__init__.py tests/test_tile_unpack_torch.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_tile_pack_torch.py tests/test_tile_unpack_torch.py tests/test_tile_ops.py</code> passed</li>
</ul>
</li>
<li>Fusion gate implemented with boundary/uncertainty-conditioned alpha:</li>
<li>Added <code>apex_x/model/fusion_gate.py</code>:<ul>
<li><code>FusionGate(nn.Module)</code> computes spatial gate:</li>
<li><code>alpha [B,1,H,W] = sigmoid(w_b * boundary_proxy + w_u * uncertainty_proxy + bias)</code></li>
<li>positive monotonic proxy weights enforced via <code>softplus(...)</code></li>
<li>outputs fused features:</li>
<li><code>fused = base + alpha * (heavy - base)</code></li>
<li>validates proxy shape contracts and aligns proxies to feature dtype/device</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>FusionGate</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_fusion_gate.py</code>:<ul>
<li>alpha shape/range and fusion formula correctness</li>
<li>sensitivity checks: increasing boundary/uncertainty proxies increases mean alpha</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/fusion_gate.py tests/test_fusion_gate.py apex_x/model/__init__.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_fusion_gate.py</code> passed</li>
</ul>
</li>
<li>Cheap block implemented (<code>1x1 + norm + ReGLU + optional residual</code>):</li>
<li>Added <code>apex_x/model/cheap_block.py</code>:<ul>
<li><code>CheapBlock(nn.Module)</code>:</li>
<li>path: <code>Conv2d(1x1) -&gt; GroupNorm -&gt; ReGLU</code></li>
<li>optional residual add</li>
<li>automatic residual projection (<code>1x1</code>) when <code>in_channels != out_channels</code></li>
<li>validation for input channels and normalization group divisibility</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>CheapBlock</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_cheap_block.py</code>:<ul>
<li>shape checks with residual projection path</li>
<li>residual identity behavior when main path is zeroed</li>
<li>no-residual zero-output behavior when main path is zeroed</li>
<li>gradient-flow checks for input and block parameters</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/cheap_block.py apex_x/model/__init__.py tests/test_cheap_block.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_cheap_block.py tests/test_model.py</code> passed</li>
</ul>
</li>
<li>Tile refine block implemented for packed tiles:</li>
<li>Added <code>apex_x/model/tile_refine_block.py</code>:<ul>
<li><code>TileRefineBlock(nn.Module)</code> operating on packed tensors <code>[B,K,C,t,t]</code></li>
<li>local refine path per tile:</li>
<li>depthwise conv (<code>k x k</code>)</li>
<li>pointwise conv</li>
<li><code>GroupNorm</code></li>
<li>ReGLU activation</li>
<li>optional residual (with automatic projection when channels differ)</li>
<li>implementation flattens <code>B*K</code> for conv processing and restores <code>[B,K,...]</code>, preserving per-tile independence</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>TileRefineBlock</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_tile_refine_block.py</code>:<ul>
<li>shape/projection path checks</li>
<li>residual identity when main path is zeroed</li>
<li>per-tile independence (no cross-tile mixing)</li>
<li>gradient-flow checks for inputs and parameters</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/tile_refine_block.py apex_x/model/__init__.py tests/test_tile_refine_block.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_tile_refine_block.py tests/test_cheap_block.py</code> passed</li>
</ul>
</li>
<li>PV backbone implemented with P3/P4/P5 feature outputs:</li>
<li>Added <code>apex_x/model/pv_backbone.py</code>:<ul>
<li><code>PVBackbone(nn.Module)</code> returning feature dict:</li>
<li><code>P3</code> (stride 8)</li>
<li><code>P4</code> (stride 16)</li>
<li><code>P5</code> (stride 32)</li>
<li>uses lightweight staged downsampling + <code>CheapBlock</code> refinement per level</li>
<li>validates input shape/channel contract and minimum spatial size</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>PVBackbone</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_pv_backbone.py</code>:<ul>
<li>parameterized shape checks across multiple input sizes</li>
<li>gradient-flow check</li>
<li>input validation checks</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/pv_backbone.py apex_x/model/__init__.py tests/test_pv_backbone.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_pv_backbone.py</code> passed</li>
</ul>
</li>
<li>PV coarse heads implemented with explicit uncertainty proxy definition:</li>
<li>Added <code>apex_x/model/pv_coarse_heads.py</code>:<ul>
<li><code>PVCoarseHeads(nn.Module)</code> producing coarse PV maps from a selected backbone level (default <code>P4</code>):</li>
<li><code>objectness_logits</code></li>
<li><code>objectness = sigmoid(objectness_logits)</code></li>
<li><code>boundary_proxy = sigmoid(boundary_logits)</code></li>
<li><code>variance_proxy = softplus(variance_logits)</code></li>
<li><code>uncertainty_proxy</code></li>
<li>clear uncertainty definition:</li>
<li><code>u_hat = 4 * p * (1 - p)</code> where <code>p = objectness</code></li>
<li>normalized Bernoulli variance (<code>u_hat=1</code> at <code>p=0.5</code>, <code>u_hat=0</code> at <code>p in {0,1}</code>)</li>
<li>output typed via <code>PVCoarseOutput</code> dataclass</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>PVCoarseHeads</code></li>
<li><code>PVCoarseOutput</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_pv_coarse_heads.py</code>:<ul>
<li>parameterized shape/range checks across multiple image sizes (via <code>PVBackbone</code> + <code>P4</code>)</li>
<li>uncertainty sensitivity checks with controlled objectness logits</li>
<li>direct uncertainty formula parity check</li>
<li>gradient-flow check through backbone + heads</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/pv_coarse_heads.py apex_x/model/__init__.py tests/test_pv_coarse_heads.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_pv_coarse_heads.py</code> passed</li>
</ul>
</li>
<li>PV module wired with backbone + coarse heads:</li>
<li>Added <code>apex_x/model/pv_module.py</code>:<ul>
<li><code>PVModule</code> composes:</li>
<li><code>PVBackbone</code> for <code>P3/P4/P5</code> feature extraction</li>
<li><code>PVCoarseHeads</code> for coarse proxies</li>
<li><code>PVModule.forward()</code> now returns <code>PVModuleOutput</code> containing:</li>
<li><code>features</code> dict (<code>P3/P4/P5</code>)</li>
<li><code>coarse</code> maps from selected level (<code>coarse_level</code>: <code>P3</code>/<code>P4</code>/<code>P5</code>)</li>
<li><code>proxy_maps</code> dict for routing-facing signals:<ul>
<li><code>objectness</code></li>
<li><code>uncertainty</code></li>
<li><code>boundary</code></li>
<li><code>variance</code></li>
</ul>
</li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>PVModule</code></li>
<li><code>PVModuleOutput</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_pv_module.py</code>:<ul>
<li>shape checks across multiple input sizes</li>
<li>coarse-level selection checks (<code>P3</code> vs <code>P5</code>)</li>
<li><code>proxy_maps</code> key/shape checks</li>
<li>finite-output assertions</li>
</ul>
</li>
<li>Added dedicated CPU smoke test in <code>tests/test_pv_module_smoke_cpu.py</code>:<ul>
<li>validates CPU forward path and proxy-map outputs are finite with expected shapes</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/pv_module.py apex_x/model/__init__.py tests/test_pv_module.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_pv_module.py tests/test_pv_module_smoke_cpu.py tests/test_pv_backbone.py tests/test_pv_coarse_heads.py</code> passed</li>
</ul>
</li>
<li>Stable state-space-like scan implemented with constrained parameters:</li>
<li>Extended <code>apex_x/utils/ssm.py</code>:<ul>
<li><code>StableStateSpaceScan(nn.Module)</code> with constrained recurrent parameters:</li>
<li>decay constrained to <code>(min_decay, max_decay)</code> via sigmoid mapping</li>
<li>positive input/output gains via softplus</li>
<li>numerically safe token sanitization/clamp path</li>
<li><code>SSMScanStats</code> for explicit scan complexity accounting:</li>
<li><code>steps</code></li>
<li><code>recurrent_updates</code></li>
<li><code>pairwise_updates</code></li>
<li><code>tile_ssm_scan(...)</code> now clamps alpha to stable bounds</li>
</ul>
</li>
<li>Exported in <code>apex_x/utils/__init__.py</code>:<ul>
<li><code>StableStateSpaceScan</code></li>
<li><code>SSMScanStats</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_stable_ssm_scan.py</code>:<ul>
<li>no-NaN/finite checks on extreme inputs</li>
<li>gradient-flow checks for inputs and scan parameters</li>
<li>O(K) behavior checks via linear recurrent-update accounting and zero pairwise updates</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/utils/ssm.py apex_x/utils/__init__.py tests/test_stable_ssm_scan.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_stable_ssm_scan.py</code> passed</li>
</ul>
</li>
<li>Bidirectional scan and merge gate added on top of stable scan:</li>
<li>Extended <code>apex_x/utils/ssm.py</code>:<ul>
<li><code>StableBidirectionalStateSpaceScan(nn.Module)</code>:</li>
<li>forward-direction stable scan</li>
<li>backward-direction stable scan (reverse sequence + reverse outputs back)</li>
<li>channel-wise constrained merge gate:<ul>
<li><code>gate = sigmoid(merge_gate_logit)</code> in <code>[0,1]</code></li>
<li>merged output: <code>gate * y_fwd + (1 - gate) * y_bwd</code></li>
</ul>
</li>
<li>complexity stats preserved as linear-time recurrent updates (no pairwise updates)</li>
</ul>
</li>
<li>Exported in <code>apex_x/utils/__init__.py</code>:<ul>
<li><code>StableBidirectionalStateSpaceScan</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_bidirectional_ssm_scan.py</code>:<ul>
<li>finite/no-NaN checks with extreme inputs</li>
<li>merge formula correctness vs explicit gate-weighted combination</li>
<li>gradient-flow checks for inputs and parameters (including merge gate path)</li>
<li>O(K) scaling checks from recurrent update counts</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/utils/ssm.py apex_x/utils/__init__.py tests/test_bidirectional_ssm_scan.py tests/test_stable_ssm_scan.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_stable_ssm_scan.py tests/test_bidirectional_ssm_scan.py</code> passed</li>
</ul>
</li>
<li>FiLM modulation implemented from tokens to packed tiles:</li>
<li>Added <code>apex_x/model/film.py</code>:<ul>
<li><code>TileFiLM(nn.Module)</code>:</li>
<li>computes FiLM parameters from tokens <code>tokens[B,K,Ct]</code></li>
<li>bounded gain path: <code>gamma = tanh(gamma_raw) * gamma_limit</code></li>
<li>shift path: <code>beta</code></li>
<li>applies modulation to packed tiles: <code>out = (1 + gamma) * tiles + beta</code></li>
<li><code>apply_film(...)</code> functional helper with strict shape validation</li>
</ul>
</li>
<li>Updated <code>apex_x/model/core.py</code>:<ul>
<li>replaced additive-only packed modulation with FiLM-style modulation using SSM mixed tokens:</li>
<li><code>gamma = tanh(mixed)</code></li>
<li><code>beta = mixed</code></li>
<li><code>packed_out = (1 + gamma) * packed + beta</code></li>
</ul>
</li>
<li>Exported in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>TileFiLM</code></li>
<li><code>apply_film</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_film_modulation.py</code>:<ul>
<li>formula and shape checks</li>
<li>gamma range bound checks</li>
<li>deterministic forward under fixed inputs</li>
<li>gradient-flow checks through tokens, tiles, and module parameters</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/film.py apex_x/model/core.py apex_x/model/__init__.py tests/test_film_modulation.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_film_modulation.py tests/test_model.py</code> passed</li>
</ul>
</li>
<li>FF heavy path implemented end-to-end with aligned detail map output:</li>
<li>Added <code>apex_x/model/ff_heavy_path.py</code>:<ul>
<li><code>FFHeavyPath(nn.Module)</code> pipeline:</li>
<li><code>TilePackTorch</code> gather on selected FF tile indices</li>
<li>tile tokenization via spatial pooling: <code>tokens[B,K,C]</code></li>
<li>stable scan (<code>forward</code> or <code>bidirectional</code>) over tokens</li>
<li>FiLM modulation (<code>gamma</code>, <code>beta</code>) from mixed tokens to packed tiles</li>
<li>local packed-tile refine via <code>TileRefineBlock</code></li>
<li><code>TileUnpackTorch</code> scatter back to dense map shape</li>
<li>optional proxy-conditioned fusion gate (<code>FusionGate</code>)</li>
<li>output contract via <code>FFHeavyPathOutput</code>:</li>
<li><code>heavy_features[B,C,H,W]</code></li>
<li><code>detail_map[B,C,H,W]</code> aligned to dense features</li>
<li><code>alpha[B,1,H,W]</code></li>
<li>diagnostics tensors (<code>tokens</code>, <code>mixed_tokens</code>, <code>gamma</code>, <code>beta</code>, <code>state</code>)</li>
<li>includes robust CPU behavior for empty tile selections (<code>K=0</code>) with zero detail contribution.</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>FFHeavyPath</code></li>
<li><code>FFHeavyPathOutput</code></li>
</ul>
</li>
<li>Added CPU tests in <code>tests/test_ff_heavy_path.py</code>:<ul>
<li>shape/alignment checks and finite outputs</li>
<li>empty-selection behavior (<code>K=0</code>) -&gt; zero <code>detail_map</code></li>
<li>deterministic repeated forward and gradient-flow checks</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/ff_heavy_path.py apex_x/model/__init__.py tests/test_ff_heavy_path.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_ff_heavy_path.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>FF module implemented for train/infer routing execution:</li>
<li>Added <code>apex_x/model/ff_module.py</code>:<ul>
<li><code>FFModule(nn.Module)</code> with two explicit entrypoints:</li>
<li><code>forward_train(...)</code>:<ul>
<li>STE routing gates via <code>ste_gate_from_utilities(...)</code></li>
<li>expected-cost computation via <code>BudgetDualController.expected_cost(...)</code></li>
<li>budget loss term via <code>BudgetDualController.budget_loss(...)</code></li>
<li>optional dual-<code>mu</code> update with persistent <code>mu_history</code></li>
<li>routed L0 heavy execution through <code>FFHeavyPath</code></li>
</ul>
</li>
<li><code>forward_infer(...)</code>:<ul>
<li>deterministic L0 greedy selection under <code>B1</code>/<code>Kmax_l0</code></li>
<li>optional L0-&gt;L1 two-stage selection under <code>B2</code>/<code>Kmax_l1</code></li>
<li>optional nesting execution (L1 heavy pass) when split utilities provided</li>
</ul>
</li>
<li>diagnostics integrated in both paths through <code>build_routing_diagnostics(...)</code>:</li>
<li>selected counts/ratios</li>
<li>utility histograms</li>
<li>per-budget usage (<code>b1/b2/b3/total</code>)</li>
<li><code>mu_history</code></li>
<li>output dataclasses:</li>
<li><code>FFTrainOutput</code></li>
<li><code>FFInferOutput</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>FFModule</code></li>
<li><code>FFTrainOutput</code></li>
<li><code>FFInferOutput</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_ff_module.py</code>:<ul>
<li>train path:</li>
<li>STE + expected-cost + budget-loss outputs</li>
<li>diagnostics presence</li>
<li>dual-<code>mu</code> history update</li>
<li>inference path:</li>
<li>deterministic budgeted L0 selection</li>
<li>optional nesting with deterministic L1 child selection under <code>B2</code></li>
<li>diagnostics coverage</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/ff_module.py apex_x/model/__init__.py tests/test_ff_module.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_ff_module.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Dual-path FPN implemented to combine PV low-res with FF high-res:</li>
<li>Added <code>apex_x/model/fpn.py</code>:<ul>
<li><code>DualPathFPN(nn.Module)</code>:</li>
<li>inputs:<ul>
<li>PV features dict <code>P3/P4/P5</code></li>
<li>FF high-res feature/detail map</li>
</ul>
</li>
<li>fusion path:<ul>
<li>lateral 1x1 projections for PV <code>P3/P4/P5</code></li>
<li>lateral 1x1 projection for FF branch</li>
<li>top-down FPN merge (<code>P5 -&gt; P4 -&gt; P3</code>)</li>
<li>explicit FF injection at <code>P3</code> after spatial alignment</li>
<li>smoothing with <code>CheapBlock</code> on <code>P3/P4/P5</code></li>
</ul>
</li>
<li>output contract via <code>DualPathFPNOutput</code>:<ul>
<li>fused pyramid dict <code>P3/P4/P5</code></li>
<li>aligned FF feature map at P3 resolution (<code>ff_aligned</code>)</li>
</ul>
</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>DualPathFPN</code></li>
<li><code>DualPathFPNOutput</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_fpn.py</code>:<ul>
<li>CPU shape and finite-value checks</li>
<li>FF-branch sensitivity (changing FF input changes fused <code>P3</code>)</li>
<li>gradient-flow checks through PV inputs, FF input, and FPN params</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/fpn.py apex_x/model/__init__.py tests/test_fpn.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_fpn.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>DET head implemented over P3..P7 (cls/box/quality):</li>
<li>Added <code>apex_x/model/det_head.py</code>:<ul>
<li><code>DetHead(nn.Module)</code>:</li>
<li>consumes pyramid features with required <code>P3/P4/P5</code></li>
<li>supports optional provided <code>P6/P7</code>; auto-generates missing levels from <code>P5</code>/<code>P6</code></li>
<li>per-level outputs:<ul>
<li><code>cls_logits</code>: <code>[B, num_classes, H, W]</code></li>
<li><code>box_reg</code>: <code>[B, 4, H, W]</code></li>
<li><code>quality</code>: <code>[B, 1, H, W]</code></li>
</ul>
</li>
<li>uses shared tower structure for cls/box/quality with GroupNorm + SiLU and export-friendly conv outputs</li>
<li>output contract via <code>DetHeadOutput</code>:</li>
<li>per-level dicts for <code>cls_logits</code>, <code>box_reg</code>, <code>quality</code></li>
<li>normalized <code>features</code> dict for effective <code>P3..P7</code> levels used by the head</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>DetHead</code></li>
<li><code>DetHeadOutput</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_det_head.py</code>:<ul>
<li>shape checks across all output levels <code>P3..P7</code> when only <code>P3..P5</code> are provided</li>
<li>behavior check that explicitly provided <code>P6/P7</code> are used as-is</li>
<li>gradient-flow checks through inputs and DET-head parameters</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/det_head.py apex_x/model/__init__.py tests/test_det_head.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_det_head.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>SimOTA/OTA cost components implemented for DET matching:</li>
<li>Added <code>apex_x/losses/simota.py</code>:<ul>
<li>classification cost:</li>
<li><code>classification_cost(...)</code> with modes:<ul>
<li>BCE-based positive-class cost</li>
<li>focal-based positive-class cost</li>
</ul>
</li>
<li>IoU cost:</li>
<li><code>iou_cost(...)</code> implementing <code>1 - IoU</code> over pairwise GT/anchor boxes</li>
<li>center prior cost:</li>
<li><code>center_prior_cost(...)</code> from GT center to anchor center distance (normalized by GT size)</li>
<li>per-GT candidate generation:</li>
<li><code>topk_center_candidates(...)</code> selecting top-k nearest anchor centers per GT</li>
<li><code>candidate_mask_from_indices(...)</code> to build per-GT candidate masks</li>
<li>integrated cost assembly:</li>
<li><code>compute_simota_cost(...)</code> combining weighted components and candidate masking</li>
<li><code>SimOTACostOutput</code> dataclass containing component matrices, combined cost, and candidates</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>classification_cost</code>, <code>iou_cost</code>, <code>center_prior_cost</code></li>
<li><code>topk_center_candidates</code>, <code>candidate_mask_from_indices</code></li>
<li><code>compute_simota_cost</code>, <code>SimOTACostOutput</code>, <code>ClassificationCostType</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_simota_cost.py</code>:<ul>
<li>per-GT top-k center candidate selection correctness on synthetic anchors/GT</li>
<li>classification-cost ranking behavior (higher positive logit -&gt; lower cost)</li>
<li>IoU cost sanity (<code>1 - IoU</code>)</li>
<li>combined SimOTA ranking on synthetic setup (reasonable anchor wins; non-candidates penalized)</li>
<li>center-prior ranking preference for nearby anchor centers</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/losses/simota.py apex_x/losses/__init__.py tests/test_simota_cost.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_simota_cost.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Dynamic-K SimOTA matching implemented (including conflict resolution):</li>
<li>Extended <code>apex_x/losses/simota.py</code>:<ul>
<li><code>DynamicKMatchingOutput</code> dataclass with:</li>
<li><code>dynamic_ks</code></li>
<li><code>matching_matrix</code></li>
<li><code>foreground_mask</code></li>
<li><code>matched_gt_indices</code></li>
<li><code>assigned_cost</code></li>
<li><code>num_foreground</code></li>
<li><code>dynamic_k_from_top_ious(...)</code>:</li>
<li>computes per-GT <code>dynamic_k</code> from sum of top IoUs (with configurable <code>topk</code> and <code>min_k</code>)</li>
<li>supports optional candidate mask</li>
<li><code>dynamic_k_matching(...)</code>:</li>
<li>selects <code>dynamic_k</code> anchors per GT by minimal total cost</li>
<li>resolves multi-GT conflicts by keeping the minimal-cost GT assignment per anchor</li>
<li>outputs deterministic one-to-one anchor-to-GT assignment for foreground anchors</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>DynamicKMatchingOutput</code></li>
<li><code>dynamic_k_from_top_ious</code></li>
<li><code>dynamic_k_matching</code></li>
</ul>
</li>
<li>Expanded <code>tests/test_simota_cost.py</code>:<ul>
<li>verifies dynamic-k computation from top-IoU sums</li>
<li>verifies crowded conflict resolution picks minimal-cost GT per anchor</li>
<li>verifies candidate-mask constraints are respected in crowded settings</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/losses/simota.py apex_x/losses/__init__.py tests/test_simota_cost.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_simota_cost.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>SimOTA assignment integrated into DET loss with target generation:</li>
<li>Added <code>apex_x/losses/det_loss.py</code>:<ul>
<li><code>build_simota_targets_for_anchors(...)</code>:</li>
<li>uses SimOTA cost + dynamic-k matching to select positive anchors</li>
<li>builds per-anchor targets:<ul>
<li><code>cls_target</code> (one-hot positives, zero background)</li>
<li><code>box_target</code> (assigned GT boxes)</li>
<li><code>quality_target</code> (matched IoU targets)</li>
</ul>
</li>
<li>returns <code>SimOTATargets</code> with matching diagnostics</li>
<li><code>det_loss_with_simota(...)</code>:</li>
<li>computes DET loss from assignment targets:<ul>
<li>classification loss (BCE or focal)</li>
<li>box loss (<code>1 - IoU</code>) on positives</li>
<li>quality BCE loss</li>
</ul>
</li>
<li>returns <code>DetLossOutput</code> with component losses and targets</li>
<li>stability features:</li>
<li>canonicalized box ordering for robust IoU math</li>
<li>optional assignment on detached predictions</li>
<li>small-object positive weighting with clipped inverse-sqrt area scaling</li>
<li>dynamic-k conflict-resolved assignment for crowded scenes</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>SimOTATargets</code></li>
<li><code>DetLossOutput</code></li>
<li><code>build_simota_targets_for_anchors</code></li>
<li><code>det_loss_with_simota</code></li>
<li><code>ClsLossType</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_det_loss_simota.py</code>:<ul>
<li>target generation and per-anchor labeling correctness</li>
<li>finite/stable loss on tiny-object crowded synthetic setup</li>
<li>toy optimization loop verifying DET loss decreases over training steps</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/losses/det_loss.py apex_x/losses/__init__.py tests/test_det_loss_simota.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_det_loss_simota.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>DET losses hardened for numerical stability and quality-focal support:</li>
<li>Updated <code>apex_x/losses/det_loss.py</code>:<ul>
<li>added logit sanitization/clipping via <code>_sanitize_logits(...)</code></li>
<li>added <code>QualityLossType</code> with <code>bce</code> and <code>qfl</code> modes</li>
<li><code>det_loss_with_simota(...)</code> now supports:</li>
<li><code>quality_loss_type=\"qfl\"</code></li>
<li><code>quality_focal_beta</code></li>
<li><code>logit_clip</code></li>
<li>focal/BCE classification and QFL/BCE quality paths now run on sanitized logits for stable behavior under extreme values</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>QualityLossType</code></li>
</ul>
</li>
<li>Expanded <code>tests/test_det_loss_simota.py</code>:<ul>
<li>toy decreasing-loss case now also exercises quality-focal path</li>
<li>added extreme-logit + tiny-box finite test with backward gradient finiteness checks</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/losses/det_loss.py apex_x/losses/__init__.py tests/test_det_loss_simota.py</code> passed</li>
<li><code>./.venv/bin/python -m mypy</code> passed</li>
<li><code>python -m pytest -q tests/test_det_loss_simota.py</code> passed</li>
<li>full project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>./.venv/bin/python -m mypy</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Deterministic DET decode + NMS implemented:</li>
<li>Added <code>apex_x/infer/detection.py</code>:<ul>
<li><code>decode_anchor_free_candidates(...)</code>:</li>
<li>decodes anchor-free <code>DetHeadOutput</code> maps into per-image candidate tensors</li>
<li>supports configurable level strides and image clipping</li>
<li>applies stable candidate ranking with deterministic tie behavior</li>
<li><code>deterministic_nms(...)</code>:</li>
<li>class-wise NMS with deterministic ordering</li>
<li>tie-breaking policy: score desc, then candidate index asc</li>
<li><code>batched_deterministic_nms(...)</code>:</li>
<li>fixed-shape batched outputs with padding and <code>valid_counts</code></li>
<li><code>decode_and_nms(...)</code>:</li>
<li>end-to-end decode + NMS convenience entrypoint</li>
<li>output dataclasses:</li>
<li><code>DetectionCandidates</code></li>
<li><code>DetectionBatch</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/infer/__init__.py</code>:<ul>
<li><code>DetectionCandidates</code></li>
<li><code>DetectionBatch</code></li>
<li><code>decode_anchor_free_candidates</code></li>
<li><code>deterministic_nms</code></li>
<li><code>batched_deterministic_nms</code></li>
<li><code>decode_and_nms</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_det_decode_nms.py</code>:<ul>
<li>end-to-end decode + NMS determinism and class-wise suppression behavior</li>
<li>deterministic tie handling in NMS (equal scores -&gt; lower index first)</li>
<li>cross-class overlap handling (no cross-class suppression)</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/infer/detection.py apex_x/infer/__init__.py tests/test_det_decode_nms.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/infer/detection.py apex_x/infer/__init__.py</code> passed</li>
<li><code>python -m pytest -q tests/test_det_decode_nms.py tests/test_import_smoke.py</code> passed</li>
<li><code>python -m pytest -q</code> passed</li>
</ul>
</li>
<li>Prototype-based instance segmentation forward path and mask assembly implemented:</li>
<li>Added <code>apex_x/model/inst_seg_head.py</code>:<ul>
<li><code>PrototypeInstanceSegHead(nn.Module)</code>:</li>
<li>prototype generator from feature maps (<code>prototypes: [B,M,Hp,Wp]</code>)</li>
<li>per-instance coefficient prediction (<code>coefficients: [B,N,M]</code>) from:<ul>
<li>ROI mean-pooled feature regions derived from <code>boxes_xyxy</code>, or</li>
<li>explicit <code>instance_embeddings</code></li>
</ul>
</li>
<li>mask assembly by linear prototype combination:<ul>
<li><code>mask_logits_lowres = einsum(coefficients, prototypes) -&gt; [B,N,Hp,Wp]</code></li>
</ul>
</li>
<li>output resizing to requested mask resolution</li>
<li>optional box cropping with configurable fill value for stable masked logits</li>
<li>per-instance <code>mask_scores</code> from masked probability averages</li>
<li>helper functions:</li>
<li><code>assemble_mask_logits_from_prototypes(...)</code></li>
<li><code>rasterize_box_masks(...)</code></li>
<li>output dataclass:</li>
<li><code>InstanceSegOutput</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>PrototypeInstanceSegHead</code></li>
<li><code>InstanceSegOutput</code></li>
<li><code>assemble_mask_logits_from_prototypes</code></li>
<li><code>rasterize_box_masks</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_inst_seg_head.py</code>:<ul>
<li>prototype-mask assembly correctness vs expected weighted combinations</li>
<li>forward-path shape/range checks and finite outputs</li>
<li>deterministic repeatability for same weights/inputs</li>
<li>gradient-flow checks (features + instance embeddings + parameters)</li>
<li>crop-to-box fill behavior outside ROI regions</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/inst_seg_head.py apex_x/model/__init__.py tests/test_inst_seg_head.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/model/inst_seg_head.py apex_x/model/__init__.py tests/test_inst_seg_head.py</code> passed</li>
<li><code>python -m pytest -q tests/test_inst_seg_head.py</code> passed</li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code> passed</li>
</ul>
</li>
<li>Segmentation losses implemented (BCE + Dice + boundary DT surrogate):</li>
<li>Added <code>apex_x/losses/seg_loss.py</code>:<ul>
<li><code>mask_bce_loss(...)</code>:</li>
<li>BCEWithLogits per mask with optional per-instance weighting <code>[B,N]</code></li>
<li><code>mask_dice_loss(...)</code>:</li>
<li>soft Dice loss over <code>[B,N,H,W]</code> masks with optional per-instance weighting</li>
<li><code>soft_boundary_distance_transform(...)</code>:</li>
<li>differentiable approximation of boundary distance transform using iterative
    soft-min neighborhood propagation</li>
<li><code>boundary_distance_transform_surrogate_loss(...)</code>:</li>
<li>boundary mismatch weighted by target soft distance transform</li>
<li><code>instance_segmentation_losses(...)</code>:</li>
<li>combined BCE + Dice + boundary loss returning <code>SegLossOutput</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>SegLossOutput</code></li>
<li><code>mask_bce_loss</code></li>
<li><code>mask_dice_loss</code></li>
<li><code>soft_boundary_distance_transform</code></li>
<li><code>boundary_distance_transform_surrogate_loss</code></li>
<li><code>instance_segmentation_losses</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_seg_loss.py</code>:<ul>
<li>BCE/Dice near-zero behavior for near-perfect logits</li>
<li>soft boundary-DT monotonicity sanity check</li>
<li>boundary surrogate sensitivity to shifted boundaries</li>
<li>toy optimization loop showing combined loss decreases with finite gradients</li>
<li>instance-weight support path</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/losses/seg_loss.py apex_x/losses/__init__.py tests/test_seg_loss.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/losses/seg_loss.py apex_x/losses/__init__.py tests/test_seg_loss.py</code> passed</li>
<li><code>python -m pytest -q tests/test_seg_loss.py</code> passed</li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>FF high-resolution tile-gated refinement hook implemented for instance masks:</li>
<li>Updated <code>apex_x/model/inst_seg_head.py</code>:<ul>
<li>added <code>FFTileRefinementHook(nn.Module)</code>:</li>
<li>inputs: <code>mask_logits [B,N,H,W]</code>, <code>ff_highres_features [B,C,H,W]</code>, <code>active_tile_indices [B,K]</code></li>
<li>packs only active tiles, applies FF-conditioned additive refinement on packed tiles, and unpacks back</li>
<li>guarantees inactive tiles remain unchanged via tile-scatter semantics</li>
<li>integrated optional hook into <code>PrototypeInstanceSegHead</code>:</li>
<li>new init toggles:<ul>
<li><code>enable_ff_refine</code></li>
<li><code>ff_refine_tile_size</code></li>
<li><code>ff_refine_order_mode</code></li>
<li><code>ff_refine_overlap_mode</code></li>
<li><code>ff_refine_blend_alpha</code></li>
<li><code>ff_refine_strength_init</code></li>
</ul>
</li>
<li>new forward args:<ul>
<li><code>ff_highres_features</code></li>
<li><code>active_tile_indices</code></li>
</ul>
</li>
<li>refinement is applied only when enabled and both FF features + active indices are provided</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>FFTileRefinementHook</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_inst_seg_refinement_hook.py</code>:<ul>
<li>hook updates only selected tiles and leaves non-selected tiles exactly unchanged</li>
<li>empty active-tile indices produce no-op behavior</li>
<li>head-level integration verifies refinement delta is confined to active tile regions</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/model/inst_seg_head.py apex_x/model/__init__.py tests/test_inst_seg_refinement_hook.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/model/inst_seg_head.py apex_x/model/__init__.py tests/test_inst_seg_refinement_hook.py</code> passed</li>
<li><code>python -m pytest -q tests/test_inst_seg_refinement_hook.py tests/test_inst_seg_head.py</code> passed</li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Panoptic output generation implemented (semantic + instance fusion):</li>
<li>Added <code>apex_x/infer/panoptic.py</code>:<ul>
<li><code>generate_panoptic_output(...)</code>:</li>
<li>combines semantic logits with instance masks into deterministic panoptic maps</li>
<li>deterministic overlap fusion:<ul>
<li>thing instances fused first, sorted by <code>(score desc, instance_index asc)</code></li>
<li>overlap resolution keeps higher-ranked instance pixels</li>
</ul>
</li>
<li>deterministic thing/stuff rules:<ul>
<li>only classes in <code>thing_class_ids</code> are accepted as thing instances</li>
<li>remaining unassigned pixels are filled by semantic stuff classes in ascending class-id order</li>
<li>segment id <code>0</code> reserved as void/unassigned</li>
</ul>
</li>
<li>supports:<ul>
<li>mask threshold, score threshold</li>
<li>minimum thing/stuff area filters</li>
<li>optional <code>masks_are_logits</code> for instance-mask logits input</li>
</ul>
</li>
<li>dataclasses:</li>
<li><code>PanopticSegmentInfo</code> (<code>id</code>, <code>category_id</code>, <code>isthing</code>, <code>area</code>, optional score/index)</li>
<li><code>PanopticOutput</code> (<code>panoptic_map</code>, <code>segments_info</code>, <code>semantic_labels</code>)</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/infer/__init__.py</code>:<ul>
<li><code>PanopticSegmentInfo</code></li>
<li><code>PanopticOutput</code></li>
<li><code>generate_panoptic_output</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_panoptic_generation.py</code>:<ul>
<li>deterministic overlap resolution on synthetic overlapping thing instances</li>
<li>thing/stuff rule verification (non-thing instances ignored, stuff preserved)</li>
<li>output contract checks on synthetic batched scenes:</li>
<li>map shape/type</li>
<li>unique segment IDs</li>
<li>per-segment area parity with panoptic map pixels</li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/infer/panoptic.py apex_x/infer/__init__.py tests/test_panoptic_generation.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/infer/panoptic.py apex_x/infer/__init__.py tests/test_panoptic_generation.py</code> passed</li>
<li><code>python -m pytest -q tests/test_panoptic_generation.py</code> passed</li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Panoptic PQ evaluation wrapper implemented (official API + fallback):</li>
<li>Added <code>apex_x/infer/pq_eval.py</code>:<ul>
<li><code>evaluate_panoptic_quality(...)</code>:</li>
<li>uses official <code>panopticapi</code> evaluator when available and paths are provided</li>
<li>otherwise falls back to an in-memory deterministic minimal PQ implementation</li>
<li>deterministic fallback behavior:</li>
<li>per-category matching with IoU threshold</li>
<li>one-to-one matches with deterministic tie handling</li>
<li>computes per-class <code>(PQ, SQ, RQ)</code> and aggregate all/things/stuff metrics</li>
<li>dataclasses:</li>
<li><code>PQClassMetrics</code></li>
<li><code>PQMetrics</code></li>
<li><code>OfficialPQPaths</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/infer/__init__.py</code>:<ul>
<li><code>PQClassMetrics</code></li>
<li><code>PQMetrics</code></li>
<li><code>OfficialPQPaths</code></li>
<li><code>evaluate_panoptic_quality</code></li>
</ul>
</li>
<li>CLI integration hook added:<ul>
<li>updated <code>apex_x/cli.py</code> <code>eval</code> command with:</li>
<li><code>--panoptic-pq</code> flag</li>
<li>runs panoptic PQ hook and prints <code>panoptic_pq=&lt;value&gt;</code> and source (<code>official</code>/<code>fallback</code>)</li>
</ul>
</li>
<li>Added fixtures:<ul>
<li><code>tests/fixtures/pq_case_perfect.json</code></li>
<li><code>tests/fixtures/pq_case_partial.json</code></li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_pq_eval.py</code></li>
<li>fixture-driven perfect and partial overlap PQ checks</li>
<li>verifies official-path attempt cleanly falls back when official API is unavailable/invalid</li>
<li><code>tests/test_cli.py</code></li>
<li>new parse test for <code>eval --panoptic-pq</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li><code>python -m ruff check apex_x/infer/pq_eval.py apex_x/infer/__init__.py apex_x/cli.py tests/test_pq_eval.py tests/test_cli.py</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/infer/pq_eval.py apex_x/infer/__init__.py apex_x/cli.py tests/test_pq_eval.py tests/test_cli.py</code> passed</li>
<li><code>python -m pytest -q tests/test_pq_eval.py tests/test_cli.py</code> passed</li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Tracking embedding head and association interfaces implemented:</li>
<li>Added <code>apex_x/model/track_head.py</code>:<ul>
<li><code>TrackEmbeddingHead</code>:</li>
<li>accepts feature tensor or feature dict</li>
<li>projects features, ROI-pools detections, and emits L2-normalized embeddings</li>
<li><code>TrackEmbeddingOutput</code> dataclass with:</li>
<li><code>embeddings</code></li>
<li><code>raw_embeddings</code></li>
<li><code>pooled_features</code></li>
</ul>
</li>
<li>Added <code>apex_x/infer/tracking.py</code>:<ul>
<li><code>TrackState</code> dataclass (validated tracker state contract)</li>
<li><code>AssociationResult</code> dataclass</li>
<li><code>AssociationProtocol</code> interface</li>
<li>deterministic <code>GreedyCosineAssociator</code> implementation</li>
<li>compatibility aliases:</li>
<li><code>TrackAssociatorProtocol</code></li>
<li><code>TrackAssociator</code></li>
</ul>
</li>
<li>Updated exports:<ul>
<li><code>apex_x/model/__init__.py</code> exports <code>TrackEmbeddingHead</code>, <code>TrackEmbeddingOutput</code></li>
<li><code>apex_x/infer/__init__.py</code> exports tracking dataclasses/protocols/associator</li>
<li><code>apex_x/__init__.py</code> exports <code>TrackState</code> and <code>AssociationProtocol</code></li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_track_head.py</code>:</li>
<li>output shape checks</li>
<li>embedding unit-norm checks</li>
<li>deterministic forward checks</li>
<li>gradient flow checks</li>
<li><code>tests/test_tracking_interfaces.py</code>:</li>
<li><code>TrackState.empty(...)</code> contract</li>
<li>protocol conformance checks</li>
<li>deterministic greedy matching/new-track behavior</li>
<li>aging/removal behavior with no detections</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/model/track_head.py apex_x/infer/tracking.py tests/test_track_head.py tests/test_tracking_interfaces.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/model/track_head.py apex_x/infer/tracking.py tests/test_track_head.py tests/test_tracking_interfaces.py</code></li>
<li><code>python -m pytest -q tests/test_track_head.py tests/test_tracking_interfaces.py</code></li>
<li>project checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
<li>note:</li>
<li><code>python -m black --check .</code> currently reports unrelated pre-existing formatting diffs in legacy files not touched in this change:<ul>
<li><code>apex_x/routing/interfaces.py</code></li>
<li><code>apex_x/train/__init__.py</code></li>
<li><code>tests/test_pq_eval.py</code></li>
<li><code>apex_x/config/schema.py</code></li>
<li><code>apex_x/infer/pq_eval.py</code></li>
<li><code>apex_x/losses/det_loss.py</code></li>
<li><code>apex_x/model/inst_seg_head.py</code></li>
</ul>
</li>
</ul>
</li>
<li>Hungarian association with lifecycle and memory-bank updates implemented:</li>
<li>Updated <code>apex_x/infer/tracking.py</code>:<ul>
<li>added Hungarian solver utility:</li>
<li><code>hungarian_assignment(...)</code></li>
<li>added <code>HungarianAssociator</code> implementing:</li>
<li>IoU + embedding-distance gating for candidate matches</li>
<li>global cost minimization via Hungarian assignment</li>
<li>track lifecycle (<code>init</code> / <code>update</code> / <code>terminate</code>) with <code>max_age</code></li>
<li>embedding memory-bank update per track with fixed bank size</li>
<li>bank-size normalization for legacy states to keep runtime stable</li>
<li>extended <code>TrackState</code> with optional lifecycle/memory fields:</li>
<li><code>hit_counts</code></li>
<li><code>memory_bank</code></li>
<li><code>memory_counts</code></li>
<li>extended <code>AssociationResult</code> with lifecycle debug outputs:</li>
<li><code>terminated_track_indices</code></li>
<li><code>terminated_track_ids</code></li>
<li><code>created_track_ids</code></li>
<li>kept backward compatibility:</li>
<li><code>GreedyCosineAssociator</code> now delegates to Hungarian with cosine-only cost</li>
<li>protocol aliases preserved</li>
</ul>
</li>
<li>Updated <code>apex_x/infer/__init__.py</code> exports:<ul>
<li><code>HungarianAssociator</code></li>
<li><code>hungarian_assignment</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_tracking_hungarian.py</code>:<ul>
<li>Hungarian global-optimum assignment on synthetic cost matrix</li>
<li>IoU + embedding-distance gating behavior</li>
<li>lifecycle termination after <code>max_age</code></li>
<li>memory-bank update/cap behavior</li>
<li>multi-frame moving-object ID consistency across reordered detections</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/infer/tracking.py apex_x/infer/__init__.py tests/test_tracking_interfaces.py tests/test_tracking_hungarian.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/infer/tracking.py apex_x/infer/__init__.py tests/test_tracking_interfaces.py tests/test_tracking_hungarian.py</code></li>
<li><code>python -m pytest -q tests/test_tracking_interfaces.py tests/test_tracking_hungarian.py tests/test_track_head.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>PCGrad++ shared-trunk conflict projection implemented:</li>
<li>Added <code>apex_x/train/pcgrad.py</code>:<ul>
<li>canonical grouped loss ordering:</li>
<li><code>det_cls</code>, <code>det_box</code>, <code>seg_mask</code>, <code>seg_boundary</code>, then sorted extras</li>
<li><code>LossGroup</code> dataclass and <code>group_loss_terms(...)</code></li>
<li><code>apply_pcgradpp(...)</code>:</li>
<li>computes per-group gradients</li>
<li>applies projection only to shared trunk parameter gradients when <code>cos &lt; 0</code></li>
<li>leaves task-head parameter gradients as standard total-loss gradients</li>
<li><code>PCGradDiagnostics</code> + <code>diagnostics_to_dict(...)</code> for logging/debug</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/train/__init__.py</code>:<ul>
<li><code>DEFAULT_LOSS_GROUP_ORDER</code></li>
<li><code>LossGroup</code></li>
<li><code>PCGradDiagnostics</code></li>
<li><code>group_loss_terms</code></li>
<li><code>apply_pcgradpp</code></li>
<li><code>diagnostics_to_dict</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_pcgradpp.py</code>:<ul>
<li>deterministic grouped ordering for canonical loss groups + extra loss terms</li>
<li>tiny-network synthetic conflicting gradients test:</li>
<li>confirms projection resolves shared-trunk conflict</li>
<li>confirms head gradients match standard total-loss gradients (no projection on heads)</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/train/pcgrad.py apex_x/train/__init__.py tests/test_pcgradpp.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/train/pcgrad.py apex_x/train/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_pcgradpp.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Distillation losses implemented (logits KL + feature L2 + boundary distill):</li>
<li>Added <code>apex_x/losses/distill.py</code>:<ul>
<li><code>logits_kl_distill(...)</code>:</li>
<li>KL divergence distillation on logits with temperature scaling (<code>T^2</code> factor)</li>
<li><code>feature_l2_distill(...)</code>:</li>
<li>layer-selective feature L2 distillation with optional per-layer weights</li>
<li>supports optional feature normalization before L2</li>
<li><code>boundary_distill_loss(...)</code>:</li>
<li>boundary-focused distillation using Sobel-based soft boundary maps</li>
<li>teacher boundary distance-transform weighting</li>
<li><code>distillation_losses(...)</code>:</li>
<li>combined wrapper returning <code>DistillationLossOutput</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/losses/__init__.py</code>:<ul>
<li><code>DistillationLossOutput</code></li>
<li><code>logits_kl_distill</code></li>
<li><code>feature_l2_distill</code></li>
<li><code>boundary_distill_loss</code></li>
<li><code>distillation_losses</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_distill_loss.py</code>:<ul>
<li>KL distill near-zero when student/teacher logits match</li>
<li>feature L2 selected-layer behavior with layer weights</li>
<li>boundary distill penalizes shifted boundaries more than aligned boundaries</li>
<li>combined distillation loss decreases in toy optimization</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/losses/distill.py apex_x/losses/__init__.py tests/test_distill_loss.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/losses/distill.py apex_x/losses/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_distill_loss.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Oracle Loss targets and router utility supervision implemented:</li>
<li>Added <code>apex_x/routing/oracle_distill.py</code>:<ul>
<li><code>compute_oracle_delta_targets(...)</code>:</li>
<li>computes sampled-tile oracle targets:<ul>
<li><code>_i = L_distill(cheap, teacher) - L_distill(heavy, teacher)</code></li>
</ul>
</li>
<li>supports sampled indices <code>[S]</code> or batched <code>[B,S]</code></li>
<li>returns detached (stop-grad) oracle targets</li>
<li>optional clamping for outlier robustness</li>
<li><code>utility_regression_loss(...)</code>:</li>
<li>regression loss (<code>l1</code> / <code>mse</code> / <code>smooth_l1</code>) between router utility logits and detached  targets</li>
<li><code>utility_ranking_loss(...)</code>:</li>
<li>pairwise hinge ranking loss over sampled tiles to preserve oracle ordering</li>
<li><code>utility_oracle_loss(...)</code>:</li>
<li>combined regression + ranking objective with diagnostics (<code>num_pairs</code>)</li>
<li>dataclasses:</li>
<li><code>OracleDeltaTargets</code></li>
<li><code>UtilityOracleLossOutput</code></li>
</ul>
</li>
<li>Updated routing exports in <code>apex_x/routing/__init__.py</code>:<ul>
<li><code>RegressionLossType</code></li>
<li><code>OracleDeltaTargets</code></li>
<li><code>UtilityOracleLossOutput</code></li>
<li><code>compute_oracle_delta_targets</code></li>
<li><code>utility_regression_loss</code></li>
<li><code>utility_ranking_loss</code></li>
<li><code>utility_oracle_loss</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_oracle_distill.py</code>:<ul>
<li>sign sanity for  targets (positive when heavy distill loss is lower than cheap)</li>
<li>stop-grad behavior (no gradients into cheap/heavy distill losses via utility supervision)</li>
<li>ranking sign sanity (correct utility order yields lower ranking loss)</li>
<li>sampled-index regression correctness (only sampled tiles influence loss)</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/routing/oracle_distill.py apex_x/routing/__init__.py tests/test_oracle_distill.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/routing/oracle_distill.py apex_x/routing/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_oracle_distill.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>TeacherModel implemented for full-compute distillation outputs with optional EMA:</li>
<li>Added <code>apex_x/model/teacher.py</code>:<ul>
<li><code>TeacherModel</code>:</li>
<li>dense/full-compute teacher forward path (PV -&gt; FPN -&gt; DET) without sparse routing</li>
<li>standardized distillation output bundle:<ul>
<li>flattened logits (<code>logits</code>)</li>
<li>per-level logits (<code>logits_by_level</code>)</li>
<li>selected feature layers (<code>features</code>)</li>
<li>boundary proxy map aligned to input size (<code>boundaries</code>)</li>
</ul>
</li>
<li>optional EMA shadow modules:<ul>
<li>configurable <code>ema_decay</code></li>
<li><code>update_ema(...)</code> for parameter/buffer updates</li>
<li>runtime switch to use online or EMA weights in <code>forward(...)</code></li>
</ul>
</li>
<li><code>TeacherDistillOutput</code> dataclass</li>
<li><code>flatten_logits_for_distill(...)</code> helper with deterministic level order</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/model/__init__.py</code>:<ul>
<li><code>TeacherModel</code></li>
<li><code>TeacherDistillOutput</code></li>
<li><code>flatten_logits_for_distill</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_teacher_model.py</code>:<ul>
<li>full-compute standardized output contract checks</li>
<li>deterministic logits-flatten ordering checks</li>
<li>EMA behavior checks:</li>
<li>initial online/EMA parity</li>
<li>EMA lag + update movement toward online model</li>
<li>frozen EMA parameter requirements</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/model/teacher.py apex_x/model/__init__.py tests/test_teacher_model.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/model/teacher.py apex_x/model/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_teacher_model.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Staged trainer pipeline implemented and wired into CLI <code>train</code> flow:</li>
<li>Added <code>apex_x/train/trainer.py</code>:<ul>
<li><code>ApexXTrainer</code> with required stages:</li>
<li>stage 0: baseline warmup</li>
<li>stage 1: teacher training (full compute)</li>
<li>stage 2: oracle bootstrapping</li>
<li>stage 3: continuous budgeting with dual <code>mu</code></li>
<li>stage 4: deterministic inference emulation</li>
<li>stage/result dataclasses:</li>
<li><code>StageResult</code></li>
<li><code>StagedTrainResult</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/train/__init__.py</code>:<ul>
<li><code>ApexXTrainer</code></li>
<li><code>StageResult</code></li>
<li><code>StagedTrainResult</code></li>
</ul>
</li>
<li>Updated CLI <code>train</code> command in <code>apex_x/cli.py</code>:<ul>
<li>now runs staged trainer instead of placeholder-only loop</li>
<li>new option: <code>--steps-per-stage</code></li>
<li>output includes <code>stage_count=5</code></li>
</ul>
</li>
<li>Added staged-train CPU smoke script:<ul>
<li><code>examples/train_stages_smoke.py</code></li>
</ul>
</li>
<li>Added validation coverage:<ul>
<li><code>tests/test_trainer_stages.py</code> (stage completeness + seed repeatability)</li>
<li><code>tests/test_train_stages_smoke.py</code> (subprocess smoke run)</li>
<li>updated <code>tests/test_cli.py</code> to assert staged output includes <code>stage_count=5</code></li>
</ul>
</li>
<li>Updated docs:<ul>
<li><code>README.md</code> now includes staged trainer quickstart/dev commands</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/train/trainer.py apex_x/cli.py tests/test_trainer_stages.py tests/test_train_stages_smoke.py tests/test_cli.py examples/train_stages_smoke.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/train/trainer.py apex_x/cli.py</code></li>
<li><code>python -m pytest -q tests/test_trainer_stages.py tests/test_train_stages_smoke.py tests/test_cli.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Exact COCO compatibility layer implemented with strict schema checks and mask parsing:</li>
<li>Added <code>apex_x/data/coco.py</code> with a strict COCO loader:<ul>
<li><code>load_coco_dataset(path, strict=True, use_cache=True)</code></li>
<li>strict top-level/record key validation (<code>images</code>, <code>annotations</code>, <code>categories</code>)</li>
<li>type/range checks for ids, bbox, area, iscrowd, segmentation payloads</li>
<li>referential integrity checks for <code>annotation.image_id</code> and <code>annotation.category_id</code></li>
</ul>
</li>
<li>Added complete parsing contracts:<ul>
<li>bbox parsing into <code>CocoBBox</code></li>
<li>polygon segmentation parsing into <code>CocoSegmentation(kind=\"polygon\")</code></li>
<li>RLE parsing for uncompressed list counts and compressed string counts into
  <code>CocoSegmentation(kind=\"rle\")</code></li>
<li>deterministic mask decode path via <code>segmentation_to_mask(...)</code></li>
</ul>
</li>
<li>Added category mapping + caching:<ul>
<li><code>CocoDataset.category_mapping()</code> caches contiguous category mapping:</li>
<li><code>original_to_contiguous</code></li>
<li><code>contiguous_to_original</code></li>
<li>category name lookup maps</li>
<li>loader cache for parsed datasets with mtime/size cache key</li>
<li><code>clear_coco_dataset_cache()</code> helper</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/data/__init__.py</code> for COCO dataclasses/helpers.</li>
<li>Added fixture-based tests:<ul>
<li><code>tests/test_coco_compat.py</code></li>
<li>fixtures:</li>
<li><code>tests/fixtures/coco_valid_mixed.json</code></li>
<li><code>tests/fixtures/coco_invalid_missing_top_keys.json</code></li>
<li><code>tests/fixtures/coco_invalid_bad_rle.json</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/data/coco.py apex_x/data/__init__.py tests/test_coco_compat.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/data/coco.py apex_x/data/__init__.py tests/test_coco_compat.py</code></li>
<li><code>python -m pytest -q tests/test_coco_compat.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Data transforms pipeline and Mosaic-v2 heuristic implemented:</li>
<li>Added <code>apex_x/data/transforms.py</code>:<ul>
<li>shared sample contract:</li>
<li><code>TransformSample</code> (image + <code>boxes_xyxy</code> + <code>class_ids</code> + optional masks)</li>
<li>pipeline + base transforms:</li>
<li><code>TransformPipeline</code></li>
<li><code>RandomHorizontalFlip</code></li>
<li><code>ClipBoxesAndMasks</code></li>
<li><code>sanitize_sample(...)</code> for clipping/filtering invalid boxes/masks</li>
<li>Mosaic-v2:</li>
<li><code>MosaicV2(...)</code> 4-image composition with configurable split jitter</li>
<li>heuristic crop-origin policy to protect important instances
    (by area threshold fallback-to-largest instance)</li>
<li>visibility-aware bbox filtering and mask-aware validity checks</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/data/__init__.py</code>:<ul>
<li><code>TransformSample</code>, <code>Transform</code>, <code>TransformPipeline</code></li>
<li><code>RandomHorizontalFlip</code>, <code>ClipBoxesAndMasks</code>, <code>MosaicV2</code>, <code>sanitize_sample</code></li>
</ul>
</li>
<li>Added tests in <code>tests/test_data_transforms.py</code>:<ul>
<li>transform-pipeline bbox/mask validity checks</li>
<li>mosaic output validity for bbox/mask contracts</li>
<li>heuristic regression test showing protected mosaic keeps significantly more
  important-instance area than unprotected crop selection</li>
<li>sanitize clipping behavior on out-of-bounds boxes</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/data/transforms.py apex_x/data/__init__.py tests/test_data_transforms.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/data/transforms.py apex_x/data/__init__.py tests/test_data_transforms.py</code></li>
<li><code>python -m pytest -q tests/test_data_transforms.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Eval pipeline implemented for DET/INST-SEG/SEM-SEG/PANO with report emission:</li>
<li>Added <code>apex_x/infer/eval_metrics.py</code>:<ul>
<li>metric computation for tiny-fixture evaluation:</li>
<li>COCO-style mAP (DET) over IoU thresholds <code>0.50:0.05:0.95</code></li>
<li>COCO-style mask mAP (INST-SEG) over IoU thresholds <code>0.50:0.05:0.95</code></li>
<li>mIoU (SEM-SEG)</li>
<li>PQ (PANO) via existing <code>evaluate_panoptic_quality(...)</code></li>
<li>fixture evaluators:</li>
<li><code>evaluate_fixture_payload(...)</code></li>
<li><code>evaluate_fixture_file(...)</code></li>
<li>built-in fallback payload <code>tiny_eval_fixture_payload()</code></li>
<li>report writers:</li>
<li><code>write_eval_reports(...)</code> emitting JSON + Markdown</li>
<li>structured summary dataclass <code>EvalSummary</code></li>
</ul>
</li>
<li>Updated exports in <code>apex_x/infer/__init__.py</code>:<ul>
<li><code>EvalSummary</code>, <code>evaluate_fixture_file</code>, <code>evaluate_fixture_payload</code>,
  <code>tiny_eval_fixture_payload</code>, <code>write_eval_reports</code></li>
</ul>
</li>
<li>Updated CLI eval command in <code>apex_x/cli.py</code>:<ul>
<li>supports:</li>
<li><code>--fixture</code> (optional fixture JSON; defaults to built-in tiny payload)</li>
<li><code>--report-json</code></li>
<li><code>--report-md</code></li>
<li>always emits metrics in stdout:</li>
<li><code>det_map</code>, <code>mask_map</code>, <code>miou</code>, <code>panoptic_pq</code></li>
<li>writes JSON and markdown report files per invocation</li>
<li>keeps <code>--panoptic-pq</code> flag as compatibility no-op</li>
</ul>
</li>
<li>Added tiny fixture + tests:<ul>
<li>fixture: <code>tests/fixtures/eval_tiny_fixture.json</code></li>
<li><code>tests/test_eval_metrics.py</code>:</li>
<li>metric values on perfect tiny fixture</li>
<li>JSON/Markdown report emission</li>
<li>built-in tiny payload validation</li>
<li><code>tests/test_cli.py</code>:</li>
<li>eval command smoke with fixture + output report paths</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/infer/eval_metrics.py apex_x/infer/__init__.py apex_x/cli.py tests/test_eval_metrics.py tests/test_cli.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/infer/eval_metrics.py apex_x/infer/__init__.py apex_x/cli.py tests/test_eval_metrics.py tests/test_cli.py</code></li>
<li><code>python -m pytest -q tests/test_eval_metrics.py tests/test_cli.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Ablation grid runner implemented in CLI with toggle sweeps and reports:</li>
<li>Added <code>apex_x/train/ablation.py</code>:<ul>
<li>toggle grid definitions for:</li>
<li><code>router</code>, <code>budgeting</code>, <code>nesting</code>, <code>ssm</code>, <code>distill</code>,
    <code>pcgrad</code>, <code>qat</code>, <code>panoptic</code>, <code>tracking</code></li>
<li>deterministic grid builder:</li>
<li><code>build_ablation_grid(...)</code> with per-toggle modes (<code>on/off/both</code>) and max-cap</li>
<li>ablation execution:</li>
<li>fixed-seed runs over grid combinations</li>
<li>trainer invocation with <code>enable_budgeting</code> switch</li>
<li>metrics aggregation (DET mAP, mask mAP, semantic mIoU, PQ, tracking consistency)</li>
<li>routing stat aggregation (selected ratios, budget usage ratio, <code>mu_last</code>)</li>
<li>report writers:</li>
<li>CSV aggregate report</li>
<li>markdown summary report</li>
</ul>
</li>
<li>Updated <code>ApexXTrainer.run(...)</code> in <code>apex_x/train/trainer.py</code>:<ul>
<li>added <code>enable_budgeting</code> flag for explicit budgeting on/off ablations</li>
</ul>
</li>
<li>Updated exports in <code>apex_x/train/__init__.py</code>:<ul>
<li>ablation dataclasses/functions (<code>AblationToggleSet</code>, grid runner, report writer)</li>
</ul>
</li>
<li>Updated CLI <code>ablate</code> command in <code>apex_x/cli.py</code>:<ul>
<li>added per-toggle mode flags (<code>--router/--budgeting/.../--tracking</code>)</li>
<li>added fixed seed support via repeated <code>--seed</code></li>
<li>added <code>--steps-per-stage</code>, <code>--max-experiments</code></li>
<li>added report outputs:</li>
<li><code>--output-csv</code></li>
<li><code>--output-md</code></li>
<li>command now runs grid + writes CSV/MD reports</li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_ablation.py</code>:</li>
<li>grid construction behavior</li>
<li>smoke run + CSV/MD output assertions</li>
<li>updated <code>tests/test_cli.py</code>:</li>
<li><code>ablate</code> command smoke with output artifact checks</li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/train/ablation.py apex_x/train/__init__.py apex_x/train/trainer.py apex_x/cli.py tests/test_ablation.py tests/test_cli.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/train/ablation.py apex_x/train/__init__.py apex_x/train/trainer.py apex_x/cli.py tests/test_ablation.py tests/test_cli.py</code></li>
<li><code>python -m pytest -q tests/test_ablation.py tests/test_cli.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>INT8 QAT + PTQ fallback path implemented with FP16 router/gating policy:</li>
<li>Added <code>apex_x/train/qat.py</code>:<ul>
<li>activation observer + activation fake quant:</li>
<li><code>ActivationObserver</code></li>
<li><code>ActivationFakeQuant</code></li>
<li>per-channel INT8 weight fake quant:</li>
<li><code>WeightPerChannelFakeQuant</code></li>
<li>wrapped train-time fake quant modules:</li>
<li><code>FakeQuantConv2d</code></li>
<li><code>FakeQuantLinear</code></li>
<li>QAT/PTQ entrypoints:</li>
<li><code>prepare_int8_qat(...)</code></li>
<li><code>prepare_int8_ptq(...)</code></li>
<li><code>calibrate_ptq(...)</code></li>
<li>explicit wrapper traversal/state controls:</li>
<li><code>iter_qat_wrappers(...)</code></li>
<li><code>set_qat_state(...)</code></li>
</ul>
</li>
<li>Updated <code>apex_x/train/trainer.py</code>:<ul>
<li>quantization preparation step added before staged training:</li>
<li>uses QAT when <code>train.qat_enable &amp;&amp; train.qat_int8</code></li>
<li>uses PTQ calibration fallback when <code>runtime.precision_profile=edge</code> and QAT is off</li>
<li>added deterministic calibration batch builder for PTQ fallback</li>
<li>added quantization diagnostics to <code>train_summary["quantization"]</code>:</li>
<li><code>mode</code>, <code>wrapped_modules</code>, <code>calibration_batches</code>, <code>router_gating_fp16</code></li>
<li>stage-3 routing gate path now keeps FP16 utility gating math and uses FP32 expected-cost accumulation</li>
</ul>
</li>
<li>Updated <code>apex_x/train/__init__.py</code>:<ul>
<li>exported QAT module types/functions for public train API surface</li>
</ul>
</li>
<li>Added tests in <code>tests/test_qat.py</code>:<ul>
<li>QAT wrapper conversion with router/gating skip policy</li>
<li>PTQ calibration state transitions (observer off + fake quant on after calibration)</li>
<li>trainer-level QAT/PTQ toggle smoke with finite loss/output checks</li>
</ul>
</li>
<li>Added documentation:<ul>
<li><code>docs/QAT.md</code> with INT8 policy, module behavior, trainer integration, and validation scope</li>
<li>linked in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/train/qat.py apex_x/train/trainer.py apex_x/train/__init__.py tests/test_qat.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/train/qat.py apex_x/train/trainer.py apex_x/train/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_qat.py tests/test_trainer_stages.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>FP8-ready precision policy implemented with safe FP16 fallback:</li>
<li>Added <code>apex_x/runtime/precision.py</code>:<ul>
<li>precision policy dataclass:</li>
<li><code>PrecisionPolicy</code></li>
<li>runtime detection + resolution:</li>
<li><code>resolve_precision_policy(...)</code></li>
<li>conservative CUDA FP8 support gate (<code>sm90+</code> + torch FP8 dtype presence)</li>
<li>dtype helpers:</li>
<li><code>dtype_name(...)</code></li>
<li>execution context helper:</li>
<li><code>heavy_ops_autocast_context(...)</code><ul>
<li>FP16 autocast path on CPU/CUDA</li>
<li>FP8-ready no-op context pending specialized kernels/plugins</li>
</ul>
</li>
</ul>
</li>
<li>Updated <code>apex_x/runtime/__init__.py</code> exports:<ul>
<li><code>PrecisionPolicy</code>, <code>resolve_precision_policy</code>, <code>dtype_name</code>, <code>heavy_ops_autocast_context</code></li>
</ul>
</li>
<li>Updated <code>apex_x/train/trainer.py</code>:<ul>
<li>resolves precision policy at trainer init</li>
<li>applies heavy-op autocast context during stage-1 teacher forward</li>
<li>adds stage metrics:</li>
<li><code>heavy_ops_dtype</code>, <code>fp8_enabled</code></li>
<li>adds precision diagnostics in <code>train_summary["precision"]</code>:</li>
<li><code>profile</code>, <code>device</code>, <code>heavy_ops_dtype</code></li>
<li><code>fp8_requested</code>, <code>fp8_enabled</code>, <code>fallback_reason</code></li>
<li><code>router_dtype</code>, <code>kan_dtype</code></li>
</ul>
</li>
<li>Updated <code>apex_x/train/qat.py</code>:<ul>
<li>expanded INT8 wrapper skip policy to preserve FP16 for KAN-like modules:</li>
<li>default skip tokens now include <code>"kan"</code> in addition to router/gating names</li>
</ul>
</li>
<li>Added tests in <code>tests/test_precision_policy.py</code>:<ul>
<li>CPU fallback smoke (<code>balanced</code> -&gt; FP16 fallback with explicit reason)</li>
<li>mocked supported CUDA path enabling FP8 for heavy ops</li>
<li>trainer summary smoke verifying fallback diagnostics</li>
</ul>
</li>
<li>Added docs:<ul>
<li><code>docs/FP8.md</code> documenting FP8 request rules, support detection, fallback contract, and smoke coverage</li>
<li>linked from <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/runtime/precision.py apex_x/runtime/__init__.py apex_x/train/trainer.py apex_x/train/qat.py tests/test_precision_policy.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/runtime/precision.py apex_x/runtime/__init__.py apex_x/train/trainer.py</code></li>
<li><code>python -m pytest -q tests/test_precision_policy.py tests/test_trainer_stages.py tests/test_qat.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>Triton fused gather+gate+scatter path scaffolded with clean fallback to reference:</li>
<li>Environment check result for this workspace:<ul>
<li><code>torch.cuda.is_available() == False</code></li>
<li>Triton package not installed</li>
<li>therefore Triton kernel implementation path is unavailable in this run</li>
</ul>
</li>
<li>Added <code>apex_x/runtime/triton_fused.py</code>:<ul>
<li>availability model:</li>
<li><code>TritonAvailability</code></li>
<li><code>get_triton_availability()</code></li>
<li>fused-result contract:</li>
<li><code>FusedTileScatterResult</code></li>
<li>reference fused pipeline:</li>
<li><code>gather_gate_scatter_reference(...)</code></li>
<li>implements:<ul>
<li>gather selected heavy/base/proxy tiles</li>
<li>per-pixel fusion gate application</li>
<li>scatter with overlap priority semantics via <code>TileUnpackTorch</code></li>
</ul>
</li>
<li>dispatch API:</li>
<li><code>gather_gate_scatter(...)</code></li>
<li>attempts Triton path when requested and available</li>
<li>cleanly falls back to reference path when unavailable or stubbed</li>
<li>explicit Triton kernel stub:</li>
<li><code>_triton_fused_kernel_stub(...)</code> raises <code>NotImplementedError</code> (by design in no-Triton env)</li>
</ul>
</li>
<li>Updated <code>apex_x/runtime/__init__.py</code> exports:<ul>
<li><code>get_triton_availability</code></li>
<li><code>gather_gate_scatter_reference</code></li>
<li><code>gather_gate_scatter</code></li>
<li>availability/result/backend dataclasses/types</li>
</ul>
</li>
<li>Added microbenchmark script:<ul>
<li><code>scripts/triton_fused_bench.py</code></li>
<li>compares reference path vs dispatched fused path</li>
<li>reports backend, fallback reason, and speed ratio</li>
<li>works on CPU fallback path</li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_triton_fused.py</code>:</li>
<li>reference fused path parity vs explicit reference composition</li>
<li>dispatch fallback behavior in no-Triton/no-CUDA case</li>
<li>forced Triton/no-fallback path raises stub error</li>
<li><code>tests/test_triton_bench.py</code>:</li>
<li>CPU smoke for benchmark utility</li>
</ul>
</li>
<li>Added runtime docs:<ul>
<li><code>docs/runtime/TRITON.md</code> describing dispatch contracts, fallback behavior, and benchmark usage</li>
<li>linked in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Verification status:<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/runtime/triton_fused.py apex_x/runtime/__init__.py tests/test_triton_fused.py tests/test_triton_bench.py scripts/triton_fused_bench.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/runtime/triton_fused.py apex_x/runtime/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_triton_fused.py tests/test_triton_bench.py tests/test_tile_pack_torch.py tests/test_tile_unpack_torch.py</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>CPU performance regression suite implemented with baseline comparison gates:</li>
<li>Added reusable perf suite module:<ul>
<li><code>apex_x/bench/perf.py</code></li>
<li>fixed-size infer benchmark (<code>ApexXModel.forward</code> on <code>[1,3,128,128]</code>)</li>
<li>microbenchmarks:</li>
<li><code>TilePackTorch</code></li>
<li><code>TileUnpackTorch</code></li>
<li><code>FusionGate</code></li>
<li>report + compare helpers:</li>
<li><code>run_cpu_perf_suite(...)</code></li>
<li><code>compare_against_baseline(...)</code></li>
<li>JSON read/write helpers</li>
</ul>
</li>
<li>Updated <code>apex_x/bench/__init__.py</code> exports:<ul>
<li>perf suite and compare utilities exposed</li>
</ul>
</li>
<li>Replaced <code>scripts/perf_regression.py</code>:<ul>
<li>runs suite and writes current JSON report</li>
<li>optional baseline-template emit</li>
<li>compare mode with pass/fail exit status for CI gating</li>
<li>artifacts:</li>
<li>current report JSON</li>
<li>comparison summary JSON</li>
</ul>
</li>
<li>Added committed CPU baseline:<ul>
<li><code>scripts/perf_baseline_cpu.json</code></li>
<li>per-metric tolerances via:</li>
<li><code>max_regression_ratio</code></li>
<li><code>max_regression_abs_ms</code></li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_perf_regression.py</code></li>
<li>suite smoke coverage</li>
<li>baseline compare pass/fail behavior</li>
</ul>
</li>
<li>Added documentation:<ul>
<li><code>docs/PERF.md</code></li>
<li>linked from <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Updated CI workflow:<ul>
<li><code>.github/workflows/ci.yml</code> now includes <code>perf-regression</code> job on <code>ubuntu-latest</code> (CPU-only)</li>
<li>job executes <code>scripts/perf_regression.py --compare ...</code></li>
<li>job uploads perf artifacts (<code>perf_current_ci.json</code>, <code>perf_compare_ci.json</code>)</li>
</ul>
</li>
<li>
<p>Verification status:</p>
<ul>
<li>targeted checks passed:</li>
<li><code>python -m ruff check apex_x/bench/perf.py apex_x/bench/__init__.py scripts/perf_regression.py tests/test_perf_regression.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/bench/perf.py apex_x/bench/__init__.py scripts/perf_regression.py</code></li>
<li><code>python -m pytest -q tests/test_perf_regression.py</code></li>
<li><code>python scripts/perf_regression.py --compare --baseline scripts/perf_baseline_cpu.json --output artifacts/perf_current_test.json --summary artifacts/perf_compare_test.json --infer-iters 15 --micro-iters 25 --infer-warmup 3 --micro-warmup 3</code></li>
<li>full checks passed:</li>
<li><code>python -m ruff check .</code></li>
<li><code>python -m mypy --cache-dir=/dev/null</code></li>
<li><code>python -m pytest -q</code></li>
</ul>
</li>
<li>
<p>TensorRT + Go runtime scaffolding added (Task A/B):</p>
</li>
<li>TensorRT C++ scaffold created under <code>runtime/tensorrt/</code>:<ul>
<li><code>CMakeLists.txt</code> with optional feature probes:</li>
<li><code>APEXX_ENABLE_TENSORRT</code> only when <code>NvInfer.h</code> is found</li>
<li><code>APEXX_ENABLE_CUDA</code> only when CUDA compiler is available</li>
<li>stub plugin interfaces/sources:</li>
<li><code>TilePack</code></li>
<li><code>TileSSMScan</code></li>
<li><code>TileUnpackFusion</code></li>
<li>optional <code>DecodeNMS</code></li>
<li>utility binary:</li>
<li><code>apexx_trt_plugin_info</code> (prints build summary and plugin flags)</li>
</ul>
</li>
<li>TensorRT docs added:<ul>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li>contract mapping from plugin spec to scaffold classes</li>
<li>guarded build instructions:</li>
<li><code>cd runtime/tensorrt &amp;&amp; cmake -S . -B build &amp;&amp; cmake --build build -j</code></li>
</ul>
</li>
<li>Go microservice scaffold created under <code>runtime/go/</code>:<ul>
<li>service entrypoint:</li>
<li><code>runtime/go/cmd/apexx-runtime/main.go</code></li>
<li>endpoints:</li>
<li><code>POST /predict</code></li>
<li><code>GET /health</code></li>
<li><code>GET /metrics</code></li>
<li>short-window batching queue with per-request budget profile support (<code>quality|balanced|edge</code>)</li>
<li>adapters:</li>
<li>ONNX Runtime CPU baseline scaffold (<code>ORTAdapter</code>)</li>
<li>TensorRT CGO scaffold with build tags:<ul>
<li><code>//go:build tensorrt &amp;&amp; cgo</code></li>
<li>default fallback returns clear unavailable error</li>
</ul>
</li>
<li>containerization:</li>
<li><code>runtime/go/Dockerfile</code></li>
<li><code>runtime/go/docker-compose.yml</code></li>
<li>tests:</li>
<li><code>runtime/go/internal/service/batcher_test.go</code></li>
<li><code>runtime/go/internal/service/http_test.go</code></li>
</ul>
</li>
<li>CI/docs integration updates:<ul>
<li><code>.github/workflows/ci.yml</code> now includes <code>go-runtime</code> job (<code>go test ./...</code> in <code>runtime/go</code>)</li>
<li><code>mkdocs.yml</code> + <code>docs/index.md</code> now link <code>docs/runtime/TENSORRT.md</code></li>
<li><code>runtime/README.md</code> and root <code>README.md</code> updated with runtime scaffold usage</li>
</ul>
</li>
<li>Build/run commands verified for scaffolds:<ul>
<li>Go tests:</li>
<li><code>cd runtime/go &amp;&amp; go test ./...</code></li>
<li>Go service:</li>
<li><code>cd runtime/go &amp;&amp; go run ./cmd/apexx-runtime -addr :8080 -adapter onnxruntime</code></li>
<li>TensorRT scaffold build commands documented (not executed in this environment due missing <code>cmake</code>):</li>
<li><code>cd runtime/tensorrt &amp;&amp; cmake -S . -B build &amp;&amp; cmake --build build -j</code></li>
</ul>
</li>
<li>
<p>Remaining work from this milestone:</p>
<ul>
<li>implement real TensorRT plugin classes (<code>IPluginV2DynamicExt</code>) + serialization</li>
<li>replace ORT stub adapter with true ONNX Runtime session execution</li>
<li>implement TensorRT CGO adapter bridge to compiled plugin/runtime binaries</li>
<li>add optional gRPC server for the Go service (HTTP baseline is complete)</li>
</ul>
</li>
<li>
<p>Runtime capability detection module implemented:</p>
</li>
<li>Added <code>apex_x/runtime/caps.py</code> with unified runtime probe object:<ul>
<li><code>RuntimeCaps</code></li>
<li><code>cuda: CudaCaps</code></li>
<li><code>triton: TritonCaps</code></li>
<li><code>tensorrt: TensorRTCaps</code></li>
<li><code>fp8: FP8Caps</code></li>
<li>exported from <code>apex_x/runtime/__init__.py</code></li>
</ul>
</li>
<li>Detection coverage:<ul>
<li>CUDA availability + device name + compute capability</li>
<li>Triton availability + version</li>
<li>TensorRT:</li>
<li>Python package/module availability</li>
<li>header availability (<code>NvInfer.h</code>/<code>NvInferRuntime.h</code>) via:<ul>
<li>explicit <code>header_search_paths</code></li>
<li>env hints (<code>TENSORRT_INCLUDE_DIR</code>, <code>TRT_INCLUDE_DIR</code>, <code>TENSORRT_ROOT</code>, <code>TRT_ROOT</code>, <code>CUDA_HOME</code>, <code>CUDA_PATH</code>)</li>
<li>common include directories</li>
</ul>
</li>
<li>INT8 availability gate for TRT usage (<code>BuilderFlag.INT8</code> + CUDA)</li>
<li>FP8 availability gate:</li>
<li>torch FP8 dtype support</li>
<li>CUDA presence</li>
<li>compute capability <code>sm90+</code></li>
</ul>
</li>
<li>Added tests (CPU-safe, mock-driven):<ul>
<li><code>tests/test_caps_runtime.py</code></li>
<li><code>tests/test_caps_tensorrt_fp8.py</code></li>
</ul>
</li>
<li>Added docs:<ul>
<li><code>docs/runtime/CAPS.md</code></li>
<li>linked in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Usage instructions:<ul>
<li>basic:</li>
<li><code>from apex_x.runtime import detect_runtime_caps</code></li>
<li><code>caps = detect_runtime_caps()</code></li>
<li><code>caps.to_dict()</code></li>
<li>explicit TRT header path:</li>
<li><code>detect_runtime_caps(header_search_paths=["/usr/local/TensorRT/include"])</code></li>
</ul>
</li>
<li>
<p>Validation status:</p>
<ul>
<li><code>python -m pytest -q tests/test_caps_runtime.py tests/test_caps_tensorrt_fp8.py</code></li>
<li><code>python -m ruff check apex_x/runtime/caps.py tests/test_caps_runtime.py tests/test_caps_tensorrt_fp8.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/runtime/caps.py apex_x/runtime/__init__.py</code></li>
</ul>
</li>
<li>
<p>Runtime parity framework implemented:</p>
</li>
<li>Added <code>apex_x/runtime/parity.py</code> with backend-agnostic parity APIs:<ul>
<li><code>ParityCase</code>, <code>run_parity_case(...)</code>, <code>evaluate_parity_outputs(...)</code></li>
<li>tolerance controls:</li>
<li><code>NumericTolerance</code></li>
<li><code>ToleranceConfig</code> (<code>default</code>, <code>fp16</code>, <code>bf16</code>, <code>int8</code>)</li>
<li>reporting objects:</li>
<li><code>TensorParityStats</code></li>
<li><code>ParityReport</code></li>
<li><code>format_parity_report(...)</code></li>
</ul>
</li>
<li>Determinism contract:<ul>
<li><code>run_parity_case(...)</code> calls <code>seed_all(seed, deterministic=...)</code> before input generation</li>
</ul>
</li>
<li>Metrics emitted per compared tensor:<ul>
<li><code>max_abs_err</code>, <code>mean_abs_err</code></li>
<li><code>max_rel_err</code>, <code>mean_rel_err</code></li>
<li><code>mismatch_count</code>, <code>total_count</code>, <code>mismatch_ratio</code></li>
<li>pass/fail against configured tolerance + mismatch-ratio limit</li>
</ul>
</li>
<li>Exported from <code>apex_x/runtime/__init__.py</code> for direct runtime use</li>
<li>Added tests:<ul>
<li><code>tests/test_parity_framework_core.py</code></li>
<li><code>tests/test_parity_framework_tolerances.py</code></li>
<li>tests are CPU-safe and use small shapes for CI speed</li>
</ul>
</li>
<li>Added documentation:<ul>
<li><code>docs/runtime/PARITY.md</code></li>
<li>linked in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Usage instructions:<ul>
<li>create a <code>ParityCase</code> with <code>input_factory</code>, <code>reference_fn</code>, and <code>candidate_fn</code></li>
<li>run <code>run_parity_case(case, seed=..., deterministic=True)</code></li>
<li>serialize/report with <code>report.to_dict()</code> or <code>format_parity_report(report)</code></li>
</ul>
</li>
<li>
<p>Validation status:</p>
<ul>
<li><code>python -m ruff check apex_x/runtime/parity.py apex_x/runtime/__init__.py tests/test_parity_framework_core.py tests/test_parity_framework_tolerances.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/runtime/parity.py apex_x/runtime/__init__.py</code></li>
<li><code>python -m pytest -q tests/test_parity_framework_core.py tests/test_parity_framework_tolerances.py</code></li>
<li><code>.venv/bin/mkdocs build --strict</code></li>
</ul>
</li>
<li>
<p>Triton TilePack gather kernel implemented with fallback dispatch:</p>
</li>
<li>Added new kernel module:<ul>
<li><code>apex_x/kernels/triton/tilepack.py</code></li>
</ul>
</li>
<li>Added package exports:<ul>
<li><code>apex_x/kernels/__init__.py</code></li>
<li><code>apex_x/kernels/triton/__init__.py</code></li>
</ul>
</li>
<li>Implemented Triton kernel contract:<ul>
<li>Input: <code>F[B,C,H,W]</code> contiguous <code>NCHW</code></li>
<li>Input indices: <code>idx[B,K]</code> integer (<code>int32</code> kernel path; <code>int64</code> accepted and cast)</li>
<li>Output: <code>P[B,K,C,t,t]</code> contiguous</li>
</ul>
</li>
<li>Kernel path support:<ul>
<li><code>fp16</code>, <code>bf16</code> on CUDA</li>
<li>no Python tile loops in kernel gather path</li>
</ul>
</li>
<li>Added vectorized reference fallback:<ul>
<li><code>tilepack_reference(...)</code> uses tensor gather (no per-tile Python loops)</li>
</ul>
</li>
<li>Added dispatch behavior:<ul>
<li><code>tilepack_dispatch(...)</code></li>
<li>falls back when Triton/CUDA unavailable</li>
<li>falls back when <code>requires_grad</code> and <code>inference_only=True</code></li>
<li>reason: Triton path is inference-oriented without custom backward registration</li>
</ul>
</li>
<li>Added parity tests:<ul>
<li><code>tests/test_triton_tilepack_parity_dispatch.py</code></li>
<li><code>tests/test_triton_tilepack_parity_gpu.py</code></li>
<li>GPU parity auto-skips when Triton/CUDA unavailable</li>
</ul>
</li>
<li>Added benchmark:<ul>
<li><code>apex_x/bench/triton_tilepack_bench.py</code></li>
</ul>
</li>
<li>Added docs:<ul>
<li><code>docs/runtime/TRITON_TILEPACK.md</code></li>
<li><code>docs/runtime/TRITON.md</code> updated with TilePack status</li>
<li>docs navigation updated in <code>docs/index.md</code> and <code>mkdocs.yml</code></li>
</ul>
</li>
<li>Run commands:<ul>
<li>tests:</li>
<li><code>python -m pytest -q tests/test_triton_tilepack_parity_dispatch.py tests/test_triton_tilepack_parity_gpu.py</code></li>
<li>bench (module):</li>
<li><code>python -m apex_x.bench.triton_tilepack_bench --iters 50 --warmup 10 --batch 1 --channels 128 --height 128 --width 128 --tile-size 8 --kmax 32 --dtype fp16</code></li>
<li>lint/type:</li>
<li><code>python -m ruff check apex_x/kernels/triton/tilepack.py apex_x/bench/triton_tilepack_bench.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/tilepack.py apex_x/bench/triton_tilepack_bench.py</code></li>
</ul>
</li>
<li>
<p>Validation status:</p>
<ul>
<li><code>python -m ruff check ...</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null ...</code> passed</li>
<li><code>python -m pytest -q tests/test_triton_tilepack_parity_dispatch.py tests/test_triton_tilepack_parity_gpu.py</code> passed (GPU tests skipped on CPU-only env)</li>
<li><code>.venv/bin/mkdocs build --strict</code> passed</li>
</ul>
</li>
<li>
<p>Triton TileUnpack scatter kernel extended to overlap + priority semantics:</p>
</li>
<li>Added kernel module:<ul>
<li><code>apex_x/kernels/triton/tileunpack.py</code></li>
</ul>
</li>
<li>Added Triton kernel dispatch/availability API:<ul>
<li><code>get_triton_tileunpack_availability()</code></li>
<li><code>tileunpack_reference(...)</code></li>
<li><code>tileunpack_triton(...)</code></li>
<li><code>tileunpack_dispatch(...)</code></li>
</ul>
</li>
<li>Added exports:<ul>
<li><code>apex_x/kernels/triton/__init__.py</code></li>
</ul>
</li>
<li>Implemented semantics:<ul>
<li>Inputs: <code>F_base[B,C,H,W]</code>, <code>P_out[B,K,C,t,t]</code>, and <code>idx/meta</code></li>
<li>Output: <code>F_merged[B,C,H,W]</code></li>
<li>deterministic overlap overwrite with priorities:</li>
<li>per-tile <code>levels[B,K]</code> (higher level wins)</li>
<li>or pre-sorted K-order (<code>assume_priority_sorted=True</code>) as implicit priority</li>
<li>default mode: <code>overlap_mode=\"override\"</code> (priority overwrite)</li>
<li>optional mode: <code>overlap_mode=\"blend\"</code> (currently reference fallback)</li>
</ul>
</li>
<li>Updated tests:<ul>
<li><code>tests/test_triton_tileunpack_parity_dispatch.py</code></li>
<li><code>tests/test_triton_tileunpack_parity_gpu.py</code></li>
<li><code>tests/test_triton_tileunpack_overlap_dispatch.py</code></li>
<li><code>tests/test_triton_tileunpack_overlap_gpu.py</code></li>
<li>includes synthetic overlap fixtures and parity against reference behavior</li>
</ul>
</li>
<li>Updated microbenchmark:<ul>
<li><code>apex_x/bench/triton_tileunpack_bench.py</code></li>
<li>supports overlap stress via <code>--overlap-shift</code></li>
<li>supports level-aware runs via default levels (<code>--no-levels</code> to disable)</li>
</ul>
</li>
<li>Added docs:<ul>
<li><code>docs/runtime/TRITON_TILEUNPACK.md</code></li>
<li>updated <code>docs/runtime/TRITON.md</code></li>
<li>updated docs nav (<code>docs/index.md</code>, <code>mkdocs.yml</code>)</li>
</ul>
</li>
<li>Run commands:<ul>
<li>parity tests:</li>
<li><code>python -m pytest -q tests/test_triton_tileunpack_parity_dispatch.py tests/test_triton_tileunpack_parity_gpu.py tests/test_triton_tileunpack_overlap_dispatch.py tests/test_triton_tileunpack_overlap_gpu.py</code></li>
<li>microbench:</li>
<li><code>python -m apex_x.bench.triton_tileunpack_bench --batch 1 --channels 128 --height 128 --width 128 --tile-size 8 --kmax 32 --overlap-shift 4 --warmup 10 --iters 50 --dtype fp16</code></li>
<li>lint/type:</li>
<li><code>python -m ruff check apex_x/kernels/triton/tileunpack.py apex_x/bench/triton_tileunpack_bench.py tests/test_triton_tileunpack_parity_dispatch.py tests/test_triton_tileunpack_parity_gpu.py tests/test_triton_tileunpack_overlap_dispatch.py tests/test_triton_tileunpack_overlap_gpu.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/tileunpack.py apex_x/bench/triton_tileunpack_bench.py</code></li>
</ul>
</li>
<li>
<p>Validation status:</p>
<ul>
<li><code>python -m ruff check ...</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null ...</code> passed</li>
<li><code>python -m pytest -q tests/test_triton_tileunpack_parity_dispatch.py tests/test_triton_tileunpack_parity_gpu.py tests/test_triton_tileunpack_overlap_dispatch.py tests/test_triton_tileunpack_overlap_gpu.py</code> passed (GPU tests skipped on CPU-only env)</li>
<li><code>python -m apex_x.bench.triton_tileunpack_bench --iters 3 --warmup 1 --batch 1 --channels 8 --height 32 --width 32 --tile-size 4 --kmax 4 --overlap-shift 2 --dtype fp16</code> executed successfully (reference backend on CPU)</li>
<li><code>.venv/bin/mkdocs build --strict</code> passed</li>
</ul>
</li>
<li>
<p>Triton FusionGate alpha/fusion kernels implemented with fallback dispatch:</p>
</li>
<li>Added kernel module:<ul>
<li><code>apex_x/kernels/triton/fusiongate.py</code></li>
</ul>
</li>
<li>Added exports:<ul>
<li><code>apex_x/kernels/triton/__init__.py</code></li>
</ul>
</li>
<li>Implemented kernels and dispatch:<ul>
<li>alpha kernel:</li>
<li>inputs: boundary/uncertainty proxies (<code>[B,1,H,W]</code> or <code>[B,H,W]</code>)</li>
<li>output: <code>alpha[B,1,H,W]</code></li>
<li>formula: <code>alpha = sigmoid(softplus(w_b) * boundary + softplus(w_u) * uncertainty + bias)</code></li>
<li>optional fusion kernel:</li>
<li><code>fused = base + alpha * (detail - base)</code></li>
<li>supports optional in-place output in dispatch API</li>
<li>fallback semantics:</li>
<li>falls back to reference when Triton/CUDA unavailable</li>
<li>falls back when autograd is requested and <code>inference_only=True</code></li>
</ul>
</li>
<li>Added tests:<ul>
<li><code>tests/test_triton_fusiongate_parity_dispatch.py</code></li>
<li><code>tests/test_triton_fusiongate_parity_gpu.py</code></li>
<li>coverage:</li>
<li>parity vs <code>apex_x.model.FusionGate.compute_alpha</code> (simplified alpha path)</li>
<li>alpha range checks (<code>[0,1]</code>)</li>
<li>optional fusion parity</li>
<li>GPU parity auto-skip without CUDA+Triton</li>
</ul>
</li>
<li>Added microbenchmark:<ul>
<li><code>apex_x/bench/triton_fusiongate_bench.py</code></li>
<li>measures:</li>
<li>alpha reference vs dispatch</li>
<li>alpha+fusion reference vs dispatch</li>
</ul>
</li>
<li>Added docs:<ul>
<li><code>docs/runtime/TRITON_FUSION.md</code></li>
<li>updated:</li>
<li><code>docs/runtime/TRITON.md</code></li>
<li><code>docs/index.md</code></li>
<li><code>mkdocs.yml</code></li>
</ul>
</li>
<li>Run commands:<ul>
<li>tests:</li>
<li><code>python -m pytest -q tests/test_triton_fusiongate_parity_dispatch.py tests/test_triton_fusiongate_parity_gpu.py</code></li>
<li>benchmark:</li>
<li><code>python -m apex_x.bench.triton_fusiongate_bench --batch 1 --channels 128 --height 128 --width 128 --warmup 10 --iters 50 --dtype fp16</code></li>
<li>lint/type:</li>
<li><code>python -m ruff check apex_x/kernels/triton/fusiongate.py apex_x/bench/triton_fusiongate_bench.py tests/test_triton_fusiongate_parity_dispatch.py tests/test_triton_fusiongate_parity_gpu.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/fusiongate.py apex_x/bench/triton_fusiongate_bench.py</code></li>
</ul>
</li>
<li>Validation status:<ul>
<li><code>python -m ruff check ...</code> passed</li>
<li><code>python -m mypy --cache-dir=/dev/null ...</code> passed</li>
<li><code>python -m pytest -q tests/test_triton_fusiongate_parity_dispatch.py tests/test_triton_fusiongate_parity_gpu.py</code> passed (GPU tests skipped on CPU-only env)</li>
<li><code>python -m apex_x.bench.triton_fusiongate_bench --iters 3 --warmup 1 --batch 1 --channels 8 --height 32 --width 32 --dtype fp16</code> executed successfully (reference backend on CPU)</li>
<li><code>.venv/bin/mkdocs build --strict</code> passed</li>
</ul>
</li>
</ul>
<h2 id="invariants-to-preserve">Invariants to Preserve</h2>
<ul>
<li>Deterministic inference tile selection under fixed config</li>
<li>Fixed <code>Kmax</code>-buffer shape contract for runtime compatibility</li>
<li>No Python-side dynamic control flow in future export graph path</li>
<li>CPU baseline must remain runnable at all times</li>
</ul>
<h2 id="open-risks">Open Risks</h2>
<ul>
<li>Tile-SSM is currently a placeholder scan, not final kernel-equivalent behavior</li>
<li>Detection/segmentation heads are minimal baseline stubs</li>
<li>Runtime plugins are currently specification-only, not implemented</li>
</ul>
<h2 id="immediate-next-steps">Immediate Next Steps</h2>
<ol>
<li>Expand baseline heads to full DET + INST-SEG proto path per spec.</li>
<li>Add explicit continuous-budget training loop example with dual <code>mu</code> update.</li>
<li>Add deterministic quadtree <code>L1/L2</code> split implementation and tests.</li>
<li>Add export smoke tests (ONNX contract checks with fixed <code>Kmax</code>).</li>
<li>Add perf threshold config file and CI perf guard for CPU baseline.</li>
<li>Add CLI entrypoints (Typer + Rich) for <code>run</code>, <code>test</code>, and <code>perf</code> commands.</li>
<li>Add initial concrete <code>losses/</code>, <code>train/</code>, <code>infer/</code>, and <code>export/</code> implementations beyond placeholders.</li>
<li>Add a typed Typer command for <code>config validate --config path.yaml --set key=value</code> using new loader/override utilities.</li>
<li>Add logging configuration knobs into <code>RuntimeConfig</code> (log level/format) and route through <code>configure_logging()</code>.</li>
<li>Add <code>apex-x config validate</code> and <code>apex-x config dump</code> subcommands for explicit config workflows.</li>
<li>Add docs deployment workflow (e.g., GitHub Pages) after docs structure stabilizes.</li>
<li>Add real TRT/ORT <code>RuntimeAdapterProtocol</code> implementations behind feature flags.</li>
<li>Add smoke example invocation to README and optionally CI as a dedicated quick check.</li>
<li>Add ADR template/checklist for future decisions to keep decision records uniform.</li>
<li>Integrate L0 mapping helpers directly inside pack/unpack metadata paths (store tile <code>(ty,tx)</code> alongside pixel origins) for easier runtime plugin parity checks.</li>
<li>Add non-square grid Hilbert fixture coverage (e.g., <code>3x5</code>, <code>5x3</code>) to lock padded-power-of-two traversal behavior.</li>
<li>Add explicit fixture snapshots for scan modes (<code>l2r/r2l/u2d/d2u</code>) on representative non-square grids and enforce them in CI.</li>
<li>Connect split-budget selection (<code>B2/B3</code>) in inference path to quadtree depth-2 mappings/metadata and add end-to-end selection tests.</li>
<li>Integrate <code>TileSelection</code>/<code>TileSelectionTrace</code> emission into model inference outputs and add CLI flag to dump selection traces for ablations.</li>
<li>Add optional CLI command to generate overlay images from stored <code>TileSelectionTrace</code> JSON for quick qualitative routing inspection.</li>
<li>Wire <code>StaticCostModel</code> into routing/inference selection path so budgeting uses per-level <code>C_c/C_h</code> + pack/unpack/split overhead directly instead of scalar placeholders.</li>
<li>Integrate <code>sample_oracle_set(...)</code> into training loops so oracle subset <code>S</code> is produced from random + uncertainty-biased policies directly from PV <code>u_hat</code>.</li>
<li>Add budget-selection debug artifact that logs per-tile score/rank and final stable tie-break order for exact replay in ablation runs.</li>
<li>Integrate PV aggregation output <code>x_i</code> into router training/inference path so utility heads consume pooled <code>mean/max/var</code> vectors instead of placeholder signals.</li>
<li>Wire <code>RouterTinyMLP</code> into model/routing execution path as the default trainable router backend (with config-selectable fallback to <code>IdentityRouter</code>).</li>
<li>Add config switch for router backend (<code>identity</code> / <code>tiny_mlp</code> / <code>kan_like</code>) and wire <code>RouterKANLike</code> into inference/training stubs.</li>
<li>Integrate <code>ste_gate_from_utilities(...)</code> into training stubs so router utilities produce <code>p_i</code>/<code>g_i</code> directly in continuous-budget examples.</li>
<li>Wire <code>BudgetDualController</code> into training stubs so <code>mu</code>, <code>E[C]</code>, and budget term are tracked/updated per step with debug logs.</li>
<li>Use <code>GreedySelectionResult.kmax_buffer</code> + <code>valid_count</code> directly in model inference outputs to mirror runtime plugin shape contracts.</li>
<li>Integrate <code>deterministic_two_stage_selection(...)</code> into model inference path so <code>B1/B2</code> and <code>L1</code> routing are exercised end-to-end in CPU baseline outputs.</li>
<li>Use <code>hysteresis_rollout(...)</code> in temporal/video inference stubs and log <code>count_mask_toggles(...)</code> as an anti-flicker metric.</li>
<li>Extend routing diagnostics to include L1/L2 selection once two-stage routing is wired into the model forward path.</li>
<li>Add optional artifact export for diagnostics snapshots (JSON + histogram plots) from CLI train/predict commands for ablation workflows.</li>
<li>Wire toggle states into YAML examples/README config snippets so users can reproduce dense/no-SSM/no-nesting baselines quickly.</li>
<li>Integrate torch tile pack/unpack path into runtime adapter abstractions and add a CPU fallback selection path for adapter-level smoke tests.</li>
<li>Integrate <code>FusionGate</code> into the model forward path (or runtime adapter path) to replace direct heavy overwrite with proxy-conditioned fusion in CPU baseline experiments.</li>
<li>Integrate <code>CheapBlock</code> into PV/FF cheap path stubs and add micro-benchmarks for block latency under CPU profiles.</li>
<li>Integrate <code>TileRefineBlock</code> after Tile-SSM in the model forward path so packed-tile local refinement is exercised end-to-end in baseline outputs.</li>
<li>Wire <code>PVBackbone</code> into model execution path as the canonical PV stream source (<code>P3/P4/P5</code>) and align routing signals to these outputs.</li>
<li>Integrate <code>PVModule</code> into <code>ApexXModel.forward</code> so routing and diagnostics consume PV coarse proxies instead of handcrafted tile-signal placeholders.</li>
<li>Replace/augment NumPy <code>tile_ssm_scan</code> usage in <code>ApexXModel.forward</code> with <code>StableStateSpaceScan</code> in torch execution paths and add parity checks for inference outputs.</li>
<li>Add <code>ApexXModel</code> config switch for scan direction mode (<code>forward</code> vs <code>bidirectional</code>) and wire merge-gated bidirectional scan into packed-tile path.</li>
<li>Wire <code>decode_and_nms(...)</code> into model/inference outputs so DET head predictions use the new deterministic decode/NMS path in end-to-end CPU runs.</li>
<li>Wire <code>PrototypeInstanceSegHead</code> into end-to-end model/infer path (using DET-selected instances) and expose assembled masks in CLI <code>predict</code> outputs.</li>
<li>Integrate <code>instance_segmentation_losses(...)</code> into training stubs with mask/box matching targets and log BCE/Dice/boundary components in trainer diagnostics.</li>
<li>Wire <code>FFTileRefinementHook</code> active-tile indices from routing outputs in model/infer path so refinement uses real FF-selected tiles end-to-end.</li>
<li>Wire <code>generate_panoptic_output(...)</code> into inference/CLI outputs so panoptic maps and <code>segments_info</code> are emitted from DET + INST-SEG + SEM-SEG predictions end-to-end.</li>
<li>Wire <code>evaluate_panoptic_quality(...)</code> into dataset evaluation loops so <code>apex-x eval</code> can consume real predicted/GT panoptic artifacts and report dataset-level PQ metrics.</li>
<li>Integrate <code>TrackEmbeddingHead</code> into model/infer outputs and add config-controlled tracking head enable/disable behavior.</li>
<li>Add a basic association loop wrapper in <code>apex_x/infer</code> that keeps <code>TrackState</code> across frames and emits stable track IDs in CLI <code>predict</code>.</li>
<li>Add optional motion gating term into Hungarian cost/gate path (for video mode) and verify flicker reduction with temporal fixtures.</li>
<li>Integrate <code>apply_pcgradpp(...)</code> into concrete training step codepath so DET/SEG grouped losses are projected on shared trunk params during optimization and surfaced in trainer diagnostics.</li>
<li>Integrate <code>distillation_losses(...)</code> into the concrete training path with config-driven weights/temperature/feature-layer selection and expose per-component values in trainer diagnostics.</li>
<li>Integrate <code>compute_oracle_delta_targets(...)</code> + <code>utility_oracle_loss(...)</code> into router training loops so sampled set <code>S</code> drives utility regression/ranking with detached oracle targets.</li>
<li>Wire <code>TeacherModel</code> into train/eval loops so EMA updates, distill outputs, and student-teacher loss plumbing are exercised end-to-end with config toggles.</li>
<li>Expand <code>ApexXTrainer</code> stage loop from smoke-level synthetic batches to dataset-backed dataloaders with checkpointing/resume support.</li>
<li>Add stage-aware CLI logging/artifacts (<code>stage_metrics.json</code>, <code>mu_history.json</code>) for ablation reproducibility.</li>
<li>Add CI smoke command for staged training CLI (<code>apex-x train --steps-per-stage 1</code>) to guard regressions in train wiring.</li>
<li>Wire <code>TransformPipeline</code> and <code>MosaicV2</code> into an actual dataset/dataloader path controlled by <code>DataConfig</code> knobs (<code>flip_prob</code>, <code>mosaic_prob</code>, scale range).</li>
<li>Add serialization/debug helpers to visualize transformed boxes/masks and mosaic split/crop decisions for reproducible augmentation ablations.</li>
<li>Add dataset-wide evaluation loops that consume real model predictions and emit the new eval report (JSON/MD) directly from inference artifacts, beyond tiny fixture mode.</li>
<li>Extend ablation runner to ingest real dataset eval outputs (instead of tiny fixture metrics) and add per-toggle significance summaries across seeds.</li>
<li>Expand QAT coverage beyond Conv/Linear wrappers to selected normalization-sensitive blocks with explicit parity gates versus FP16 baseline.</li>
<li>Add runtime-backed FP8 kernel probe path (beyond capability check) and enforce parity/perf gates before enabling FP8-by-default on compatible GPUs.</li>
<li>Implement real Triton fused gather+gate+scatter kernel and wire it under <code>gather_gate_scatter(...)</code> dispatch when CUDA+Triton are available; add parity + perf thresholds against reference path.</li>
<li>Add dataset/profile-specific perf baselines (e.g., quality/balanced/edge configs) and split tolerances by CPU model class for stricter regression gates.</li>
</ol>
<h2 id="latest-update-2026-02-08-triton-fused-stage-1-pipeline">Latest Update (2026-02-08): Triton Fused Stage-1 Pipeline</h2>
<ul>
<li>Added a new practical fused Triton fast path module:</li>
<li><code>apex_x/kernels/triton/fused_pack_op_unpack.py</code></li>
<li>Implements <code>gather -&gt; pointwise affine + ReGLU-like gate -&gt; scatter</code> in one Triton kernel launch sequence.</li>
<li>Added dispatch + fallback API:<ul>
<li><code>get_triton_fused_stage1_availability()</code></li>
<li><code>fused_pack_op_unpack_reference(...)</code></li>
<li><code>fused_pack_op_unpack_triton(...)</code></li>
<li><code>fused_pack_op_unpack_dispatch(...)</code></li>
</ul>
</li>
<li>Determinism rule for Stage-1 path:<ul>
<li>requires unique tile indices per batch row to avoid overlap write races.</li>
</ul>
</li>
<li>Added exports:</li>
<li><code>apex_x/kernels/triton/__init__.py</code> now exports fused Stage-1 APIs.</li>
<li>Added parity tests:</li>
<li><code>tests/test_triton_fused_stage1_dispatch.py</code></li>
<li><code>tests/test_triton_fused_stage1_gpu.py</code></li>
<li>Added microbenchmark:</li>
<li><code>apex_x/bench/triton_fused_stage1_bench.py</code></li>
<li>compares:<ul>
<li>explicit reference composition (<code>pack -&gt; op -&gt; unpack</code>)</li>
<li>separate dispatch composition (<code>TilePack dispatch -&gt; op -&gt; TileUnpack dispatch</code>)</li>
<li>fused Stage-1 dispatch</li>
</ul>
</li>
<li>Added docs:</li>
<li><code>docs/runtime/TRITON_FUSED_STAGE1.md</code></li>
<li>updated:<ul>
<li><code>docs/runtime/TRITON.md</code></li>
<li><code>docs/index.md</code></li>
<li><code>mkdocs.yml</code></li>
</ul>
</li>
</ul>
<h3 id="run-commands">Run Commands</h3>
<ul>
<li>Tests:</li>
<li><code>python -m pytest -q tests/test_triton_fused_stage1_dispatch.py tests/test_triton_fused_stage1_gpu.py</code></li>
<li>Microbenchmark:</li>
<li><code>python -m apex_x.bench.triton_fused_stage1_bench --batch 1 --channels 128 --height 128 --width 128 --tile-size 8 --kmax 32 --warmup 10 --iters 50 --dtype fp16</code></li>
<li>Lint/type quick checks:</li>
<li><code>python -m ruff check apex_x/kernels/triton/fused_pack_op_unpack.py tests/test_triton_fused_stage1_dispatch.py tests/test_triton_fused_stage1_gpu.py apex_x/bench/triton_fused_stage1_bench.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/fused_pack_op_unpack.py apex_x/bench/triton_fused_stage1_bench.py</code></li>
</ul>
<h3 id="remaining-work">Remaining Work</h3>
<ul>
<li>Wire Stage-1 fused kernel into legacy runtime entrypoint:</li>
<li><code>apex_x/runtime/triton_fused.py::gather_gate_scatter(...)</code></li>
<li>Extend fused kernel beyond Stage-1 local transform:</li>
<li>add overlap-priority semantics in-kernel where needed</li>
<li>integrate Tile-SSM-related fused blocks (next stages)</li>
<li>Add GPU CI perf threshold gates for <code>speedup_separate_over_fused</code>.</li>
</ul>
<h2 id="latest-update-2026-02-08-triton-tilessm-scan-baseline">Latest Update (2026-02-08): Triton TileSSM Scan Baseline</h2>
<ul>
<li>Added Triton TileSSM scan module:</li>
<li><code>apex_x/kernels/triton/tilessm_scan.py</code></li>
<li>Forward-only recurrence scan over tokens <code>tokens[B,K,C]</code> with stable sanitization/clamping.</li>
<li>Outputs:<ul>
<li><code>y[B,K,C]</code></li>
<li><code>final_state[B,C]</code></li>
</ul>
</li>
<li>Added availability + dispatch API:<ul>
<li><code>get_triton_tilessm_availability()</code></li>
<li><code>tilessm_scan_reference(...)</code></li>
<li><code>tilessm_scan_triton(...)</code></li>
<li><code>tilessm_scan_dispatch(...)</code></li>
</ul>
</li>
<li>Dispatch keeps training-safe behavior:<ul>
<li><code>inference_only=True</code> falls back to reference when autograd is active.</li>
</ul>
</li>
<li>Exported TileSSM API:</li>
<li><code>apex_x/kernels/triton/__init__.py</code></li>
<li>Integrated inference path into model heavy FF scan:</li>
<li>updated <code>apex_x/model/ff_heavy_path.py</code><ul>
<li>new <code>use_triton_inference_scan</code> toggle</li>
<li>eval mode uses <code>tilessm_scan_dispatch(...)</code></li>
<li>train mode keeps torch scan path (<code>StableStateSpaceScan</code> / <code>StableBidirectionalStateSpaceScan</code>)</li>
</ul>
</li>
<li>updated <code>apex_x/model/ff_module.py</code><ul>
<li>routes <code>RuntimeConfig.enable_runtime_plugins</code> to <code>FFHeavyPath(..., use_triton_inference_scan=...)</code></li>
</ul>
</li>
<li>Added tests:</li>
<li><code>tests/test_triton_tilessm_parity_dispatch.py</code></li>
<li><code>tests/test_triton_tilessm_parity_gpu.py</code></li>
<li><code>tests/test_ff_heavy_path_tilessm_dispatch.py</code></li>
<li>Added throughput benchmark:</li>
<li><code>apex_x/bench/triton_tilessm_bench.py</code></li>
<li>Added docs:</li>
<li><code>docs/runtime/TRITON_SSM.md</code></li>
<li>updated:<ul>
<li><code>docs/runtime/TRITON.md</code></li>
<li><code>docs/index.md</code></li>
<li><code>mkdocs.yml</code></li>
</ul>
</li>
</ul>
<h3 id="run-commands_1">Run Commands</h3>
<ul>
<li>Tests:</li>
<li><code>python -m pytest -q tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py tests/test_ff_heavy_path_tilessm_dispatch.py tests/test_ff_heavy_path.py</code></li>
<li>Benchmark:</li>
<li><code>python -m apex_x.bench.triton_tilessm_bench --batch 2 --steps 256 --channels 128 --warmup 10 --iters 50 --dtype fp16</code></li>
<li>Lint/type checks:</li>
<li><code>python -m ruff check apex_x/kernels/triton/tilessm_scan.py apex_x/model/ff_heavy_path.py apex_x/model/ff_module.py apex_x/bench/triton_tilessm_bench.py tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py tests/test_ff_heavy_path_tilessm_dispatch.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/tilessm_scan.py apex_x/model/ff_heavy_path.py apex_x/model/ff_module.py apex_x/bench/triton_tilessm_bench.py tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py tests/test_ff_heavy_path_tilessm_dispatch.py</code></li>
<li>Docs:</li>
<li><code>.venv/bin/mkdocs build --strict</code></li>
</ul>
<h3 id="validation-status">Validation Status</h3>
<ul>
<li><code>ruff</code>: passed on changed TileSSM files.</li>
<li><code>mypy</code>: passed on changed TileSSM files.</li>
<li><code>pytest</code>: passed for new parity/integration tests (GPU tests auto-skipped on CPU-only environment).</li>
<li>benchmark smoke run: completed on CPU fallback path.</li>
<li>docs build: passed with strict mode.</li>
</ul>
<h3 id="remaining-work_1">Remaining Work</h3>
<ul>
<li>Add multi-direction scan execution mode in Triton TileSSM path (current kernel is forward-only baseline).</li>
<li>Add a fused TileSSM + tile-local refine path after this baseline.</li>
<li>Add GPU CI lane for TileSSM parity/perf thresholds when CUDA runners are available.</li>
</ul>
<h2 id="latest-update-2026-02-08-triton-tilessm-multi-direction">Latest Update (2026-02-08): Triton TileSSM Multi-Direction</h2>
<ul>
<li>Extended <code>apex_x/kernels/triton/tilessm_scan.py</code> to support directional scanning:</li>
<li><code>direction</code>: <code>forward</code>, <code>backward</code>, <code>bidirectional</code></li>
<li><code>merge_mode</code> for bidirectional: <code>sum</code>, <code>avg</code>, <code>gated</code></li>
<li>optional torch-computed <code>merge_gate</code> for gated merge (<code>[C]</code> or <code>[B,1,C]</code>)</li>
<li>Added clean directional API:</li>
<li><code>scan(tokens, direction=...) -&gt; y</code></li>
<li>routes through dispatch with fallback behavior</li>
<li>Kept training/inference separation:</li>
<li>training/backward still uses torch scan path</li>
<li>inference dispatch can use Triton path (<code>inference_only=True</code>)</li>
<li>Updated FF inference integration:</li>
<li><code>apex_x/model/ff_heavy_path.py</code></li>
<li>Triton inference path now uses directional dispatch (<code>forward</code> and <code>backward</code>) and applies learned torch gate for merge in bidirectional mode.</li>
<li>Updated exports:</li>
<li><code>apex_x/kernels/triton/__init__.py</code> now exports:<ul>
<li><code>ScanDirection</code></li>
<li><code>BidirectionalMergeMode</code></li>
<li><code>scan</code></li>
</ul>
</li>
<li>Updated benchmark for multi-direction overhead:</li>
<li><code>apex_x/bench/triton_tilessm_bench.py</code></li>
<li>now reports forward/backward/bidirectional timings and overhead ratios vs forward.</li>
<li>Updated tests:</li>
<li><code>tests/test_triton_tilessm_parity_dispatch.py</code><ul>
<li>added backward parity vs torch manual recurrence</li>
<li>added bidirectional parity for <code>sum/avg/gated</code></li>
<li>added clean API <code>scan(...)</code> test</li>
</ul>
</li>
<li><code>tests/test_triton_tilessm_parity_gpu.py</code><ul>
<li>added bidirectional avg parity test (GPU)</li>
</ul>
</li>
<li>Updated docs:</li>
<li><code>docs/runtime/TRITON_SSM.md</code></li>
<li><code>docs/runtime/TRITON.md</code></li>
</ul>
<h3 id="run-commands_2">Run Commands</h3>
<ul>
<li>Tests:</li>
<li><code>python -m pytest -q tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py tests/test_ff_heavy_path_tilessm_dispatch.py tests/test_ff_heavy_path.py</code></li>
<li>Benchmark:</li>
<li><code>python -m apex_x.bench.triton_tilessm_bench --batch 2 --steps 256 --channels 128 --warmup 10 --iters 50 --dtype fp16</code></li>
<li>Lint/type:</li>
<li><code>python -m ruff check apex_x/kernels/triton/tilessm_scan.py apex_x/kernels/triton/__init__.py apex_x/model/ff_heavy_path.py apex_x/bench/triton_tilessm_bench.py tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py</code></li>
<li><code>python -m mypy --cache-dir=/dev/null apex_x/kernels/triton/tilessm_scan.py apex_x/kernels/triton/__init__.py apex_x/model/ff_heavy_path.py apex_x/bench/triton_tilessm_bench.py tests/test_triton_tilessm_parity_dispatch.py tests/test_triton_tilessm_parity_gpu.py</code></li>
<li>Docs:</li>
<li><code>.venv/bin/mkdocs build --strict</code></li>
</ul>
<h3 id="validation-status_1">Validation Status</h3>
<ul>
<li><code>ruff</code>: passed</li>
<li><code>mypy</code>: passed</li>
<li><code>pytest</code>: passed (GPU tests skipped on CPU-only environment)</li>
<li>benchmark smoke run: passed (reference fallback on CPU)</li>
<li>docs build (<code>mkdocs --strict</code>): passed</li>
</ul>
<h2 id="latest-update-2026-02-08-tensorrt-build-hardening-harness">Latest Update (2026-02-08): TensorRT Build Hardening + Harness</h2>
<ul>
<li>Read runtime specs from:</li>
<li><code>docs/runtime/PLUGIN_SPEC.md</code> (canonical)</li>
<li><code>docs/runtime/TENSORRT.md</code></li>
<li>Added alias page: <code>docs/runtime/PLUGIN_SPECS.md</code> -&gt; points to canonical spec</li>
<li>Hardened TensorRT CMake in <code>runtime/tensorrt/CMakeLists.txt</code>:</li>
<li>shared plugin library support:<ul>
<li><code>apexx_trt_plugins</code> (SHARED)</li>
</ul>
</li>
<li>added always-build static core:<ul>
<li><code>apexx_trt_plugin_core</code> (STATIC, PIC)</li>
</ul>
</li>
<li>compile-guard behavior:<ul>
<li>shared plugin library builds only when TensorRT headers and CUDA compiler are found</li>
<li>if TRT/CUDA unavailable, shared build is skipped cleanly and repo remains buildable</li>
</ul>
</li>
<li>plugin info target kept available:<ul>
<li><code>apexx_trt_plugin_info</code></li>
</ul>
</li>
<li>harness target added conditionally (only with shared build):<ul>
<li><code>apexx_trt_plugin_harness</code></li>
</ul>
</li>
<li>Added minimal plugin enqueue-like path for stubs:</li>
<li><code>runtime/tensorrt/include/apexx_trt/plugin_stub.hpp</code><ul>
<li><code>DummyTensor</code>, <code>PluginEnqueueInputs</code>, <code>PluginEnqueueOutputs</code>, <code>PluginStub::enqueue(...)</code></li>
</ul>
</li>
<li>implemented enqueue methods in:<ul>
<li><code>runtime/tensorrt/src/tile_pack_plugin.cpp</code></li>
<li><code>runtime/tensorrt/src/tile_ssm_scan_plugin.cpp</code></li>
<li><code>runtime/tensorrt/src/tile_unpack_fusion_plugin.cpp</code></li>
<li><code>runtime/tensorrt/src/decode_nms_plugin.cpp</code></li>
</ul>
</li>
<li>Added shared-library C ABI entrypoints in:</li>
<li><code>runtime/tensorrt/include/apexx_trt/common.hpp</code></li>
<li><code>runtime/tensorrt/src/common.cpp</code></li>
<li>symbols:<ul>
<li><code>apexx_trt_abi_version()</code></li>
<li><code>apexx_trt_build_summary_cstr()</code></li>
<li><code>apexx_trt_invoke_minimal(...)</code></li>
</ul>
</li>
<li>Added minimal runtime harness executable source:</li>
<li><code>runtime/tensorrt/tests/plugin_harness_main.cpp</code></li>
<li>harness behavior:<ul>
<li>loads plugin shared library via <code>dlopen</code>/<code>LoadLibrary</code></li>
<li>resolves C ABI symbols</li>
<li>creates dummy tensors</li>
<li>invokes minimal plugin call path for TilePack/TileSSMScan/TileUnpackFusion/DecodeNMS</li>
</ul>
</li>
<li>Added build doc:</li>
<li><code>docs/runtime/TENSORRT_BUILD.md</code></li>
<li>Updated docs navigation and runtime note cross-links:</li>
<li><code>mkdocs.yml</code></li>
<li><code>docs/index.md</code></li>
<li><code>docs/runtime/TENSORRT.md</code></li>
</ul>
<h3 id="exact-build-commands">Exact Build Commands</h3>
<ul>
<li>Auto-detect build:</li>
<li><code>cd runtime/tensorrt</code></li>
<li><code>cmake -S . -B build</code></li>
<li><code>cmake --build build -j</code></li>
<li><code>./build/apexx_trt_plugin_info</code></li>
<li>Explicit TRT/CUDA paths:</li>
<li><code>cd runtime/tensorrt</code></li>
<li><code>cmake -S . -B build -DTENSORRT_INCLUDE_DIR=\"${TENSORRT_ROOT}/include\" -DCMAKE_CUDA_COMPILER=\"${CUDA_HOME}/bin/nvcc\"</code></li>
<li><code>cmake --build build -j</code></li>
<li>Force skip shared plugin build (portable/CI machines):</li>
<li><code>cd runtime/tensorrt</code></li>
<li><code>cmake -S . -B build -DAPEXX_ENABLE_TENSORRT=OFF -DAPEXX_ENABLE_CUDA=OFF -DAPEXX_BUILD_PLUGIN_TEST_HARNESS=OFF</code></li>
<li><code>cmake --build build -j</code></li>
<li>Harness run (when shared plugin target is built):</li>
<li><code>./build/apexx_trt_plugin_harness ./build/libapexx_trt_plugins.so</code></li>
<li>or:</li>
<li><code>export APEXX_TRT_PLUGIN_LIB=./build/libapexx_trt_plugins.so</code></li>
<li><code>./build/apexx_trt_plugin_harness</code></li>
</ul>
<h3 id="environment-variables">Environment Variables</h3>
<ul>
<li><code>TENSORRT_ROOT</code>: TensorRT install root (optional)</li>
<li><code>CUDA_HOME</code>: CUDA root (optional)</li>
<li><code>CMAKE_PREFIX_PATH</code>: dependency discovery override (optional)</li>
<li><code>APEXX_TRT_PLUGIN_LIB</code>: path to shared plugin library for harness runtime loading</li>
</ul>
<h3 id="validation-status_2">Validation Status</h3>
<ul>
<li><code>mkdocs build --strict</code>: passed</li>
<li><code>pytest tests/test_import_smoke.py</code>: passed</li>
<li>Local CMake configure/build execution could not be run in this environment because <code>cmake</code> binary is not installed (<code>command not found</code>).</li>
</ul>
<h2 id="update-protocol-every-significant-change">Update Protocol (Every Significant Change)</h2>
<ul>
<li>Update this file with:</li>
<li>what changed</li>
<li>why it changed</li>
<li>what to do next</li>
<li>If architecture changed, also update <code>docs/DECISIONS.md</code></li>
<li>If requirements changed, update PRD/spec first, then code</li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
